{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d7b8ca-aa14-4dcb-bcc7-9df74692fd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "GPU Name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd29752-bb3c-46ce-8cc3-54c4ff32ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in c:\\users\\vinay\\anaconda3\\lib\\site-packages (6.3.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from ftfy) (0.2.5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  100 non-null    int64 \n",
      " 1   id          100 non-null    object\n",
      " 2   title       100 non-null    object\n",
      " 3   abstract    100 non-null    object\n",
      " 4   published   100 non-null    object\n",
      " 5   pdf_url     100 non-null    object\n",
      " 6   full_text   100 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.6+ KB\n",
      "Paper ID: 2110.00237v1\n",
      "\n",
      "Abstract: For each $s\\in \\mathbb R$ and $n\\in \\mathbb N$, let $\\sigma_s(n) =\n",
      "\\sum_{d\\mid n}d^s$. In this article, we give a comparison between\n",
      "$\\sigma_s(an+b)$ and $\\sigma_s(cn+d)$ where $a$, $b$, $c$, $d$, $s$ are fixed,\n",
      "the vectors $(a,b)$ and $(c,d)$ are linearly independent over $\\mathbb Q$, and\n",
      "$n$ runs over all positive integers. For example, if $|s|\\leq 1$, $a, b, c,\n",
      "d\\in \\mathbb N$ are fixed and satisfy certain natural conditions, then $$\n",
      "\\sigma_s(an+b) < \\sigma_s(cn+d)\\quad\\text{ for all $n\\leq M$} $$ where $M$ may\n",
      "be arbitrarily large, but in fact $\\sigma_s(an+b) - \\sigma_s(cn+d)$ has\n",
      "infinitely many sign changes. The results are entirely different when $|s|>1$,\n",
      "where the following three cases may occur: \\begin{itemize} \\item[(i)]\n",
      "$\\sigma_s(an+b) < \\sigma_s(cn+d)$ for all $n\\in \\mathbb N$; \\item[(ii)]\n",
      "$\\sigma_s(an+b) < \\sigma_s(cn+d)$ for all $n\\leq M$ and $\\sigma_s(an+b) >\n",
      "\\sigma_s(cn+d)$ for all $n\\geq M+1$; \\item[(iii)] $\\sigma_s(an+b) -\n",
      "\\sigma_s(cn+d)$ has infinitely many sign changes. \\end{itemize} We also give\n",
      "several examples and propose some problems.\n",
      "\n",
      "Clean Text: \n",
      "1. Introduction Perhaps, the most interesting inequalities in number theory are those between primes and functions whose values depend on primes. For example, functions f and g may satisfy f(x) < g(x) on a large interval [1, M], but in fact f(x) − g(x) has infinitely many sign changes as x → ∞; and the smallest number x0 for which f(x0) > g(x0) exists in theory but is very difficult to find explicitly. Although it might be better to focus only on those f and g which are asymptotic and satisfy some kinds of Chebyshev's bias phenomenon, we do not require these conditions here. In fact, we are interested in the inequalities between f(x) and g(x) and the number of sign changes in f(x) − g(x) as x → ∞. In this article, we will be concerned with the comparison between the values of the function σs over arithmetic progressions. Throughout, s is a real number, m and n are positive integers, p is a prime, pn is the nth prime, ϕ(n) is the number of m ≤ n with gcd(m, n) = 1, σs(n) = P d|n d s , τ(n) = σ0(n), σ(n) = σ1(n), and 2020 Mathematics Subject Classification. Primary 11A25; Secondary 11B25, 11N64. Key words and phrases. divisor function; arithmetic progression; local behavior; arithmetic function; inequality. 12 P. PONGSRIIAM ζ is the Riemann zeta function which is given by ζ(s) = P∞ n=1 n −s for s > 1. We sometimes simply write (m, n) to denote gcd(m, n). Jarden [7, p. 65] observed that ϕ(30n+1) > ϕ(30n) for all n ≤ 105 and further computations will show us that this inequality continues to hold for all n up to a billion. However, contrary to the numerical evidence, Newman [17] proved that there are infinitely many n such that ϕ(30n + 1) < ϕ(30n); the smallest such n for which this inequality holds has 1116 digits and was given explicitly by Martin [15], namely, n = (z − 1)/30 where z = Q j=4 pj p385p388. Aldaz, Bravo, Guti´errez, and Ubis [1] extended Newman's theorem to the following form: if a, b, c, d are nonnegative integers, a, c > 0, and ad − bc 6= 0, then lim inf n→∞ ϕ(an + b) ϕ(cn + d) = 0 and lim sup n→∞ ϕ(an + b) ϕ(cn + d) = ∞. The assumption ad − bc 6= 0 is necessary because they [1] also showed that if ad−bc = 0, then R ≤ ϕ(an+b)/ϕ(cn+d) ≤ M for some positive real numbers R and M, and so the limits infimum and supremum are not 0 and ∞, respectively. This gives a complete picture for the comparison between ϕ(an+b) and ϕ(cn+d). However, as far as we are aware, this kind of investigation has not been done for σs. We find a similar (but reverse) inequality, namely, σ(30n + 1) < σ(30n) for all n ≤ 107, yet there are infinitely many n for which σ(30n + 1) > σ(30n). In general, if −1 ≤ s ≤ 1, then the results for σs are similar to those of ϕ (see Theorem 2.5, Corollary 2.6, and Examples 2.7 and 2.14). Nevertheless, if |s| > 1, then the answers are completely different. First of all, we show in Theorem 2.9 that σs(an + b)/σs(cn + d) is bounded away from 0 and ∞. Secondly, comparing the size of σs(an + b) and σs(cn + d), the following three inequality examples may occur: (IE1) Always win or always lose: σs(an + b) < σs(cn + d) for all n ∈ N (see Theorems 2.10, 2.11 and 2.12, and Examples 2.2 and 2.14). (IE2) Change signs exactly once: σs(an+b) < σs(cn+d) for an arbitrarily long string of consecutive integers n = 1, 2, . . . , M, and σs(an+b) > σs(cn+d) for all n ≥ M + 1 (see Theorem 2.15 and Example 2.18). (IE3) Change signs infinitely often: σs(an + b) < σs(cn + d) and σs(am + b) > σs(cm + d) for infinitely many m and n (see Theorems 2.19 and 2.20). The inequalities in (IE1), (IE2), and (IE3) may be considered as the 0-type, 1-type, and ∞-type inequalities according to the number of sign changes in σs(an+b)−σs(cn+d) as a, b, c, d are fixed and n runs over all positive integers. We do not know whether or not there exists an example for a k-type inequality for each positive integer k > 1 (see also Problem 12).SUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS By changing the role of a, b, c, d, we can replace the signs < by > and > by < in (IE1), (IE2), and (IE3). In addition, to avoid triviality or unnecessary complications, we focus our study on the cases where a, b, c, d are nonnegative integers, a, c > 0, and ad − bc 6= 0. Note that the assumption ad − bc 6= 0 is equivalent to (a, b) and (c, d) are linearly independent over Q; for if ad − bc = 0, then a (a, b)− c (c, d) = (0, 0) and if (a, b) = (q1/q2)(c, d) for some q1 ∈ Z, q2 ∈ N, then ad − bc = (q1c/q2) d − (q1d/q2) c = 0. In the next section, we prove the main results and show several examples. We also propose some possible research problems and give some related references. We do not plan to solve these problems soon; we will do it in the future but we do not mind if the reader will solve them. 2. Main Results Throughout, let a, b, c, d be nonnegative integers with a, c > 0. We first deal with the case ad = bc in Theorem 2.1 and Example 2.2. After that, we restrict ourselves to the case ad 6= bc and give general criteria and several examples for (IE1), (IE2), and (IE3) introduced earlier. Recall that the function σs is multiplicative for every s ∈ R, and observe that if ad = bc, then there are positive integers r1 and r2 such that r1(a, b) = r2(c, d). We have the following result. 2.1. The case ad = bc and s ∈ R. Theorem 2.1. Let s ∈ R and let a, b, c, d be nonnegative integers, a, c > 0, and ad = bc. Let r1 and r2 be positive integers such that r1(a, b) = r2(c, d). Then for every n ≥ 1, r s σs(r1) ≤ σs(an + b) σs(cn + d) ≤ σs(r2) r s . Proof. Observe that if p is a prime and α, β are nonnegative integers, then σs(p α)σs(pβ ) is equal to (1 + p s + · · · + pαs)(1 + ps + · · · + pβs), which is larger than or equal to (1+p s+· · ·+pαs)+pαs(ps+p2s+· · ·+pβs) = 1+ps+p2s+· · ·+p(α+β)s = σs(pα+β ). Similarly, σs(p α+β ) ≥ p αsσs(pβ ). From this and the multiplicativity of σs, it follows that σs(m)σs(n) ≥ σs(mn) ≥ msσs(n) for all m, n ∈ N. Therefore for every n ≥ 1, σs(r1)σs(an + b) ≥ σs(r1(an + b)) ≥ r s 1σs(an + b), σs(r2)σs(cn + d) ≥ σs(r2(cn + d)) ≥ r s 2σs(cn + d). Since the middle terms of each inequality are the same, these lead to the desired result. 4 P. PONGSRIIAM Example 2.2. If a, b, c, d are integers as given in Theorem 2.1, then it is easy to construct an example such that σs(an + b) < σs(cn + d) for all n ∈ N. For example, σs(2n) < σs(4n) for all n ∈ N and s ∈ R. In general, if 0 < a < c and a | c, then every divisor of a is also a divisor of c, while c | c but c ∤ a, which implies σs(an) < σs(cn) for all n ∈ N and s ∈ R. Problem 1. By Example 2.2, we know that (IE1) exists for infinitely many a, b, c, d satisfying ad = bc. It is natural to ask whether or not (IE2) and (IE3) can occur in this case. For example, if M is a given positive integer, can we always find s ∈ R and a, b, c, d satisfying the assumption of Theorem 2.1 such that σs(an + b) < σs(cn + d) for n ≤ M and σs(an + b) > σs(cn + d) for all n ≥ N where N ≥ M + 1? Can we choose N to be M + 1 for each M? If s is a given real number, are there nonnegative integers a, b, c, d satisfying a, c > 0 and ad = bc such that σs(an + b) − σs(cn + d) changes sign infinitely many times? Problem 2. Does the converse of Example 2.2 hold? In other words, if s ∈ R, a, b, c, d are nonnegative integers, a, c > 0, ad = bc, and σs(an + b) < σs(cn + d) for all n ∈ N, can we conclude that a | c? or perhaps (a, b) | (c, d)? Remark 2.3. Before proceeding to the next subsection, let us recall that if 1 + an > 0 for all n ∈ N, then the infinite product Q∞ n=1(1 + an) is said to be convergent if limk→∞ Qk n=1(1 +an) exists and is not zero. If the limit converges to zero (or diverges to ∞), then the infinite product is said to diverge to zero (or diverge to ∞), respectively. In addition, it is well-known that if P∞ n=1 |an| converges, then Q∞ n=1(1+|an|) converges; if P∞ n=1 |an| = ∞, then Q∞ n=1(1+|an|) also diverges to ∞. We will often refer to the following condition: (A) a, b, c, d are nonnegative integers, a, c > 0, and ad 6= bc. (2.1) 2.2. The case ad 6= bc and |s| ≤ 1. Theorem 2.4. Let a, b, c, d satisfy the condition (A) given in (2.1). Then there exists a strictly increasing sequence (nk) of positive integers that does not depend on s and (i) lim k→∞ σs(ank + b) σs(cnk + d) = 0 for all s ∈ [0, 1]. In particular, if 0 ≤ s ≤ 1, then (ii) lim inf n→∞ σs(an + b) σs(cn + d) = 0 and (iii) lim sup n→∞ σs(an + b) σs(cn + d) = ∞.SUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS Proof. We modify the idea of Newman [17] and Aldaz et. al [1]. Recall that p is always a prime and pn is the nth prime. Let D = 2τ(|ad − bc|) and for each k ≥ 1, let mk be the product of all primes p ≤ pk with p ∤ c. Since ad− bc 6= 0, D is well-defined. In addition, mk is a finite product, mk ≤ p k k , and mk → ∞ as k → ∞. The following observation will be used throughout this article sometimes without reference. We have, for any s ≥ 0, σs(n) ns = X d|n d s = Y pαkn 1 + p s + p 2s + · · · + p αs ≥ Y p|n 1 + p s . (2.2) Next, we will construct a strictly increasing sequence (nk) of positive integers such that σs(ank + b) (ank + b) s ≤ D and lim k→∞ (cnk + d) s σs(cnk + d) = 0 for all s ∈ [0, 1]. (2.3) Since gcd(mk, c) = 1, there exists a pair of integers n0, y0 which is a solution to the Diophantine equation cn − mky = −d, and all solutions are given by n = n0 + mkt and y = y0 + ct where t ∈ Z is arbitrary. We keep in mind that the integers n0, y0 may depend on k and so n and y depend on k and t. Then an + b = a(n0 + mkt) + b = (an0 + b) + amkt = δ(A + Bt) where δ = gcd(an0 + b, amk), A = (an0 + b)/δ, and B = amk/δ. Then δ divides c(an0 + b) − y0(amk) = a(cn0 − mky0) + bc = bc − ad. Since (A, B) = 1, we obtain by Dirichlet's theorem for primes in arithmetic progressions that there are infinitely many t ∈ Z + such that A + Bt is a prime. So we choose t ∈ Z+ so that A + Bt is a prime larger than |bc − ad| ≥ δ. Therefore for each k ≥ 1, we can choose a large positive integer tk and a pair of positive integers nk = nk,tk, yk = yk,tksatisfying cnk − mkyk = −d, ank + b = δqk where qk is a prime larger than δ, nk+1 − nk > 0, and qk+1 − qk > 0 for all k. Now that we have the P sequence (nk), it remains to prove (2.3). So let s ∈ [0, 1]. Since s ≤ 1, the series p p −s diverges to ∞. In addition, by (2.2) and the fact that cnk + d = mkyk, we obtain (cnk + d) s σs(cnk + d) ≤ Y p|mkyk 1 + p s − ≤ Y p|mk 1 + p s − = Y p≤pk p∤c 1 + p s − , which diverges to zero as k → ∞. Hence the second part of (2.3) is verified. Since ank + b = δqk, δ | ad − bc, qk > δ, and σs is multiplicative, we have σs(ank + b) (ank + b) s = σs(δ) δ s σs(qk) q s k =   X u|δ u s   1 + q s k ≤ 2τ(δ) ≤ D,6 P. PONGSRIIAM which is the first part of (2.3). By writing, σs(an + b) σs(cn + d) = σs(an + b) (an + b) s · an + b cn + d s · (cn + d) s σs(cn + d) , (2.4) substituting n = nk, and applying (2.3), we obtain (i). Then (ii) follows immediately from (i). Since (ii) holds for all a, b, c, d, we can interchange the role of a, c and b, d to obtain (iii). This completes the proof. We can extend Theorem 2.4 to the case s ∈ [−1, 1] as follows. Theorem 2.5. Let a, b, c, d satisfy the condition (A) and (nk) the sequence constructed in the proof of Theorem 2.4. Then σs(ank+b)/σs(cnk+d) converges to zero as k → ∞ for all s ∈ [−1, 1]. In addition, there exists a sequence (mk) such that σs(amk + b)/σs(cmk + d) → ∞ as k → ∞ for all s ∈ [−1, 1]. In particular, if |s| ≤ 1, then lim inf n→∞ σs(an + b) σs(cn + d) = 0 and lim sup n→∞ σs(an + b) σs(cn + d) = ∞. Proof. If 0 ≤ s ≤ 1, then this follows from Theorem 2.4. So assume that −1 ≤ s < 0. Let r = −s. Then 0 < r ≤ 1 and for each m ∈ N, we have σr(m) mr = X d|m d r = X d|m d s = σs(m). Therefore σs(ank + b) σs(cnk + d) = σr(ank + b) σr(cnk + d) cnk + d ank + b r . Applying Theorem 2.4 to the right-hand side of the above equation, we obtain that the left-hand side converges to zero as k → ∞, as required. Since this is true for all a, b, c, d, we can interchange the role of a, b, c, d to obtain the sequence (mk) with the desired property. The rest follows immediately. Corollary 2.6. If −1 ≤ s1 < s2 < · · · < sℓ ≤ 1 and a, b, c, d satisfy the condition (A), then there are infinitely many m, n ∈ N such that σs(am + b) < σs(cm + d) and σs(an + b) > σs(cn + d) for all s ∈ {s1, s2, . . . , sℓ}. Proof. Since the sequences (nk) and (mk) in Theorem 2.5 can be used for all s ∈ [−1, 1], this corollary follows immediately from Theorem 2.5. Example 2.7. By running the computation in a computer, we find that σs(30n + 1) < σs(30n) for all s ∈ {−1, 0, 1/2, 1} and n ≤ 106. However, by Corollary 2.6, there are infinitely many m ∈ N such that σs(30m + 1) > σs(30m) for all s ∈ {−1, 0, 1/2, 1}.SUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS The smallest m for which σ1/2(30m + 1) > σ1/2(30m) is m = 2338703. When s ∈ {−1, 0, 1} the smallest such m seems to be very large. Problem 3. It may be interesting to find the smallest positive integer n for which the following inequalities hold: σ(6n + 1) > σ(6n), σ(30n + 1) > σ(30n), σ(210n + 1) > σ(210n), etc. Adjusting Martin's method [15] may lead to such the integer n. In general, suppose a, b, c, d are fixed and satisfy the condition (A). Let f : [−1, 1] → N be defined by f(s) = fσ,a,b,c,d(s) = ns be the smallest positive integer for which σs(ans + b) − σs(cns + d) changes sign. How is f behave? Is f increasing on [1/2, 1]? Definitely, the answer depends on a, b, c, d. Are there a, b, c, d such that f is increasing on [−1, 1] or on [0, 1]? Is f a step function? Many questions can be asked. We leave them to the reader's curiosity. For 2 ≤ k ≤ 10, let g(k) = fσ,6,1,6, k− k be the smallest n such that σ k− k (6n + 1) > σ k− k (6n). Then, by running the computation in a computer, we find that g(2) = 379, g(3) = 5839, g(4) = 95929 = g(5), g(6) = 326159 = g(7), g(8) = 2198029 = g(9), and g(10) = 7813639. This is a numerical data which suggests that g may be increasing on [1/2, 1]. Remark 2.8. When |s| > 1, the results are entirely different. First of all, unlike the results for |s| ≤ 1 in Theorem 2.5, it does not matter if ad − bc is zero or nonzero, σs(an + b)/σs(cn + d) is always bounded away from zero and infinity when |s| > 1 as shown in the next theorem. 2.3. The first case for |s| > 1. Theorem 2.9. Let |s| > 1 and let a, b, c, d be nonnegative integers with a, c > 0. Then there are positive real numbers R and M such that R|s| ζ(|s|) ≤ σs(an + b) σs(cn + d) ≤ ζ(|s|)M|s|. Proof. Since (an+b)/(cn+d) converges to a/c > 0 as n → ∞, there are R1, M1 > 0 such that R1 ≤ (an + b)/(cn + d) ≤ M1 for all n ≥ 1. Let R = min{1, R1} and M = max{1, M1}. If s > 1 and n ∈ N, then R s ≤ (an + b) s (cn + d) s ≤ Ms and 1 ≤ σs(n) ns = X d|n d s ≤ X∞ d= d s = ζ(s). (2.5)8 P. PONGSRIIAM So if s > 1 and n ∈ N, we write σs(an+b)/σs(cn+d) as in (2.4) and apply (2.5) to obtain the desired result. If s < −1 and n ∈ N, then 1 ≤ σs(n) = X d|n d−s ≤ ζ(−s) and therefore R−s ζ(−s) ≤ ζ(−s) ≤ σs(an + b) σs(cn + d) ≤ ζ(−s) ≤ ζ(−s)M−s. This completes the proof. Various situations where (IE1) may occur are given in Theorems 2.10 and 2.12. The integer N in Theorem 2.10 may or may not be 1 but it can be chosen to be 1 as shown in Theorems 2.11 and 2.12. From this point on, we restrict ourselves to the case s > 1 and leave the study of s < −1 to the interested reader. Theorem 2.10. Suppose a and c are distinct positive integers. (i) If a > c and b, d are nonnegative integers, then there are N ∈ N and a real number s0 > 1 such that σs(an + b) > σs(cn + d) for all s ≥ s0 and n ≥ N. (ii) If a < c and b, d are nonnegative integers, then there are N ∈ N and a real number s0 > 1 such that σs(an + b) < σs(cn + d) for all s ≥ s0 and n ≥ N. Proof. As usual, (ii) follows from (i) by changing the role of a, c and b, d. So we only need to prove (i). Let ε = (a/c − 1)/2. Then 1 < 1 + ε < a/c. Since (an + b)/(cn + d) → a/c as n → ∞, there exists N ∈ N such that an + b > (1 + ε)(cn + d) for all n ≥ N. In addition, ζ(s) → 1 as s → ∞, so there exists s0 > 1 such that ζ(s) < 1 + ε for all s ≥ s0. For s ≥ s0 and n ≥ N, the first quotient on the right-hand side of (2.4) is larger than 1, and therefore σs(an + b) σs(cn + d) > an + b cn + d s (cn + d) s σs(cn + d) > (1 + ε) s P k|cn+d k−s > (1 + ε) s ζ(s) > (1 + ε) s−1 > 1. This completes the proof. Adjusting Theorem 2.10 a little, we can take N = 1 as follows. Theorem 2.11. Let a, b, c, d be integers. Then the following statements hold. (i) If a > c > 0 and b ≥ d ≥ 0, then there exists s0 > 1 such that σs(an + b) > σs(cn + d) for all s ≥ s0 and n ≥ 1.SUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS (ii) If 0 < a < c and 0 ≤ b ≤ d, then there exists s0 > 1 such that σs(an + b) < σs(cn + d) for all s ≥ s0 and n ≥ 1. Proof. We only need to prove (i). Following the proof of Theorem 2.10, let ε be a positive real number satisfying ε < min c , b − d + c + d . Since a ≥ c + 1 and εc < 1, we have a − c − εc ≥ 1 − εc > 0. Therefore, for every n ≥ 1, (an + b) − (1 + ε)(cn + d) = (a − c − εc)n + b − d − εd ≥ (1 − εc) + b − d − εd = (1 + b − d) − ε(c + d) > 0. Thus, an+b > (1+ε)(cn+d) for all n ≥ 1, that is, we can take N in the proof of Theorem 2.10 to be N = 1. The rest is the same and the proof is complete. The difference between the assumptions of Theorem 2.10 and 2.11(i) is that b ≥ d ≥ 0 in the latter while b, d are any given nonnegative integers in the former. In both theorems, the real number s0 is selected and depends on the given integers a, b, c, d. In the next theorem, s0 may be chosen to be independent of a, b, c, d. Theorem 2.12. Let s0 > 1, a, b, c, d satisfy the condition (A) and ad > bc. If either a s0 ζ(s0) < cs0 or 1 ≤ a < c(1 − 1/s0), then σs(an + b) < σs(cn + d) for all n ∈ N and for all s ≥ s0. In particular, for each s0 > 1, there are infinitely many nonnegative integers a, b, c, d such that 0 < a < c, ad − bc > 0, and σs(an + b) < σs(cn + d) for all s ≥ s0 and n ∈ N. Proof. We first recall that for s > 1 and x > 0, we have X n≤x ns ≤ 1 + Z x t s dt = s s − + x 1−s 1 − s ≤ s s − , which implies ζ(s) ≤ s/(s − 1). Now suppose that either a s0 ζ(s0) < cs0 or 1 ≤ a < c(1 − 1/s0) holds. Since ad − bc > 0, we see that an + b cn + d < a c < 1 for every n ∈ N. Therefore if a s0 ζ(s0) < cs , n ∈ N, and s ≥ s0, then σs(an + b) σs(cn + d) = σs(an + b) (an + b) s an + b cn + d s (cn + d) s σs(cn + d) ≤ ζ(s) a c s ≤ ζ(s0) a c s < 1.10 P. PONGSRIIAM If 1 ≤ a < c(1 − 1/s0), then the above implies that for s ≥ s0 and n ∈ N, σs(an + b) σs(cn + d) ≤ ζ(s0) a c s ≤ s s0 − a c < 1. In any case, we have σs(an+b) < σs(cn+d) for all n ∈ N and s ≥ s0. It remains to show that there are infinitely many nonnegative integers a, b, c, d satisfying all the required condition. Since s0 > 1 is given, we can find a large positive integer c such that c(1−1/s0) > 1. Then there exists a positive integer a < c(1−1/s0). Now we can choose any b ≥ 0 and then select any d satisfying d > bc/a. Then 0 < a < c, ad − bc > 0, 1 ≤ a < c(1 − 1/s0), and σs(an + b) < σs(cn + d) for all s ≥ s0 and n ∈ N. This completes the proof. We can change the condition ad > bc in Theorem 2.12 and modify the proof to obtain the following result. Theorem 2.13. Let s0 > 1, a, b, c, d satisfy the condition (A), ad < bc, and a + b < c + d. If either (a + b) s0 ζ(s0) < (c + d)s0 or a + b < (c + d)(1 − 1/s0), then σs(an + b) < σs(cn + d) for all n ∈ N and for all s ≥ s0. In particular, for each s0 > 1, there are infinitely many nonnegative integers a, b, c, d having the above properties. Proof. Since ad < bc and a + b < c + d, we have a c < an + b cn + d ≤ a + b c + d < 1 for all n ≥ 1. Following the proof of Theorem 2.12, if (a + b) s0 ζ(s0) < (c + d)s , n ∈ N, and s ≥ s0, then σs(an + b) σs(cn + d) = σs(an + b) (an + b) s an + b cn + d s (cn + d) s σs(cn + d) ≤ ζ(s) a + b c + d s ≤ ζ(s0) a + b c + d s < 1. If a + b < (c + d)(1 − 1/s0), then the above implies that for s ≥ s0 and n ∈ N, σs(an + b) σs(cn + d) ≤ ζ(s0) a + b c + d s ≤ s s0 − a + b c + d < 1. The rest is easy, so the proof is complete. Example 2.14. By using a computer, we see that σ(2n + 5) < σ(6n + 17) for all n ≤ 106 while σ1/2(2n + 5) < σ1/2(6n + 17) for n ≤ and the inequality changes to > when n = 5. By Corollary 2.6, there are infinitely many n ∈ N for which these inequalities are both < or both >, but we do not know if there exist infinitely many n for which these inequality areSUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS opposite. By Theorem 2.12, we have σs(2n + 5) < σs(6n + 17) and σs(5n + 4) < σs(6n + 7) for all n ∈ N and s ≥ 3. However, we do not know if there are infinitely many m ∈ N for which the inequalities σ(2m + 5) > σ(6m + 17) and σ(5m + 4) > σ(6m + 7) simultaneously hold. Problem 4. Let B = {s1, s2, . . . , sk} and C = {sk+1, sk+2, . . . , sk+ℓ} be subsets of [−1, 1] and let a, b, c, d satisfy the condition (A). By Corollary 2.6, there are infinitely many m and n such that σs(am + b) < σs(cm + d) and σs(an + b) > σs(cn + d) for all s ∈ B ∪ C. Are there infinitely many n for which σs(an + b) < σs(cn + d) for all s ∈ B and σs(an + b) > σs(cn + d) for all s ∈ C? Perhaps, the answer depends on B and C. If B, C ⊆ [1 − ε, 1] where 0 < ε < 1 is very small and all elements of B are less than every element of C, is the above statement true? Similarly, suppose c2, d2 satisfy the condition (A) and (a, b), (c, d), (c2, d2) are linearly independent over Q. We know that there are infinitely many m, n ∈ N for which σs(am + b) < σs(cm + d) and σs(cn + d) < σs(c2n + d2). Since m and n above may be different, it is natural to ask if there are infinitely many r ∈ N such that σs(ar + b) < σs(cr + d) < σs(c2r + d2). If (a, b),(c, d),(c2, d2), . . . ,(cℓ, dℓ) are linearly independent over Q, can we extend the above inequality to σs(ar + b) < σs(cr + d) < σs(c2r + d2) < · · · < σs(cℓr + dℓ)? Problem 5. Suppose 0 ≤ s ≤ 1 and ai, bi, ci, di are nonnegative integers, ai, ci > 0 and aidi − bici 6= 0, for each i = 1, 2, . . . , ℓ. Are there infinitely many n ∈ N such that σs(ain+bi) < σs(cin+di) for all i ∈ {1, 2, . . . , ℓ}? If I, J ⊆ {1, 2, . . . , ℓ} are disjoint, are there infinitely many n ∈ N for which σs(ain + bi) < σs(cin + di) and σs(ajn + bj ) > σs(cjn + dj ) for all i ∈ I and j ∈ J? Are they true if the set of all (ai, bi) and (ci, di) are linearly independent over Q? Perhaps, there exist some kind of admissible sets of ai, bi, ci, di to guarantee that one of the above are true. Goldston, Graham, Pintz, and Yildirim [5], and De Koninck and Luca [4] solved similar problems. Their ideas may be useful in solving Problems 4 and 5 too. Problem 6. What is the infimum of s0 such that σs(2n + 5) < σs(6n + 17) and σs(5n + 4) < σs(6n + 7) for all n ∈ N and s ≥ s0? By Example 2. such the infimum is ≤ 3. In general, if ai, bi, ci, di satisfy the conditions of Theorem 2.12 for all i = 1, 2, . . . , ℓ, can we determine the infimum of s0 such that σs(ain + bi) < σs(cin + di) for all s ≥ s0, n ∈ N, and i = 1, 2, . . . , ℓ? We consider (IE2) in the next subsection. We show that for each s0 > 1, we can find integers a, b, c, d such that for all s ≥ s0, σs(an+b) < σs(cn+d) for an arbitrarily long string of consecutive integers n = 1, 2, . . . , M and σs(an + b) >12 P. PONGSRIIAM σs(cn + d) for all large n ≥ N. In addition, if we sacrifice the uniformity of s, we can force N to be M + 1. 2.4. The second case for |s| > 1. Theorem 2.15. The following statements hold. (i) Let s0 > 1 and M ∈ N be given. Suppose a, b, c, d are integers satisfying b ≥ 0, c ≥ 1, a > cζ(s0), and d ≥ ζ(s0)b + (M + 1)(aζ(s0) − c). Then a > c > 0, ad − bc > 0, and σs(an + b) < σs(cn + d) for all s ≥ s and n = 1, 2, . . . , M and there exists N ∈ N such that σs(an + b) > σs(cn + d) for all s ≥ s0 and n ≥ N. (ii) Let M ∈ N be given. Suppose a, b, c, d are integers satisfying c > b ≥ 1, a > 2c, d = (M +q)(a−c)+b, where q = q1/q2, 0 < q1 < q2, (q1, q2) = 1, and q2 | a − c. Then a > c > 0, ad − bc > 0, and there exists s0 > such that σs(an+b) < σs(cn+d) for all s ≥ s0 and n = 1, 2, . . . , M and σs(an + b) > σs(cn + d) for all s ≥ s0 and n ≥ M + 1. Remark 2.16. Obviously, there are infinitely many integers a, b, c, d satisfying the assumption of Theorem 2.15. So we can find as many examples for (IE2) as we like. The integer N in Theorem 2.15(i) may or may not be equal to M + 1. So (ii) does not immediately follow from (i). In addition, s0 and M in (i) are given independently while s0 in (ii) may depend on M and a, b, c, d. We do not know whether it is possible to obtain the result as in (ii) but M and s0 are independent variables. Proof of Theorem 2.15. We first prove (i). Observe that aζ(s0) − c > a − c > 0, d − b > d − ζ(s0)b > 0, ad − bc > 0, and d − b a − c ≥ d − ζ(s0)b aζ(s0) − c > M. The inequality (d − b)/(a − c) > M implies an + b < cn + d for all n ≤ M and the inequality (d − ζ(s0)b)/(aζ(s0) − c) > M leads to ζ(s0)(aM + b) < cM + d. Since ad−bc > 0, the sequence ((an+b)/(cn+d))n≥1 is increasing and therefore an + b cn + d ≤ aM + b cM + d < ζ(s0) < 1 for all n ≤ M. Hence for s ≥ s0 and n ≤ M, we obtain σs(an + b) σs(cn + d) = σs(an + b) (an + b) s an + b cn + d s (cn + d) s σs(cn + d) (2.6) ≤ ζ(s) aM + b cM + d s ≤ ζ(s0) aM + b cM + d < 1,SUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS which implies σs(an + b) < σs(cn + d). It remains to show that when n is large enough, the inequality reverse. From (2.6), we see that for s ≥ s σs(an + b) σs(cn + d) ≥ an + b cn + d s ζ(s) which converges, as n → ∞, to a c s ζ(s) > ζ(s0) s ζ(s) > 1. So there exists N ∈ N such that σs(an + b) > σs(cn + d) for all n ≥ N. This N can be chosen uniformly for all s ∈ [s0, ∞) in the sense that it depends on s0, a, b, c, d but not on s as follows. As n → ∞, we have an+b cn+d s → a c s0 > ζ(s0) s . Then there exists N ∈ N such that if n ≥ N, then an+b cn+d s > ζ(s0) s , and so for all s ≥ s0 and n ≥ N, we have an+b cn+d > 1 and σs(an + b) σs(cn + d) ≥ an + b cn + d s ζ(s) ≥ an + b cn + d s ζ(s) > ζ(s0) s ζ(s) > 1. Next, we prove (ii). The conditions on q1 and q2 make sure that q ∈ (0, 1), d ∈ Z +, and M < (d − b)/(a − c) < M + 1. It is also obvious that a > c > 0, d > b, and ad − bc > 0. Let α0 = (d − b)/b. Then bα0 = (M + q)(a − c) > c > b. So α0 > 1. Let α = min{α0, 2}. Define functions f, g : [1, α] → R by f(x) = d − bx ax − c and g(x) = dx − b a − cx . Then for x ∈ (1, α], we have dx − b > d − bx ≥ d − bα ≥ d − bα0 = d − (d − b) = b > 0 and ax − c > a − cx ≥ a − cα ≥ a − 2c > 0. Therefore 0 < f(x) < g(x) for all x ∈ (1, α] and M < f(1) = g(1) < M + 1. By using the usual method in calculus, it is easy to verify that f and g are continuous on [1, α], f is decreasing on [1, α], and g is increasing on [1, α]. Since f(1) > M, ζ(s) > 1, and ζ(s) → 1 as s → ∞, there exists a real number s1 > 1 such that ζ(s) ∈ (1, α) and f(ζ(s)) > M for all s ≥ s1. Similarly, since M + 1 > g(1), there is a real number s2 > 1 such that ζ(s) ∈ (1, α) and g(ζ(s)) < M + 1 for all s ≥ s2. Let s0 = max{s1, s2}. Then s0 > 1, ζ(s) ∈ (1, α) and M < f(ζ(s)) < g(ζ(s)) < M + 1 for all s ≥ s0. (2.7) Next, we show that σs(an + b) < σs(cn + d) for all s ≥ s0 and n ≤ M. Similar to the proof of the first part, the sequence ((an + b)/(cn + d))n≥1is increasing14 P. PONGSRIIAM and aM + b < cM + d. In addition, the inequality M < f(ζ(s)) in (2.7) implies that ζ(s)(aM + b) < cM + d. From these, we obtain, for all s ≥ s0 and n ≤ M, σs(an + b) σs(cn + d) ≤ ζ(s) an + b cn + d s ≤ ζ(s) aM + b cM + d s < ζ(s) aM + b cM + d < 1, as desired. Similarly, for s ≥ s0, we have ζ(s) < α ≤ 2, a − cζ(s) > 0, and g(ζ(s)) < M + 1, which implies ζ(s)(c(M + 1) + d) < a(M + 1) + b. Therefore, for all s ≥ s0 and n ≥ M + 1, σs(an + b) σs(cn + d) ≥ an + b cn + d s ζ(s) ≥ a(M + 1) + b c(M + 1) + d s ζ(s) > ζ(s) s−1 > 1. This completes the proof. By changing the role of a, b, c, d, we obtain the following corollary. Corollary 2.17. For each s0 > 1 and M ∈ N, there are integers a, b, c, d, N satisfying b, d ≥ 0, 0 < a < c, ad − bc < 0, N ≥ M + 1 such that σs(an + b) > σs(cn + d) for all s ≥ s0 and n ≤ M σs(an + b) < σs(cn + d) for all s ≥ s0 and n ≥ N. Furthermore, if M ∈ N is given, we can find the integers a, b, c, d and real number s0 > 1 as the above with the additional property that N can be chosen to be M+1. Example 2.18. If s0 = 2 and M = 999999, then we obtain by Theorem 2.15(i) that we can choose c = 2, b = 1, a = 5, and d = 6224673 to obtain σs(5n + 1) < σs(2n+6224673) for all s ≥ 2 and n ≤ 999999 and σs(5n+1) > σs(2n+6224673) for all s ≥ 2 and n ≥ N for some large N. Suppose M = 9999, c = 2, b = 1, a = 5, q = 1/3, and d = 29999. By the proof of Theorem 2.15(ii), we need to select s1, s2 > 1 so that d − bζ(s1) aζ(s1) − c > M and dζ(s2) − b a − cζ(s2) < M + 1, that is, ζ(s1) < 49996 and ζ(s2) < 5000149999 . We can use Wolfram Alpha to find an estimate for ζ(s) by simply writing zeta(s) and clicking enter. The decimal expansion of ζ(16) is also given as Sequence A013674 in the Online Encyclopedia of Integer Sequences. We see that we can take s1 = s2 = 16. So we choose s0 = 16 and obtain that σs(5n + 1) < σs(2n + 29999) for all s ≥ 16 and n ≤ 9999, σs(5n + 1) > σs(2n + 29999) for all s ≥ 16 and n ≥ 10000. The number s0 = 16 is not optimal but the results change when s is smaller than 13. For each s > 1, let h(s) be the smallest positive integer n such thatSUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS σs(5n + 1) > σs(2n + 29999). So h(s) = 10000 for all s ≥ 16. The values of h(2), h(3), . . . , h(15) are as follows: h(s) = 10, 000 for s ∈ {13, 14, 15, 16}, h(s) = 9999 for s ∈ {10, 11, 12}, h(9) = 9997, h(8) = 9991, h(7) = 9981, h(6) = h(5) = 9883, h(4) = 9691, h(3) = 9115, h(2) = 7207. Problem 7. From Remark 2.16, prove or disprove that if M is given and is very large, then there exists s0 > 1 such that if 1 < s ≤ s0, then there are no integers a, b, c, d satisfying a > c > 0, b, d ≥ 0, ad − bc 6= 0, σs(an + b) < σs(cn + d) for all n ≤ M and σs(an + b) > σs(cn + d) for all n ≥ M + 1. Problem 8. From Example 2.18, it may be interesting to study the behavior of the function h on (1, 16]. In general, suppose a, b, c, d, M, s0 satisfy the conditions in Theorem 2.15(ii), and h(s) is the smallest positive integer n such that σs(an+ b)−σs(cn+d) changes sign. Then h(s) = M + 1 for all s ≥ s0. Can we describe the behavior of h on (1, s0]? Recall that ⌈s⌉ is the smallest integer larger than or equal to s. Next, we construct an example for (IE3). 2.5. The third case for |s| > 1. Theorem 2.19. Let s > 0 and n = ⌈s⌉ be given. If p is a prime larger than 1 + n n+1, then σs(p − 1) > σs(p) and σs(p) < σs(p + 1). In particular, there are infinitely many m, r ∈ N such that σs(m) > σs(m + 1) and σs(r) < σr(r + 1). Proof. Suppose p > 1 + n n+1. Then σs(p + 1) ≥ 1 + (p + 1)s > 1 + ps = σs(p). For the other inequality, we observe that n/(p − 1) < 1/ n+1 and 1 + p − s ≤ 1 + p − n = Xn k= n k p − k ≤ Xn k= n p − k < Xn k= n+1 k < 1 +X∞ k= n+k = 1 + n ≤ 1 + s . Then σs(p − 1) − σs(p) ≥ 1 + ((p − 1)/2)s + (p − 1)s − 1 − p s , which is equal to (p − 1)s 1 + s − 1 + p − s > 0. Therefore σs(p − 1) > σs(p) and σs(p) < σs(p + 1), as required. Since there are infinitely many such p, we can take m = p − 1 and r = p to obtain infinitely many m, r ∈ N as desired. 16 P. PONGSRIIAM By Theorem 2.10, in order to construct an example for (IE3), it is easier (may be necessary) to consider the case a = c. Then we have a generalization of Theorem 2.19 as follows. Theorem 2.20. Suppose s > 0, a ∈ N, b, d are distinct nonnegative integers, and (a, b) = (a, d) = 1. Then there are infinitely many m, n ∈ N such that σs(am + b) < σs(am + d) and σs(an + b) > σs(an + d). Proof. The statement is symmetric with respect to b and d, so we can assume without loss of generality that b < d. Since (a, b) = 1, there are infinitely many m ∈ N such that am + b is prime, and therefore σs(am + b) = 1 + (am + b) s < 1 + (am + d)s ≤ σs(am + d). Next, let ℓ = d − b, k = ⌈s⌉, and q a prime with q ∤ aℓ. Then (ℓ, q) = (a, q) = (a, d) = 1. By Chinese remainder theorem and Dirichlet's theorem for primes in arithmetic progressions, there are infinitely many primes p such that p ≡ ℓ (mod q), p ≡ d (mod a), p > d, and p > ℓ + ℓkqk+1. For each such p, let n = np = (p − d)/a. Then σs(an + d) = σs(p) = 1 + p s , an + b = p − d + b = p − ℓ, and so σs(an + b) ≥ 1 + (p − ℓ) s + ((p − ℓ)/q)s . Then σs(an + b) − σs(an + d) ≥ (p − ℓ) s (1 + 1/qs) − p s . To show that σs(an + b) > σs(an + d), it is enough to show that 1 + 1/qs > ps/(p − ℓ) s . We have p p − ℓ s = 1 + ℓ p − ℓ s ≤ 1 + ℓ p − ℓ k = X k j= k j ℓ p − ℓ j ≤ X k j= kℓ p − ℓ j . Since kℓ/(p − ℓ) < 1/qk+1, the above is less than 1 + q k+1 + q k+2 + q k+3 + · · · = 1 + (q − 1)q k ≤ 1 + q k ≤ 1 + q s . So the proof is complete. Problem 9. Suppose s > 1 and a, b, c, d are positive integers. If σs(an + b) − σs(cn + d) changes sign infinitely often, is it true that a = c? If it is not true, assuming further that s is large and (a, b) = (c, d) = 1, can we conclude that a = c? Problem 10. By Theorem 2.4, σ(30n + 1) − σ(30n) has infinitely many sign changes but it may be interesting to know more about this. For example, is itSUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS true that (i) X n≤m σ(30n+1)<σ(30n) 1 > X n≤m σ(30n+1)>σ(30n) 1 for all m ∈ N? Is it true that (ii) X n≤m σ(30n) > X n≤m σ(30n + 1) for all m ∈ N? Numerical evidence suggests that they are true but we currently do not have a proof. If they are not true, do the sign reverse for infinitely many m? We can replace 30n + 1 and 30n by an + b and cn + d and we can also change σ to σs, or any other function of interest. Perhaps, it is true that (iii) X n≤m σ(30n+1)<σ(30n) n > X n≤m σ(30n+1)>σ(30n) n . Maybe, the left-hand side of (iii) divided by log m is closed to 1 as m → ∞ while the right-hand side of (iii) divided by log m is closed to 0 as m → ∞. This question is motivated by those on primes. So it should be useful to read, for example, the articles by Bays and Hudson [2], Knapowski and Turan [10, 11, 12], and Meng [16]. See also [20, 25, 26] and some of our future articles for more information on palindromes and the comparison between the number of palindromes in different bases. Problem 11. Let Js and ϕs be the arithmetic functions that are defined for all n ∈ N by Js(n) = n s Y p|n 1 − p s and ϕs(n) = X 1≤m≤n (m,n)= ms. So J1(n) = ϕ(n) = ϕ0(n) and therefore Js and ϕs are generalizations of the Euler function ϕ. What are the corresponding results for Js(an + b), Js(cn + d), ϕs(an+b), and ϕs(cn+d). There are other generalizations of ϕ which may be of interest. The inequalities related to σs, ϕs, and Js over the Fibonacci numbers are also investigates in [6, 14]. For some recent articles related to divisibility properties of the Fibonacci numbers, see for example in [18, 19, 21]. Problem 12. We already showed that the following three cases may occur: (i) σs(an + b) − σs(cn + d) never changes sign, (ii) σs(an + b) − σs(cn + d) changes sign exactly once, (iii) σs(an + b) − σs(cn + d) changes sign infinitely many times.18 P. PONGSRIIAM Is it possible to construct an example for which σs(an + b) − σs(cn + d) changes sign exactly two times? If k is a given positive integer, can we find s ∈ R, a, b, c, d ≥ 0 such that there are exactly k sign changes in σs(an+b)−σs(cn+d)? We can replace σ by ω and Ω and obtain the same results in Theorem 2.4. Here ω(n) is the number of distinct prime divisors of n and Ω(n) is the number of prime powers dividing n. We record it as a theorem. Theorem 2.21. Let a, b, c, d satisfy the condition (A). Then there exists a strictly increasing sequence (nk) of positive integers such that (i) lim k→∞ ω(ank + b) ω(cnk + d) = lim k→∞ Ω(ank + b) Ω(cnk + d) = 0. In particular, (ii) lim inf n→∞ ω(an + b) ω(cn + d) = lim inf n→∞ Ω(an + b) Ω(cn + d) = 0; (iii) lim sup n→∞ ω(an + b) ω(cn + d) = lim sup n→∞ Ω(an + b) Ω(cn + d) = ∞. Proof. We construct the sequence (nk) in exactly the same way as in the proof of Theorem 2.4. Then ω(ank + b) = ω(δqk) ≤ 1 + ω(|ad − bc|), Ω(ank + b) = Ω(δqk) ≤ 1 + Ω(|ad − bc|), ω(cnk + d) = ω(mkyk) ≥ ω(mk) → ∞ as k → ∞, Ω(cnk + d) = Ω(mkyk) ≥ Ω(mk) → ∞ as k → ∞. These imply the desired results. Problem 13. We can extend the functions ω and Ω by defining ωs(n) = X p|n p s and Ωs(n) = X pkkn kpsfor all n ∈ N. What are the corresponding results for ωs and Ωs over arithmetic progressions? Some results on ω(Fn) and ω(Ln) are obtained in [3] and [24]. Problem 14. It may be interesting to compare f(Aan+b) and f(Acn+d), where f is an arithmetic function and (An)n≥1 is an integer sequence which is of interest. For example, suppose Fn is the nth Fibonacci number, can we say anything about the behavior of σs(Fan+b) and σs(Fcn+d)? The order (or rank) of appearance of n in the Fibonacci sequence, denoted by z(n), is the smallest positive integer m such that n | Fm. The function z is not multiplicative but isSUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS closed to being multiplicative because z(lcm[m, n]) = lcm[z(m), z(n)], and so z(p a p a · · · p ak k ) = lcm[z(p a ), z(p a ), . . . , z(p ak k )], where p1, p2, . . . , pk are distinct primes and a1, a2, . . . , ak are positive integers. Can we compare z(an+b) and z(cn+d)? Some formulas concerning z(n) when n is of special forms are shown in [9, 22, 23] and in the references of these articles. We may also replace z by any other interesting arithmetic functions. Problem 15. Define σs(n, q, a) by σs(n, q, a) = X d|n d≡a (mod q) d s . What are the results on the inequalities between σs(n, q, a1) and σs(n, q, a2)? For example, if q = 2, we consider the inequalities between the sum of odd divisors of n and even divisors of n. Are there an infinite number of sign changes in σs(n, 2, 0) − σs(n, 2, 1) or in P n≤x σs(n, 2, 0) − P n≤x σs(n, 2, 1)? The answers may generally depend on s, n, q, a. We can define ωs(n, q, a) and Ωs(n, q, a) in a similar way. For some results in this direction, see for example in the work of Khan [8], Liu, Shparlinski, and Zhang [13], Meng [16] and Pongsriiam and Vaughan [27, 28, 29], and references therein. If we are interested in other kinds of divisors, we may consider the comparison between the sums of those divisors. Define σs,A(n) = P d∈A(n) d s for all n ∈ N, where A(n) is, for example, the squarefree divisors of n or the unitary divisors of n. There are many other possible research problems. We leave them to the reader's imagination. Acknowledgements. This project is funded by the National Research Council of Thailand (NRCT), Grant Number NRCT5-RSA63021-02. References [1] J. M. Aldaz, A. Bravo, S. Guti´errez, and A. Ubis, A theorem of D. J. Newman on Euler's ϕ function and arithmetic progressions, Amer. Math. Monthly, 108 (2001), 364–367. [2] C. Bays and R. H. Hudson, A new bound for the smallest x with π(x) > Li(x), Math. Comp., 69 (2000), 1285–1296. [3] Y. Bugeaud, F. Luca, M. Mignotte, and S. Siksek, On Fibonacci numbers with few prime divisors, Proc. Japan Acad. Ser. A Math Sci., 81 (2005), 17–20. [4] J. M. De Koninck and F. Luca, Arithmetic functions monotonic at consecutive arguments, Stud. Sci. Math. Hung., 51(2) (2014), 155–164. [5] D. A. Goldston, S. W. Graham, J. Pintz, and C. Y. Yildirim, Small gaps between almost primes, the parity problem, and some conjecture of Erd¨os on consecutive integers, Int. Math. Res. Notices, 7 (2011), 1439–1450. [6] M. Jaidee and P. Pongsriiam, Arithmetic functions of Fibonacci and Lucas numbers, Fibonacci Quart., 57(3) (2019), 246–254. [7] D. Jarden, Recurring Sequences, Riveon Lematematika, Jerusalem, 1973.20 P. PONGSRIIAM [8] R. Khan, The divisor function in arithmetic progressions modulo prime powers, Mathematika, 62 (2016), 898–908. [9] N. Khaochim and P. Pongsriiam, On the order of appearance of products of Fibonacci numbers, Contrib. Discrete Math., 13(2) (2018), 45–62. [10] S. Knapowski and P. Turan, Comparative prime number theory VIII, Acta Math. Acad. Sci. Hung., 14 (1963), 251–268. [11] S. Knapowski and P. Turan, Further developments in the comparative prime number theory VI, Acta Arith., 12 (1966), 85–96. [12] S. Knapowski and P. Turan, Further developments in the comparative prime number theory VII, Acta Arith., 21 (1972), 193–201. [13] K. Liu, I. Shparlinski, and T. Zhang, Divisor problem in arithmetic progressions modulo a prime power, Adv. Math., 325 (2018), 459–481. [14] F. Luca, Arithmetic functions of Fibonacci numbers, Fibonacci Quart., 37(3) (1999), 265–268. [15] G. Martin, The smallest solution of φ(3n + 1) < φ(30n) is . . ., Amer. Math. Monthly, (1999), 449–451. [16] X. Meng, Number of prime factors over arithmetic progressions, Q. J. Math., 71(1) (2020), 97–121. [17] D. J. Newman, Euler's φ function on arithmetic progressions, Amer. Math. Monthly, (1997), 256–257. [18] K. Onphaeng and P. Pongsriiam, Exact divisibility by powers of the integers in the Lucas sequence of the first kind, AIMS Math., 5(6) (2020), 6739–6748. [19] K. Onphaeng and P. Pongsriiam, Exact divisibility by powers of the integers in the Lucas sequences of the first and second kinds, AIMS Math., 6(11) (2021), 11733–11748. [20] P. Phunphayap and P. Pongsriiam, Reciprocal sum of palindromes, J. Integer Seq., 22(8) (2019), Article 19.8. [21] P. Phunphayap and P. Pongsriiam, Explicit formulas for the p-adic valuations of Fibonomial coefficients II, AIMS Math., 5(6) (2020), 5685–5699. [22] P. Pongsriiam, A complete formula for the order of appearance of the powers of Lucas numbers, Commun. Korean Math. Soc., 31(3) (2016), 447–450. [23] P. Pongsriiam, The order of appearance of factorials in the Fibonacci sequence and certain Diophantine equations, Period. Math. Hungar., 79(2) (2019), 141–156. [24] P. Pongsriiam, Fibonacci and Lucas numbers which have exactly three prime factors and some unique properties of F18 and L18, Fibonacci Quart., 57(5) (2019), 130–144. [25] P. Pongsriiam, Longest arithmetic progressions of palindromes, J. Number Theory, (2021), 362–375. [26] P. Pongsriiam and K. Subwattanachai, Exact formulas for the number of palindromes up to a given positive integer, Int. J. Math. Comput. Sci., 14(1) (2019), 27–46. [27] P. Pongsriiam and R. C. Vaughan, The divisor function on residue classes I, Acta Arith., 168(4) (2015), 369–381. [28] P. Pongsriiam and R. C. Vaughan, The divisor function on residue classes II, Acta Arith., 182(2) (2018), 133–181. [29] P. Pongsriiam and R. C. Vaughan, The divisor function on residue classes III, Ramanujan J., accepted, online first version available at https://link.springer.com/article/10.1007/s11139-020-00288-5SUMS OF DIVISORS ON ARITHMETIC PROGRESSIONS Department of Mathematics Faculty of Science, Silpakorn University Nakhon Pathom THAILAND Email address: prapanpong@gmail.com, pongsriiam p@silpakorn.edu\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper ID: 0702190v3\n",
      "\n",
      "Abstract: In this article we investigate the possibility of encoding classical\n",
      "information onto multipartite quantum states in the distant laboratory\n",
      "framework. We show that for all states generated by Clifford operation there\n",
      "always exist such an encoding, this includes all stabilizer states such as\n",
      "cluster states and all graph states. We also show encoding for classes of\n",
      "symmetric states (which cannot be generated by Clifford operations). We\n",
      "generalise our approach using group theoretic methods introducing the unifying\n",
      "notion of Pseudo Clifford operations. All states generated by Pseudo Clifford\n",
      "operations are locally encodable (unifying all our examples), and we give a\n",
      "general method for generating sets of many such locally encodable states.\n",
      "\n",
      "Clean Text: \n",
      "1. Choose a set of Pauli generators {gi} n i=1 for the zero state |¯0i. 2. Construct a hermitian commutative set L defined by Eq. (23) associated with the generators {gi} n i=1. 3. Construct a Lie group SUL from the Lie subalgebra L. We call the Lie group SUL a Pauli encoder group. 4. For an arbitrary Clifford operation C and an arbitrary Z ∈ SUL, we obtain a Pauli encodable state CZ |¯0i and a Pauli encoder h{CgiC †}n i=1i. In general the difficulties arise in step ii) – not all generator sets will allow for a nice construction of L (23). We show two concrete constructions for the Pauli encodable states for given Pauli encoders in the followings. If the generator set is given by {gi = I ⊗(i−1) ⊗ X ⊗ I⊗(n−i)}, we have the hermitian commutative set L defined by L = {w ¯ i ≡ Xi1 ⊗ Xi2 ⊗ · · · ⊗ Xin , i := i1i2 · · ·in ∈ Z n 2 }, (24) as used earlier. Thus, an element Z ∈ SUL is given by Z = exp[i X i∈Z n ciw ¯ i ], (ci ∈ C). (25) Therefore, with an arbitrary Clifford operation C, a Pauli encodable state is given by C exp[i X i∈Z n ciw ¯ i ] |¯0i, (26) and the corresponding Pauli encoder set is given by h{C · (I ⊗(i−1) ⊗ X ⊗ I⊗(n−i )) · C † } n i=1i. (27) If the generator is given by {gi = Z ⊗(i−1) ⊗ X ⊗ I⊗(n−i)}n i=1, we have the hermitian commutative set L defined by L = h{qi ≡ I ⊗(i−1) ⊗ X ⊗ Z⊗(n−i) } n i=1i. (28) Thus, an element Z ∈ SUL is given by Z = exp[i Xn i= ciqi] |¯0i, (ci ∈ C), (29) and, with an arbitrary Clifford operation C, a Pauli encodable state is given by C exp[i Xn i= ciqi] |¯0i (30) where we take q0 = I ⊗n. The corresponding Pauli encoder is given by h{C · (Z ⊗(i−1) ⊗ X ⊗ I⊗(n−i) ) · C † } n i=1i. (31) We see that the symmetric basis state represented by Un,1 of Eq. (14) is a special case of Eq. (30).Local encoding of classical information onto quantum states V. CONCLUSION AND DISCUSSION In this work we have looked at the possibility of encoding classical information onto quantum states by local unitary operations. We have presented explicit encodings for large sets of states including all stabiliser and various symmetric basis states. We have introduced the notion of Pseudo Clifford which unifies these states under one general local encoding method. Finally, by resorting to group theoretic analysis we have given a method to find large sets of states with the same local encodings. Although the methods used for local encoding presented here are not as general as possible, they do cover many interesting sets of states. It seems to be a difficult problem to describe the extent to which states are covered by our encoding strategies. It remains an open problem wether all states are locally encodable at all. We may also be interested in different ways of local encoding for other reasons and applications. For example in dense coding [4, 11] we wish to encode the information by acting on only a subset of the parties (the idea being that then by sending that same subset through a quantum channel, we can communicate more information than the that allowed by the Holevo bound). The local encoding presented here could not be used for such a protocol. We can then ask can we extend these results to consider such protocols, or what can our results say about when we can or cannot. For example, we know that for optimum dense coding, we must have a maximally entangled state between the senders and receivers. Imagine we try to dense code using the state |ψi = √ 2n− P n− i=0 U|iis ⊗ |iir ∈ H⊗n ⊗ H⊗n, where |iix are the product states of the computational basis over the senders' and receivers' spaces for subscripts s and r respectively, and U acts on S only. The Schmidt basis on the side of the senders (subscript s) is in general entangled across the set of senders by unitary U. If U is just identity, then we can encode simply using the Pauli operators [11]. Surprisingly we can see that the senders can still encode the full basis locally, independent of U. This can be easily shown, since for optimal dense coding, we would require hψ| v † i ⊗I · vj ⊗I |ψi = δij for all i, j. It is easy to see that the U drops out and the condition is equivalent to simply T r[v † i vj ] = 0. This is satisfied for the local Pauli, hence they allow dense coding for these states. Thus maximum entangled states can be always optimally locally dense coded independent of the Schmidt basis. The same result can be obtained by using the Choi-Jamiolkowski isomorphism [12] by bringing the unitary over to the receiver's side |ψi = √ 2n− P n− i=0 U|iis ⊗ V |iir = √ 2n− P n− i=0 |iis ⊗ U T V |iir. In this way it is clear that the standard Pauli approach will work from [11]. We can also note that some of the states considered here have mirror results in local decoding. It is known that the ability to decode such encoded classical information is bounded by the entanglement [13], and explicit bounds are given for W-states and large sets of graph states (which, in the case of graph states, can be made tight [14]). We can thus compare the amount of information we can encode to that we can decode ∆Ilocal = Ilocal encodable−Ilocal decodable. For graph states this gives ∆Ilocal = E(|ψi) = n/2 (where E is the geometric measure of entanglement [15]). Indeed, from [14] for all states where we can locally encode we have ∆Ilocal ≥ E(|ψi). This allows us to talk about a kind of irreversibility of local information - we can encode much easier than decode locally, and the difference is bounded by the entanglement. It is interesting to consider what such a quantity would mean in relation to other tasks such as measurement based quantum computing, error correction e.t.c. We see then that there are many open questions remaining, and that these results may have potential interest in various areas of quantum information processing and studies of locality. In addition we may also consider the usefulness of the task directly in many-party quantum cryptographic scenarios where we have distributed encoders and decoders. These will be the topics of ongoing study. Acknowledgements We are very grateful to Akimasa Miyake, Shashank Virmani, Masaki Owari, Toshio Ohshima and Terry Rudolph for stimulating discussions on this topic. This work was sponsored by the Asahi Glass Foundation and the Japan Society for the Promotion of Science. [1] C. H. Bennett and G. Brassard. 1984. in Proc. IEEE International Conference on Computers, Systems, and Signal Processing, Bangalore, India (IEEE, New York, 1984). [2] A. Ekert. Phys. Rev. Lett., 67(661), 1991. [3] C. H. Bennett, G. Brassard, C. Crepeau, R. Jozsa, A. Peres, and W. K. Wootters. Phys. Rev. Lett, 70(1895), 1993. [4] C. H. Bennett and S. Weisner. Phys. Rev. Lett, 69(2881), 1992. [5] R. Raussendorf and H. J. Briegel. Phys. Rev. Lett., 86(5188), 2001.Local encoding of classical information onto quantum states [6] C. H. Bennett, D. P. DiVincenzo, C. A. Fuchs, T. Mor, E. Rains, P. W. Shor, J. A. Smolin, and W. K. Wootters. Phys. Rev. A, 59(1070), 1999. [7] C. H. Bennett, D. P. DiVincenzo, T. Mor, P. W. Shor, J. A. Smolin, and B. M. Terhal. Phys. Rev. Lett., 82(5385), 1999. [8] M. Hein, W. D¨ur, J. Eisert R. Raussendorf, M. Van den Nest, and H. J. Briegel. 2005. quant-ph/0602096. [9] M. A. Nielsen and I. L. Chuang. Quantum Computation and Quantum Information. Cambridge University Press, 2000. [10] A. Miyake and H. J. Briegel. Phys. Rev. Lett., 95(220501), 2005. [11] D. Bruß, G. M. D'Ariano, M. Lewenstein, C. Macchiavello, A. Sen(De), and U. Sen. Phys. Rev. Lett., 93(210501), 2004. [12] M.-D Choi Lin. Alg. Appl., 10 (285), 1975; A. Jamiolkowski Rep. Math. Phys., 3 (275), 1972. [13] M. Hayashi, D. Markham, M. Murao, M. Owari, and S. Virmani. Phys. Rev. Lett., 96(040501), 2006. [14] D. Markham, A. Miyake, and S. Virmani. 2006. quant-ph/0609102. [15] A. Shimony, Ann. NY. Acad. Sci 755, 675 (1995); H. Barnum and N. Linden, J. Phys. A 34, 6787 (2001); A. Miyake and M. Wadati, Phys. Rev. A 64, 042317 (2001); T.-C. Wei and P. M. Goldbart, Phys. Rev. A 68, 042307 (2003).\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper ID: 0011028v1\n",
      "\n",
      "Abstract: Under the mild condition of continuity at a single point we describe all the\n",
      "bijections of the set of all partial isometries on a Hilbert space which\n",
      "preserve the order and the orthogonality in both directions. Moreover, we\n",
      "present a natural analogue of Wigner's theorem on quantum mechanical symmetries\n",
      "for the set of all rank-1 partial isometries.\n",
      "\n",
      "Clean Text: \n",
      "1. G. Cassinelli, E. De Vito, P.J. Lahti and A. Levrero, Symmetry groups in quantum mechanics and the theorem of Wigner on the symmetry transformations, Rev. Math. Phys. 9 (1997), 921–941. 2. T. Dang, Y. Friedman and B. Russo, Affine geometric proofs of the Banach Stone theorems of Kadison and Kaup, Rocky Mountain J. Math. 20 (1990), 409–428. 3. L. Moln´ar, A generalization of Wigner's unitary-antiunitary theorem to Hilbert modules, J. Math. Phys. 40 (1999), 5544–5554. 4. L. Moln´ar, Generalization of Wigner's unitary-antiunitary theorem for indefinite inner product spaces, Commun. Math. Phys. 201 (2000), 785–791. 5. L. Moln´ar and P. Semrl, ˇ Order isomorphisms and triple isomorphisms of operator ideals and their reflexivity, Arch. Math. 69 (1997), 497–506. 6. M. Omladiˇc and P. Semrl, ˇ Additive mappings preserving operators of rank one, Linear Algebra Appl. 182 (1993), 239–256. Institute of Mathematics and Informatics, University of Debrecen, Debrecen, P.O.Box 12, Hungary E-mail address: molnarl@math.klte.hu\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper ID: 0610007v2\n",
      "\n",
      "Abstract: Explicit bases for the spaces of holomorphic cusp forms of all even positive\n",
      "weights and all orders are constructed. The dimensions of these spaces are\n",
      "computed.\n",
      "\n",
      "Clean Text: \n",
      "1. Introduction In this paper we establish the complete classification of cusp forms of all orders. Higher-order cusp forms constitute a natural extension of the notion of classical cusp forms and they have attracted the interest of several researchers in the broader area of automorphic forms during the last few years. Reasons for this interest include its relevance for new approachesto problems related to the distribution of modular symbols ([CDO]), to GL(2) L-functions ([DKMO], [F]), to percolation theory ([KZ]) and, more recently, to Manin's non-commutative modular symbols ([M]) via the connection of higher-order forms with iterated integrals ([DS]). This approach has already yielded striking successes, e.g. the proof that modular symbols have a normal distribution ([PR]), the establishment of higher order Kronecker limit formulas ([JO]) etc. The first step towards a classification of spaces of higher-order cusp forms was taken in [DO], where the case of order 2 was settled. Unexpectedly, the classification of higher weights proved to be far from routine and it seems that ultimately this is related to difficulties to identify the underlying cohomology in orders higher than 2. Indeed, we have not found yet an Eichler-Shimura-type theorem similar to that proved in [DO]. However, in this work we succeed in computing the dimensions of the spaces of higher-order forms and in constructing explicit bases that are fully computable. The first two sections deal with technical preliminaries some of which have independent interest (e.g. the growth estimates for antiderivatives of higher-order cusp forms). The basic theorem, establishing the analytic continuation and growth properties of the generalized Poincar´e series on which the basis elements is built, is proved in section 3.2. It is based on a quite large scale induction which relies crucially on the spectral analysis of a certain Poincar´e-type series. The basis elements are constructed in Sections 3.3 and 3.4, where it is also proved that they are actually a basis of the space of weight higher-order cusp forms. In section 4 we contruct bases for higher-order cusp forms of higher weight. 2. Definitions and basic estimates Let Γ ⊂ P SL2(R) be a Fuchsian group of the first kind acting on the upper half plane H with non compact quotient Γ\\H of genus g. We assume that there are m ≥ 2 inequivalent cusps. As usual we write x + iy = z ∈ H and H ∗ for H together with the cusps. Let dµz be the hyperbolic volume form dxdy/y2 and V = Z Γ\\H dxdy y the volume of Γ\\H. For a fundamental domain F fix representatives of the inequivalent cusps in F and give them labels such as a, b. Use the corresponding scaling matrices σa, σb to give convenient local coordinates near these cusps as in [I1], Ch 2. The subgroup Γa is the set of elements of Γ fixing a and σa −1Γaσa = Γ∞ = n ± 1 m 0 m ∈ Z o . Typeset by AMS-TEX 1The slash operator |k defines an action of P SL2(R) on functions f : H 7→ C by (f|kγ)(z) = f(γz)(cz + d) −k with γ = ∗ ∗ c d ∈ P SL2(R). Extend the action to C[P SL2(R)] by linearity. We set j(γ, z) = cz + d. We now define the space S t k (Γ) of cusp forms of order t and weight k ≥ 0 recursively by setting: (i) S k (Γ) = {0} and (ii) for t ≥ 1, by letting S t k (Γ) be the space of holomorphic functions f : H → C such that: 1. f|k(γ − 1) ∈ S t− k (Γ), for all γ ∈ Γ, 2. f|kπ = f, for all parabolic π ∈ Γ and 3. for each cusp a, (f|kσa)(z) ≪ e −cy as y → ∞ uniformly in x for some constant c > 0 (\"vanishing at the cusps\"). When the group is clear, we will be using S t k instead of S t k (Γ). A useful reformulation of this definition, essentially proved in [DKMO] is that a holomorphic f : H → C is a t-th order cusp form if and only if it is invariant under the parabolic elements, it satisfies f|k(γ1 − 1). . .(γt − 1) = 0 for all γi ∈ Γ and, for each γ ∈ Γ and each cusp a, (f|kγσa)(z) ≪ e −cy as y → ∞ uniformly in x with c > 0 and the implied constant depending on γ. Further, by relaxing the third condition to include functions such that, for each cusp a, (f|kσa)(z) ≪ y c as y → ∞ uniformly in x for some constant c, we obtain the space of t-th order modular forms. We denote it by Mt k . The next lemma is stated in greater generality than what we need it for in the sequel because we want it to cover other situations that have arisen in our work. We define recursively certain sets of maps denoted by Ht. First, for convenience we use the superscripts + and − to indicate absence and presence of complex conjugation respectively. We set (i) H0 = H1 = {0} and (ii) for t > 1, we set Ht := M r+s≤t 1≤r,s≤t− Hr ⊗ S s where Hr ⊂ M aps(Γ, C) is generated by maps of the form γ → Ym i= Z γzi zi fi(w)dw± for some zi ∈ H ∗ with fi ∈ S ri such that fi|2(· − 1) ∈ Hri and Pm i=1 ri = r. (Here and in the sequel we will take sums whose upper limit is smaller than the lower to be equal to 0.) We identify each of these spaces with their images in M aps(Γ, St− ) under the natural projection. With this notation we can now state a proposition that gives important estimates for derivatives and anti-derivatives of weight 2 cusp forms of all orders. Lemma 2.1. For all t ≥ 0, if f ∈ S t satisfies f|2(· − 1) ∈ Ht then, for any cusp a, (i) Im(z)|f(z)| ≪ Xt− i= | log(Im(z))| i (ii) Z z z f(w) dw ≪ Xt j= | log(Im(σa − z))| j and (iii) Z γz z f(w) dw ≪ X i+j≤t 0≤i,j | log(Im(σa − z))| i | log(Im(σa − γz))| j 2for all z ∈ H. The implied constants are independent of z and γ. Proof: We will use induction on t. For t = 0, it is trivial. Let now t > 0. Assume the result holds for orders < t and let f ∈ S t satisfy f|2(· − 1) ∈ Ht. To prove (i), let F∞ be the strip of (x, y) with y > 0 and |x| ≤ 1/2 and F the fundamental domain consisting of z ∈ F∞ such that |j(γ, z)| > 1 for all γ ∈ Γ − Γ∞. Then Im(z)|f(z)| ≪ 1 in F because f has exponential decay at each cusp. If, on the other hand, z ∈ F∞ −F, then there is γ ∈ Γ−Γ∞ and w ∈ F such that z = γw. According to Lemma 1.25 of [Sh], there is a r > 0 depending only on Γ such that Im(w) ≤ 1/(r Im(z)). On the other hand, since w ∈ F, Im(z) <Im(w). Therefore, log(Im(z)) < log(Im(w)) ≤ −2 log(r) − log(Im(z)) and hence | log(Im(w))| ≤ 2| log(r)| + | log(Im(z))|. (2.1) Now, if (f|2(γ − 1))(z) = X ′ Ym i= ( Z γzi zi hi(w)dw) ±h0(z) (2.2) where the prime indicates that the summation is over (h1, . . . , hm, h0) ∈ S l 2 × · · · × S lm 2 × S l (l1 + · · · + lm + l0 ≤ t) with hi|2(· − 1) ∈ Hli(i > 0), then |Im(z)f(z)| = |Im(w)(f|2γ)(w)| ≤ |Im(w)f(w)| + X ′ | Ym i= Z γzi zi hi(w)dw||Im(w)h0(w)|. With the boundedness of Im(z)|f(z)| in F and the inductive hypothesis, we deduce that |Im(z)f(z)| ≪ 1 +X ′ Ym n= X i+j≤ln 0≤i,j | log(Im(w))| i | log(Im(γw))| j l X0− i= | log(Im(w))| i with the implied constant independent of w and γ. With (2.1) this implies |Im(z)f(z)| ≪ 1 +X ′ Ym n= X i+j≤ln 0≤i,j | log(Im(z))| i+j l X0− i= | log(Im(z))| i ≪ Xt− i= | log(Im(z))| i for z ∈ F∞ − F and thus for all z ∈ H because both sides of (i) are translation invariant. To prove (ii), we first note that Z σaz z f(w) dw = Z z σa −1z (f|2σa)(w) dw. Since f|2σa(σa −1γσa − 1) = f|2(γ − 1)σa, an inductive argument implies that f|2σa ∈ St (Γ′) with Γ ′ := σ − a Γσa. In fact, a similar argument implies that f|2σa(· − 1) ∈ Ht(Γ′ ). Therefore, we can use (i) to deduce Im(z)|(f|2σa)(z)| ≪ Xt− i= | log(Im(z))| i Further the invariance under the parabolic elements gives Z z+ z (f|2σa)(w) dw = 0. Therefore, Z σaz z f(w) dw ≪ Z x+iy σ − a z log(Imw) t−1 + · · · + Im(w) dw 3with y =Imz and x ≡Rez mod 1 and 0 ≤ x < 1. The last integral equals Z x+iIm(σa − z0) σ − a z + Z x+iy x+iIm(σa −1z0) log(Imw) t−1 + · · · + Im(w) dw where the integration path is, in both cases, a straight segment. This sum in turn equals: log(Im(σa − z0))t−1 + · · · + Im(σa −1z0) (x − Re(σa − z0)) + i Z y Im(σa −1z0) log(s) t−1 + · · · + s ds ≪ Xt j= (log(Imz))j Replacing z by σ − a z completes the proof of (ii). Finally, by employing (2.2) it is easy to see that Z γz z f(w)dw = Z γz z f(w)dw − Z z z f(w)dw + X ′ Ym i= ( Z γzi zi hi(w)dw) ± Z z z h0(w)dw (2.3) where the summation is over (h1, . . . , hm, h0) ∈ S l 2 × · · · × S lm 2 × S l , (l1 + · · · + lm + l0 ≤ t) with hi|2(· − 1) ∈ Hli, (i > 0) and the inequality follows from (ii) and the inductive hypothesis. 3. Bases for S t (Γ) 3.1 Preliminaries We collect here some notation and results we will be using frequently in the sequel. Let C∞(Γ\\H, k) denote the space of smooth functions ψ on H that transform as ψ(γz) = ε(γ, z) kψ(z) for γ in Γ and ε(γ, z) = j(γ, z)/|j(γ, z)|. Note that this notion of weight in general differs from the previous definition of weight. We define the Maass raising and lowering operators by Rk = 2iy d dz + k , Lk = −2iy d dz¯ − k . It is an elementary exercise to show that Rk : C ∞(Γ\\H, k) → C∞(Γ\\H, k + 2), Lk : C∞(Γ\\H, k) → C∞(Γ\\H, k − 2). For n > 0, we write Rn for Rk+2n−2 · · · Rk+2Rk and L n for Lk−2n+2 · · ·Lk−2Lk. We also let L0 and R0 be the identity operator. A very useful fact proved in [JO] (Lemma 9.2) is that if γ ∈PSL2(R) and µ(s, k, F) := F(γ)Im(γz) s e(mγz)ε(γ, z) −k then Rkµ(s, k, F) = 2iµ(s + 1, k + 2, d dz F) + (s + k )µ(s, k + 2, F) − 4πmµ(s + 1, k + 2, F) Lkµ(s, k, F) = −2iµ(s + 1, k − 2, d dz¯ F) + (s − k )µ(s, k − 2, F) (3.1) 4The hyperbolic Laplacian ∆ = −4y 2 d/dz d/dz can be realized as ∆ = −L2R0 = −R−2L0. Further, for τ ∈ P SL2(R), we let the operator θτ,k : C∞(Γ\\H, k) → C∞(τ −1Γτ\\H, k) be defined by θτ,kψ(z) = ψ(τz) ε(τ, z) k . It is easy to verify that this action commutes with the raising and lowering operators: θτ,k−2Lk = Lkθτ,k, θτ,k+2Rk = Rkθτ,k. In stating our bounds, the notation yΓ(z) = maxa(maxγ∈Γ(Im(σa −1γz))) will often be useful. For example, if |ψ| is smooth with weight 0 then we write ψ(z) ≪ yΓ(z) A, instead of ψ(σaz) ≪ yA for each cusp a as y → ∞. We also use the notation yF(z) = maxa(Im(σa − z)) for z in a fundamental domain F. We next recall that the usual non-holomorphic Eisenstein series Ea(z, s) = X γ∈Γa\\Γ Im(σa − γz) s is absolutely convergent for s with Re(s) > 1 (and uniformly convergent for s in compact sets there) and that it has the Fourier expansion at the cusp b Ea(σbz, s) = δaby s + φab(s)y1−s + X m6= φab(m, s)Ws(mz) = δaby s + φab(s)y1−s + O(e−2πy) (3.2) as y → ∞ with an implied constant depending only on s and Γ. The hyperbolic Laplacian operates on L (Γ\\H) the space of smooth, automorphic, square integrable functions. Any element ξ of L (Γ\\H) may be expanded according to the discrete and continuous spectrum of ∆ (Roelcke-Selberg decomposition): ξ(z) = X∞ j= hξ, ηj iηj (z) + 4π X b Z ∞ −∞ hξ, Eb(·, 1/2 + ir)iEb(z, 1/2 + ir) dr, (3.3) where {ηj} denotes a complete orthonormal basis of Maass forms, with corresponding eigenvalues λj = sj (1 − sj ), which forms the discrete spectrum. As always, we will write sj = σj + itj, chosen so that σj > 1/2 and tj > 0, and we enumerate the eigenvalues, counted with multiplicity, by 0 = λ0 < λ1 6 λ2 6 · · · . Weyl's law ((11.3) of [I1]) implies #{j| |λj | 6 T } ≪ T. (3.4) The decomposition (3.3) is absolutely convergent for each fixed z and uniform on compact subsets of H, provided ξ and ∆ξ are smooth and bounded (see, for example, Th. 4.7 and Th. 7.3 of [I1]). For each j, the Fourier expansion of ηj is ηj (σaz) = ρaj (0)y 1−sj + X m6= ρaj (m)Wsj(mz). (3.5) For all but finitely many of the j (corresponding to λj < 1/4) we have σj = 1/2 and ρaj (0) = 0. The constant δΓ used throughout this paper is chosen so that 1 − δΓ > σ1 > 1/2. With this notation we now state 5Lemma 3.1. For all z ∈ H, T ∈ R and n ∈ Z+ we have (i) R n ηj (z) , Ln ηj (z) ≪Γ,n (|tj | n + 1)yΓ(z)1/2 + (|tj |2n+5 + 1)yΓ(z)−3/ (ii) Ea(z, 1/2 + ir) ≪ Γ,T yΓ(z) 1/ for all r ∈ [T, T + 1] (iii) Z T + T |R nEa(z, 1/2 + ir)| dr, Z T + T |L nEa(z, 1/2 + ir)| dr ≪ T 4n+12yΓ(z) Proof: For a proof of see Lemma 8.2, (11.12) and Lemma 8.3 of [DO] respectively. We now define the basic auxiliary functions we will be using in the sequel and prove their basic properties. For k ∈ 2Z, we consider Uam(z, s, k) = X γ∈Γa\\Γ Im(σa − γz) s e(mσa − γz)ε(σa − γ, z) −k and for simplicity we set Uam(z, s) := Uam(z, s, 0). By a direct computation based on (3.1) RkUam(z, s, k) = (s + k/2)Uam(z, s, k + 2) − 4πmUam(z, s + 1, k + 2) (3.6) LkUam(z, s, k) = (s − k/2)Uam(z, s, k − 2). (3.7) Proposition 3.2. For k ∈ 2Z, Uam(z, s, k) has a meromorphic continuation to all s with Re(s) > 1 − δΓ its only pole appearing at s = 1 when m = k = 0. It is simple with residue 1/V . Furthermore, Ua0(z, s, k) ≪ yΓ(z) σ and Uam(z, s, k) ≪ yΓ(z) 1/ (m > 0) for these s with the implied constant depending on s, m, k, Γ. Proof: This is the content of Propositions B and C of [DO]. Given this analytic continuation we set Pam(z)2 := y −1Uam(z, 1, 2), These series are holomorphic for m > 0 and span S2(Γ) (cf. [JO] Th. 3.2). When m = 0 they satisfy j(σb, z) −2Pa0(σbz)2 = δab − yV + O(e −2πy) as y → ∞ (3.8) and y d dz Pa0(z)2 = i 2V . (3.9) For f ∈ S t and n ∈ Z≥1 we set: Ian(zn) = Z zn i∞ · · · Z z i∞ Z z i∞ fa(z0)dz0dz1 · · · dzn− where fa(z) = f(σaz)/j(σa, z) . For n ≤ 0, we set Ian(z) = f (−n) a (z). We observe that Ia1(σa − z) = R z a f(w)dw. With this notation, we set, for each r ∈ Z≥ Qam(z, s, n, r; ¯f) = X γ∈Γa\\Γ Ian(σa −1γz) Im(σa − γz) s e(mσa − γz)ε(σa − γ, z) −r . In this section we will give the domains of initial convergence and bounds of this series and its derivative. Their analytic continuation will be discussed in the next section. 6Proposition 3.3. Let f ∈ S t be such that f|2(· − 1) ∈ Ht. For k ∈ 2Z and σ = Re(s) > 1 the series Qam(z, s, 1, k, ¯f) and Q′ am(z, s, 1, k, ¯f) converge absolutely and uniformly on compacta to analytic functions of s. For these s and for all m ≥ 0, Qam(z, s, 1, k; ¯f) and (|m| + 1)−1yQ′ am(z, s, 1, k; ¯f) are bounded by a constant times yΓ(z) 1/2−σ/ . The implied constants are independent of z and m. Proof: Let f ∈ S t 2 be such that f|2(· − 1) ∈ Ht. By Lemma 2.1 and the elementary inequality | log y| < ǫ(y ǫ + y−ǫ ) we have Z σbz a f(w)dw ≪ Xt j=−t y jǫ (3.10) for all z in H and hence Z γσbz a f(w)dw = Z σaσa −1γσbz a f(w)dw ≪ Xt j=−t Im(σa − γσbz) jǫ for any cusp b and any z in H. The implied constant depends solely on a, ǫ, f and Γ. Further, the Fourier expansion of R σbz b f(w)dw yields Z σbz a f(w)dw = Z b a f(w) dw + 2πi X∞ n= ab(n) n e(nz) (3.11) with ab(n) the n-th Fourier coefficient of f at the cusp b. Thus, Z σaz a f(w)dw ≪ e −2πy as y → ∞. (3.12) Consequently, since |e(mσa −1γz)ε(σa−1γ, z)−k | ≤ 1, Qam(σaz, s, 1, k; ¯f) ≪ X γ∈Γa\\Γ | Z γσaz a f(w)dw|Im(σa − γσaz) σ ≪ e −2πyyσ + X γ∈Γa\\Γ γ6=I   Xt j=−t Im(σa − γσaz) σ+jǫ  ≪ y 1−σ+tǫ for σ > 1 + tǫ as y → ∞ by (3.2). When a 6= b we have Qam(σbz, s, 1, k; ¯f) ≪ Xt j=−t Ea(σbz, σ + jǫ) ≪ y 1−σ+tǫ for σ > 1 + tǫ as y → ∞. Choose ǫ = (σ − 1)/2t for simplicity and we have demonstrated that Qam(z, s, 1, k; ¯f) ≪ yΓ(z) 1/2−σ/ for σ > 1 and an implied constant depending on σ, a, f and Γ alone. This proves the statement for Qam(z, s, 1, k; ¯f). With (3.1) we deduce that 2iyQ′ am(z, s, 1, k; ¯f) = (s + k )Qam(z, s, 1, k + 2; ¯f)− 4πmQam(z, s + 1, 1, k + 2; ¯f) − k Qam(z, s, 1, k; ¯f) 7This together with the continuation and bounds of Qam that we have just proved yields the desired result about Q′ am. 3.2. The basic theorem We are ready to state the theorem that will enable us to construct the basis elements for S t . We first construct a family of elementary functions in S t . Fix a cusp a and let {f1, . . . , fg} be an orthonormal basis of S2. For ij ∈ {1, . . . , g} we set Fi1,...,it (z) = fi1(z) Z z a fi2(w) Z w a fi . . . dw. It is easy to see with (2.3) and an inductive argument that Fi1,...,it|2(γ − 1) = Xt− r= Fi1,...,ir Z γa a Fir+1,...,it(w)dw. (3.13) It is straightforward, by an inductive argument, to see that they are invariant under the parabolic elements, that they vanish at the cusps and that Fi1,...,it|2(γ − 1) ∈ S t− . Hence Fi1,...,it ∈ S t . Since these functions will play a fundamental role in the sequel, we set At = {Fi1,...,it;ij ∈ {1, . . . , g}}. It is clear that, if f ∈ At, f|2(· − 1) ∈ Ht, so the results of the previous sections apply to the elements of this set. To generate further higher-order cusp forms, we need some functions that depend on standard cusp forms in a less elementary way than the Fi1,...,it's do. Specifically, let m ≥ 0 and k ∈ 2Z. For f ∈ S t (Γ) we set Zam(z, s, 1, k; ¯f) := X γ∈Γa\\Γ Z γa a f(w)dwIm(σa − γz) s e(mσa − γz)ε(σa − γ, z) −k This function is essentially a generalization of the function Zam(z, s; f) which was crucial for the construction of a basis of the space of second-order cusp forms in [DO]. However, the multiplier is slightly modified. The advantage is that in this way we avoid the introduction of the function Gam used in [DO]. We need to meromorphically continue Zam to a region that contains 1. The proof has many similarities to that of the corresponding result in [DO]. Theorem 3.4. For f ∈ At, Zam(z, s, 1, k; ¯f) admits a meromorphic continuation to Re(s) > 1 − δΓ. The only possible pole is s = 1 and it can only occur when k ≤ 0. For k = 0, it is simple. For k ≥ 2, and m 6= 0, Zam(z, s, 1, k; ¯f) ≪ yF(z) 1/ . For k ≥ 2, Za0(z, s, 1, k; ¯f) ≪ yF(z) σ . For k = 2, Za0(z, 1, 1, 2; ¯f) ≪ yF(z) 1/ . The implied constants are independent of z in all cases. Proof: We will prove the theorem by induction on t. For t = 0, it is trivial. Let t > 0 and suppose, the statement is true for orders < t. If f ∈ At, then (2.3) implies Zam(z, s, 1, k; ¯f) = Qam(z, s, 1, k;¯f) − ( Z z a f(w)dw) Uam(z, s, k)+ X ′ Zam(z, s, 1, k; ¯h)( Z a z h1(w)dw) (3.14) where the prime indicates that the summation is over some pairs (h, h1) ∈ Ar × At−r, 1 ≤ r ≤ t − 1. The meromorphic continuation and bounds of Uam(z, s, k) and Zam(z, s, 1, k; ¯h) in (3.14) are known by Prop. 3.2 and the inductive hypothesis respectively. Therefore, we only need to meromorphically continue and bound Qam(z, s, 1, k; ¯f). To this end we first need to study Qam(z, s + n + 1, −n, k, ¯f) for n ≥ 0. 8Proposition 3.5. Suppose that f ∈ At . For k ∈ Z and −n 6 0 the series Qam(z, s + n + 1, −n, k, ¯f) has a meromorphic continuation to Re(s) > 1 − δΓ. For k ≥ 0, it is analytic. Also for these s and k ≥ 0 we have Qam(z, s + n + 1, −n, k; ¯f) ≪ e −πyΓ(z) with the implied constant depending on n, m, f, k, s and Γ alone. Proof: We begin with the formula g (n)(γz) = (−2i) −n Im(γz) −n−1Xn r= (−1)n−rε(γ, z) −2r− n r (n + 1)! (r + 1)! L r θγ,−2(yg(z)) valid for any holomorphic g : H → C and for all γ in Γ (see [CO] for a proof). Set Γ′:= σa −1Γσa. Then σa −1Γaσa = Γ∞ and ε(σa, z) −kQam(σaz, s, −n, k; ¯f) = X γ′∈Γ∞\\Γ′ f (n) a (γ ′z)Im(γ ′ z) s e(mγ′z)ε(γ ′ , z) −k = (−2i) −nXn r= (−1)n−r n r (n + 1)! (r + 1)! X γ′∈Γ∞\\Γ′ L r (θγ′ ,−2(yfa(z)))Im(γ ′ z) s−n− e(mγ′z)ε(γ ′ , z) −(2r+2)−k Now, if f|2(γ − 1) = P ′( R γa a h(w)dw)h1 (γ ∈ Γ), with (h, h1) ∈ Ar(Γ) × At−r(Γ), (r ≥ 1), then fa|2(γ ′ −1) = P ′ ( R γ ′σa−1a σa −1a ha(w)dw)(h1)a for γ ′ ∈ Γ′ and (ha,(h1)a) ∈ Ar(Γ′ )×At−r(Γ′). Therefore, L r θγ′ ,−2(yfa(z)) = L r y(fa|2γ ′)(z) = L r yfa(z) + X ′ Z γ′σa −1a σa −1a ha(w)dwLr y(h1)a(z) It is also easy to see (cf. Prop. E of [DO]) that for all G : H → C, L r yGa(z) = L r yG(z) σaz ε(σa, z) 2r+ so X γ′∈Γ∞\\Γ′ L r θγ′ ,−2(yfa(z)) Im(γ ′ z) s−n− e(mγ′z)ε(γ ′ , z) −(2r+2)−k = L r (yf(z))|σazUam(σaz, s − n − 1, 2r + 2 + k)ε(σa, z) −k+ X ′ h L r (yh1(z))× X γ∈Γa\\Γ Z γa a h(w)dwIm(σa − γz) s−n− e(mσa − γz)ε(σa − γ, z) −(2r+2)−k i|σazε(σa, z) −k = L r (yf(z))|σazUam(σaz, s − n − 1, 2r + 2 + k)ε(σa, z) −k+ X ′ L r (yh1(z))|σazZam(σaz, s − n − 1, 1, 2r + 2 + k; h¯)ε(σa, z) −k (3.15) Since h ∈ Ar, r < t, the inductive hypothesis implies that Zam has a meromorphic continuation for Re(s − n − 1) > 1 − δΓ. By Prop. 3.2 the same holds for Uam. Moreover, since 2r + 2 ≥ 2, by the inductive hypothesis and Prop. 3.2 we deduce that we obtain an analytic function when k ≥ 0. The function L r yf(z) (and L r yh(z) ) has exponential decay at every cusp b because θσb,−2r−2L r yf(z) = L r θσb,−2yf(z) = L r yj(σbz)−2f(σbz) = L r y X∞ n= ab(n)e(nz) ! . 9Hence L r yf(z) ≪ yΓ(z) r+1e−2πyΓ(z) (3.16) for an implied constant depending on r, f and Γ. Therefore, with (3.15), (3.16), Prop. 3.2 and the inductive hypothesis, we have for Re(s) > 1 − δΓ and k ≥ 0: Qam(z, s + n + 1, −n, k; ¯f) ≪ e −πyΓ(z) . We are now ready to prove the analytic continuation of Qam(z, s, 1, k, ¯f). Proposition 3.6. Let m ≥ 0 and k ∈ 2Z. For f ∈ At the series Qam(z, s, 1, k; ¯f) has continuation to a meromorphic function of s with Re(s) > 1 − δΓ. For k > 0, we obtain an analytic function. For k = 0, it has only a simple pole at s = 1 with residue −aa(m) 2πim if m 6= 0 and 0 otherwise. For k 6= or k = m = 0, we have Qam(z, s, 1, k; ¯f) ≪ yΓ(z) 1/ . For k = 0, m 6= 0, (s − 1)Qam(z, s, 1, 0; ¯f) ≪ yΓ(z) 1/ . The implied constants depend on s, m, f and Γ. Proof: We first prove the result for k = 0. By Proposition 3.3, Qam(z, s, 1, 0; ¯f) is square integrable for Re(s) > 1 and the spectral decomposition yields Qam(z, s, 1, 0; ¯f) = X∞ j= hQam(·, s, 1, 0; ¯f), ηj iηj + 4π X b Z ∞ −∞ hQam(·, s, 1, 0; ¯f), Eb(·, 1/2 + ir)iEb(z, 1/2 + ir) dr. (3.17) We recall the Prop. 9.3 and Cor. 9.4 of [JO]: Lemma 3.7. Let ξ1, ξ2 and ψ be any smooth Γ invariant functions (not necessarily in L (Γ\\H)). If (∆ − λ)ξ1 = ξ2, (∆ − λ ′ )ψ = 0 and ξ1, R0ξ1, ∆ξ1 ≪ yΓ(z) A, ψ, R0ψ ≪ yΓ(z) B for A + B < 0 and R0 = 2iy d dz the raising operator, then hξ1, ψi = λ′ − λ hξ2, ψi. We will apply this lemma to ξ1 = Qam(z, s, n, 0; ¯f) (n ∈ Z) and ψ = ηj . (3.1) implies that for all n ∈ Z, (∆ − s(1 − s))Qam(z, s, n, 0; ¯f) = − 8πimQam(z, s + 2, n − 1, 0; ¯f) + 4πmsQam(z, s + 1, n, 0; ¯f) + 2isQam(z, s + 1, n − 1, 0; ¯f). Next, we have ηj (z), R0ηj (z) ≪ yΓ(z) 1/2 by Lemma 3.1(i) and Qam(z, s, 1, 0; ¯f), R0Qam(z, s, 1, 0; ¯f), ∆Qam(z, s, 1, 0; ¯f) ≪ yΓ(z) 1/2−σ/ for σ = Re(s) > 1 by Proposition 3.3 and Proposition 3.5. So we may use Lemma 3.7 to get, for Re(s) > 2, hQam(·, s, 1, 0; ¯f), ηj i = (sj − s)(1 − sj − s) − 8πimhQam(·, s + 2, 0, 0; ¯f), ηj i + 4πmshQam(·, s + 1, 1, 0; ¯f), ηj i + 2ishQam(·, s + 1, 0, 0; ¯f), ηj i . 10We can repeat this procedure W times in all to obtain, again for Re(s) > 2, hQam(·, s, 1, 0; ¯f), ηj i = X l Pl(m, s) Rl(sj , s) hQam(·, s + W + cl, 1 − dl, 0; ¯f), ηj i, (3.18) with integers cl, dl satisfying 0 6 cl, dl 6 W, dl ≤ W + cl, Pl(m, s) a polynomial in m, s alone of degree W in m and of degree W in s and Rl(sj , s) a polynomial in sj , s alone of degree 2W in sj and of degree 2W in s. In fact Rl(sj , s) = Y b (sj − b − s)(1 − sj − b − s) (3.19) where, for each l, the product is over some subset of integers b in {0, 1, · · · , 2W} of cardinality W. If dl = 0, then we have Qam(z, s + W + cl, 1, 0; ¯f) ≪ yΓ(z) 1/4−W/ (3.20) by Proposition 3.3, for W > 1. Hence hQam(·, s + W + cl, 1, 0; ¯f), ηj i ≪ q ||yΓ(z)−1/4|| · ||ηj || = q ||yΓ(z)−1/4|| ≪ 1. (3.21) For 0 < dl 6 W, Prop. 3.5 implies that Qam(z, s + W + cl, 1 − dl, 0; ¯f) ≪ e −πyΓ(z) and hence hQam(z, s + W + cl, 1 − dl, 0; ¯f), ηj i ≪ 1. Therefore, for j > 0, hQam(·, s, 1, 0; ¯f), ηj i is an analytic function of s for Re(s) > 1 − δΓ and satisfies hQam(·, s, 1, 0; ¯f), ηj i ≪ |sj | −2W ≪ |λj |−W (3.22) for implied constants depending on s, m, W, f and Γ alone and with the dependence on s being uniform on compacta. For j > 0 and for all n ≥ 0 we can now use (3.4), Lemma 3.1 (i) and (3.22) to get X T 6|λj |<T + < Qam(·, s, 1, 0; ¯f), ηj > Rn ηj (z) ≪ T 1−W ((Tn/2 + 1)yΓ(z)1/2 + (Tn+7/2 + 1)yΓ(z)−3/ ). Hence for W = 6 + n, X∞ j= < Qam(·, s, 1, 0; ¯f), ηj > Rn(ηj (z)) ≪ yΓ(z) 1/ (3.23) for all s with Re(s) > 1 − δΓ. The sum converges uniformly for s in compact sets with Re(s) > 1 − δΓ giving an analytic function of s. When n > 0, Rn eliminates hQam(·, s, 1, 0; ¯f), η0iη0(z). For j = 0, the constant eigenfunction is η0 = V −1/ . If m 6= 0, by unfolding we obtain hQam(·, s, 1, 0; f), η0iη0 = −aa(m) Γ(s − 1) 2πim(4πm) s− = −aa(m) 2πim s − + O(1) as s → 1 for fa(z) = P∞ m=1 aa(m)e(mz). If m = 0, the same process gives 0. 11With arguments similar to those used for the discrete spectrum we now consider the continuous spectrum. For Pl, Rl, cl and dlidentical to (3.18), Lemma 3.1 (ii) gives hQam(·, s, 1, 0; ¯f), Eb(·, 1/2 + ir)i = X l Pl(m, s) Rl(1/2 + ir, s) hQam(·, s + W + cl, 1 − dl, 0; ¯f), Eb(·, 1/2 + ir)i, (3.24) which is true for Re(s) > 2 initially. With (3.19), (3.20), Prop. 3.5 and Lemma 3.1 (ii) we see that (for W > 1) the right side of (3.24) converges and gives the analytic continuation of the left side to Re(s) > 1 − δΓ. Now, for all n ≥ 0, Z T + T hQam(·, s, 1, 0; ¯f), Eb(·, 1/2 + ir)iR nEb(z0, 1/2 + ir) dr = X l Pl(m, s) Z T + T hQam(·, s + W + cl, 1 − dl, 0; ¯f), Eb(·, 1/2 + ir)i Rl(1/2 + ir, s) R nEb(z0, 1/2 + ir) dr = X l Pl(m, s) Z T + T Z F Qam(z, s + W + cl, 1 − dl, 0; ¯f) Rl(1/2 + ir, s) Eb(z, 1/2 + ir)R nEb(z0, 1/2 + ir) dµz dr. (3.25) The integrand satisfies Qam(z, s + W + cl, 1 − dl, 0; ¯f) Rl(1/2 + ir, s) Eb(z, 1/2 + ir)R nEb(z0, 1/2 + ir) ≪ |r| −2W+n yΓ(z) 1/4−W/ yΓ(z) 1/ yΓ(z0) 1/ by (3.19), (3.20), Prop. 3.5, Lemma 3.1(ii) and the easily proved identity R nEa(z, s) = s(s + 1)· · ·(s + n − 1)Ua0(z, s, 2n). Thus the double integral in (3.25) is absolutely and uniformly convergent and we may interchange the limits of integration to obtain X l Pl(m, s) Z F Qam(z, s+W +cl, 1−dl, 0; ¯f) Z T + T Eb(z, 1/2 + ir) Rl(1/2 + ir, s) R nEb(z0, 1/2 +ir) dr dµz. (3.26) Also Z T + T Eb(z, 1/2 + ir) Rl(1/2 + ir, s) R nEb(z0, 1/2 + ir) dr ≪ T −2W sZ T + T |Eb(z, 1/2 + ir)| 2 dr · Z T + T |RnEb(z0, 1/2 + ir)| 2 dr. So, with Lemma 3.1 (iii), (3.26) is bounded by a constant times X l |Pl(m, s)|T 12−2W+2n Z F yΓ(z) 3/4−W/ dµz · yΓ(z0) 1/ . This means that, for W chosen large enough, Z ∞ −∞ hQam(·, s, 1, 0; ¯f), Eb(·, 1/2 + ir)iR nEb(z, 1/2 + ir) dr ≪ yΓ(z)1/ . 12To combine the information we have collected for the discrete and the continuous part of (3.17) we observe that with (3.23) and preceeding discussion we can interchange summation and differentation to get R n X∞ j= < Qam(·, s, 1, 0; ¯f), ηj > ηj (z) = X∞ j= < Qam(·, s, 1, 0; ¯f), ηj > Rn ηj (z) and that Lemma 10.2 of [DO] implies 4π X b R n Z T + T hQam(·, s, 1, 0; ¯f), Eb(·, 1/2 + ir)iEb(z, 1/2 + ir) dr = 4π X b Z T + T hQam(·, s, 1, 0; ¯f), Eb(·, 1/2 + ir)iR nEb(z, 1/2 + ir) dr for all T ∈ R. Therefore, R nQam(z, s, 1, 0; ¯f) = hQam(·, s, 1, 0; ¯f), η0iRn η0 + X∞ j= hQam(·, s, 1, 0; ¯f), ηj iR n ηj (z) + 4π X b Z ∞ −∞ hQam(·, s, 1, 0; ¯f), Eb(·, 1/2 + ir)iR nEb(z, 1/2 + ir) dr and it has a continuation to a meromorphic function of s with Re(s) > 1 − δΓ. For these values, (s − 1)Qam(z, s, 1, 0; ¯f), RnQam(z, s, 1, 0; ¯f) (n > 0) and Qa0(z, s, 1, 0; ¯f) are all ≪ yΓ(z) 1/2 The only pole is at s = 1 and it comes from the contribution of η0 when n = 0. To pass to general k's we apply the operators Rr successively, using (3.1), to obtain, for k > 0: Qam(z, s, 1, k; ¯f) = s(s + 1)· · ·(s + k 2 − 1) R kQam(z, s, 1, 0; ¯f) + k X− i=− X k j=1+i ′ pi,j (m, s)Qam(z, s + j, −i, k; ¯f) (3.27) with polynomials pi,j in m and s. Here the prime indicates that we exclude the term corresponding to (i, j) = (−1, 0). Thanks to Propositions 3.3, 3.5 (for −i ≤ 0) and the meromorphic continuation and growth of RkQam(z, s, 1, 0; f) we just proved, the identity (3.27) implies Prop. 3.6. For k < 0, we work in a similar way. End of proof of Th. 3.4 By Propositions 3.2 and 3.6, the inductive hypothesis and (3.14), we deduce that for k > 0 Zam(z, s, 1, k; ¯f) is holomorphic in s and that for k = 0 the only possible pole is at s = 1 which is simple. This completes the proof of the analytic continuation of Zam. To prove the bounds, we recall from (3.11) and (3.12) that, for z ∈ F, R σaz a f(w)dw ≪ 1 and R σbz a f(w)dw ≪ e −2πy, if a 6= b as y → ∞. The desired bound follows from this, Propositions 3.2 and 3.6, the inductive hypothesis and (3.14). For m = 0, k = 2 and s = 1 we deduce the bound from these inequalities and Ua0(σbz, 1, 2) ≪ δaby + 1, as y → ∞ (see (3.8)). 3.3 A family of functions of S t . In this section we construct a family of t-order cusp forms based on the analytic continuation of Zam(z, s, 1, 2; f) established in Section 3.2. The construction is carried out in three steps. In the first step, since we are mainly interested in the weight according to j(γ, z) rather than ε(γ, z), we set Zam(z, s; ¯f) := y −1Zam(z, s + 1, 1, 2; ¯f) = X γ∈Γa\\Γ Z γa a f(w)dwIm(σa − γz) s e(mσa − γz)j(σa − γ, z) − . (3.28) 13According to Theorem 3.4, Zam(z, s, F¯ i1,...,it− ) is analytic for Re(s) > −δΓ. It is easy to see that Zam(·, 0, F¯ i1,...,it− )|2(γ − 1) = Z γ−1a a Fi1,...,it− Pam + Xt− r= Z γ−1a a Fi1,...,ir Zam(·, 0, F¯ ir+1,...,it− ). Further, for Re(s) large we have: d dz¯ Zam(z, s; F¯ i1,...,it− ) = is 2y Zam(z, s + 1, 1, 0; F¯ i1,...,it− ) (3.29) In the second step, if fit = P l alPaml, we set, for j ≥ 1, Zij ,...,it = X l alZaml(·, 0; F¯ ij ,...,it− ). An inductive argument implies that, for t ≥ 2, Zi1,...,it|2(γ − 1) = Xt− r= Z γ−1a a Fi1,...,ir Zir+1,...,it(3.30) In view of (3.29), we apply the same linear combination to Ress=1Zam(·, s, 1, 0; F¯ i1,...,it− ) and to −aa(m) 2πim , for m > 0. We denote them by Ri1,...,it and ai1,...,it respectively. Then, (3.14) and Prop. 3. give Ri1,...,it = ai1,...,it + Xt− r= Z a z Fi1,...,ir Rir+1,...,it. (3.31) For convenience we have set Zj := fj . (3.30) and induction imply that Zi1,...,it|2(γ1 − 1). . .(γt−1 − 1) = Z γ − a a fi1. . . Z γ − t− a a fit−1 fit (3.32) In the third step, we suitably modify the functions constructed so far to obtain holomorphic forms. To state a lemma we will need, we recursively define the following functions: Si1:= Z a z fi1(w)dw and Si1,...,it:= Xt r= Z a z Fi1,...,ir(w)dw Sir+1,...,it. We also set Sik+1,...,ik = 1, Sij ,...,ik = 0 for j > k + 1 and Si0 = 1. Lemma 3.8. Let t ∈ Z≥2. For every i1, . . . , it ∈ {1, . . . , g} we have (i) For m 6= 0, Ri1,...,it = Xt− j= Si1,...,ij· aij+1,...,it. (ii) Ress=1Za0(·, s, 1, 0; F¯ i1,...,it ) = V Si1,...,it . 14Proof: (i) is proved by induction in t. By (3.14), it is clear for t = 2. If the result holds for orders < t, then (3.31) implies that Ri1,...,it = ai1,...,it + Xt− r= Z a z Fi1,...,ir Xt− j=r Sir+1,...,ij aij+1,...,it . By the definition of Sij ...ikfor j > k, the inner sum can be written in the form Pt− j=1 Sir+1,...,ij aij+1,...,it and thus Ri1,...,it = ai1,...,it + Xt− j= Xt− r= Z a z Fi1,...,ir Sir+1,...,ij aij+1,...,it. Since Sij ,...,ik = 0 for j > k + 1, the inner sum equals Si1,...,ij. This proves the identity for t. (ii) follows from (3.14), Prop. 3.2 and a straightforward induction argument because, as shown in the proof of Prop. 3.6., ai1,...,itin (3.14) is 0. By (3.29) and Lemma 3.8(i), there is a linear combination Z(i1, . . . , it−1) of Zi1,i2, . . . , Zi1,...,it− for m 6= 0 such that d dz¯ (Zi1,...,it − Z(i1, . . . , it−1)) = i 2y (Si1,...,it−2 ait−1,it) (3.33) Since Ress=1(Qam(z, s, 1, 0; F¯ it− )) = −aa(m) 2πim = 2i< fit− , Pam(·) >, (where < ·, · > is the usual Petersson scalar product), by the definition of ait−1,it we have, ait−1,it = 2i< fit− , fit >. Therefore, if it−1 6= it, (3.33) and the orthonormality of the basis imply that Zi1,...,it − Z(i1, . . . , it−1) is holomorphic. If it−1 = it, (3.33) again implies that Zi1,...,it − Z(i1, . . . , it−1) − Zi1,...,it−2,1,1 − Z(i1, . . . , it−2, 1) is holomorphic. In order to keep track of the basis elements we will construct in the sequel, we indicate the conjugation of R γji∞ i∞ fij (w)dw by a minus sign in the notation of the corresponding subscript. Specifically, in view of (3.32) we set, for every i1, . . . , it ∈ {1, . . . , g} with (it−1, it) 6= (1, 1), Z−i1,...,−it−1,it = (−1)t−1(Zi1,...,it − Z(i1, . . . , it−1)) if it−1 6= it (−1)t−1(Zi1,...,it − Z(i1, . . . , it−1) − Zi1,...,1,1 − Z(i1, . . . , it−2, 1)) if it−1 = it. The reason we have added the factor (−1)t−1is so that Z satisfy (3.32) without the γj 's being inverted on the right-hand side. For t = 1, we set, for i < 0, Zi = Z−i = fi:= f−i. Theorem 3.9. For t ∈ Z≥2, i1, . . . , it−1 ∈ {−1, . . . , −g}, it ∈ {1, . . . , g} and (it−1, it) 6= (−1, 1), we have Zi1,...,it ∈ S t . Proof: They are holomorphic by construction. The invariance under the parabolic elements of all Zi1,...,ir's is deduced by (3.30) and the fact that Fi1,...,ir ∈ S t . (3.32) implies that Zi1,...,it|2(γ1 − 1). . .(γt − 1) = 0. 15The growth condition proved in Theorem 3.4 implies that each Zi1,...,ir and thus Zi1,...,it is ≪ yF(z) −1/ . (Recall that Zam(z, s + 1, 1, 2; ¯f) is divided by y in Zam(z, s; ¯f)). Considering the Fourier expansion of Zi1,...,it we deduce its vanishing at the cusps. Now, (3.30) and Th. 3.4 imply that Zi1,...,ir|2γ ≪ yF(z) −1/ for each γ ∈ Γ. Therefore, the same estimate holds for the holomorphic Zi1,...,it|2γ and a look at its Fourier expansion implies the vanishing at the cusps for each γ. By (the second formulation of) the definition of S t 2 we deduce the result. In the next section we will also need a family of functions lying outside S t . They are the analogue of the function Zµ,µ + 2iV < µ, µ >Pa0(z)2 in Prop. 5.2 of [DO]. If ai (i = 1, . . . , m) is a set of inequivalent cusps for Γ, set fg+i:= Pai0 − Pam0 for i = 1, . . . , m − 1. Then {fg+1, . . . , fg+m−1} a basis of the space E2 of Eisenstein series of M2 (cf. [GO]). For ij ∈ {1, . . . , g}, we set Z ′ −i1,...,−it−1,it = ( Z−i1,...,itif it−1 6= it (−1)t− Zi1,...,it − Z(i1, . . . , it−1) − 2iV · Zam0(·, 0; F¯ i1,...,it− ) if it−1 = it. The last term is understood to be Pam0(·)2 when t = 2. By Lemma 3.8(ii), (3.29) and (3.33) we observe that Z′ −i1,...,−it−1,it is holomorphic. By the holomorphicity, Theorem 3.4 and (3.8), Z′ −i1,...,it vanishes at all cusps except am in the case t = 2. Again the reason for the factor (−1)t−1is that Z′ now satisfies (3.32) without the γj 's being inverted on the right-hand side. 3.4 Construction of a basis of S t We will use the functions defined in Section 3.3 to build recursively bases for all S t 's. We first introduce some notation and prove an elementary lemma. First, following [R], for an increasing finite sequence j1, . . . jt−1 we call a shuffle of type (r, t) a pair (φ, ψ) of order-preserving maps φ : {j1, . . . , jr−1} → {1, . . . , t − 1} and ψ : {jr, . . . , jt−1} → {1, . . . , t − 1} whose images are disjoint and complementary. Since the specific underlying sequence will be understood in each case, we denote their set simply by Sr,t. We then have Lemma 3.10. For F ∈ S r , G ∈ Mt−r+ 0 we have (F ·G)|2(γ1 −1). . .(γt−1 −1) = X (φ,ψ)∈Sr,t F|2(γφ(1) −1). . .(γφ(r−1) −1)·G|0(γψ(r) −1). . .(γψ(t−1) −1). Proof: By Th. 2.2 of [CD], we have (F · G)|2(γ − 1) = F|2(γ − 1) · G + F · G|0(γ − 1) + F|2(γ − 1) · G|0(γ − 1). This means that each time we apply a γ − 1 (γ ∈ Γ) on F · G, either F or G or both are acted upon by γ − 1 too. Now, F (resp. G) is annihilated by any products with r (resp. t − r + 1) factors of the form γ −1. Therefore, the only non-vanishing terms left after (γ1 −1). . .(γt−1 −1) is applied on F ·G are the products of the form F|2(γi1 − 1). . .(γir−1 − 1) · G|0(γj1 − 1). . .(γjt−r − 1) with i1 < · · · < ir−1, j1 < · · · < jt−r and i1, . . . , ir−1, j1, . . . , jt−r covering {1, . . . , t−1}. In particular, by the last two facts the sets of ik and jk are disjoint. This implies Lemma 3.10. 16Next, for j ∈ {±1, . . . , ±g} ∪ {g + 1, . . . , g + m − 1} we set < fj , γ > for R γi i fj (w)dw, when j > and R γi∞ i∞ f−j (w)dw, for j < 0. We also set A for the space generated by maps φ : Γl → S2 defined by φ(γ1, . . . , γl) =< fi1, γ1 > · · · < fil, γl > fil+ with −ij = ij+1 = 1 for at least one j ∈ {1, . . . , l}. (In section 4 we will need the analogue of this space with fil+1 of higher weight. In an effort to simplify notation, A will stand for the space in the case of weight 2 and when we need it for higher weights, we will indicate it by a subscript.) We denote by I ′ the set of vectors (i1, . . . , it) with entries in {±1, . . . , ±g} for which there is no j ∈ {1, . . . , t − 1} such that −ij = ij+1 = 1. We also let I be the set of (i1, . . . , it) ∈ I ′ , with it > 0. Starting with Zi, suppose now that, for each s < t, the forms Zi1,...,is, (i1, . . . , is) ∈ I satisfy Zi1,...,is|2(γ1 − 1). . .(γs−1 − 1) =< fi1, γ1 > · · · < fis−1, γs−1 > fis + φ(γ1, . . . , γs−1) (3.34) for some φ ∈ A. We claim that for every (i1, . . . , it) ∈ I, there are Zi1,...,itsatisfying (3.34) with s = t. First, with Lemma 3.10, [Zi Z z i Zi2,...,it(w)dw]|2(γ1 − 1). . .(γt−1 − 1) = fi1 < fi , γ1 > · · · < fit−1, γt−2 > Z γt−1i i fit(w)dw + φ(γ1, . . . , γt−1). (3.35) Hence, for (i1, . . . , it−1) ∈ I and it ∈ {1, . . . , g} we set Zi1,...,it:= Zit Z z i Zi1,...,it−1(w)dw. Next, if i1 < 0, (i1, i2) ∈ I, and (i3, . . . , it) ∈ I, [Zi1,i Z z i Zi3,...,it(w)dw]|2(γ1 − 1). . .(γt−1 − 1) = X (φ,ψ)∈S2,t Z γφ(1)i i fi1(w)dwfi tY− j= < fij, γψ(j) > Z γψ(t)i i fit(w)dw + φ(γ1, . . . , γt−1) for some φ ∈ A. By the definition of shuffles, R γt−1i i fit (w)dw appears as the last factor and thus unconjugated in each summand of the right-hand side except for that corresponding to φ(1) = t − 1. Therefore, by (3.35), there is a linear combination of Zj R z i Zj2,...,jt (w)dw's denoted by A(fi1, . . . , fit), such that [Zi1,i Z z i Zi3,...,it(w)dw − A(fi1, . . . , fit)]|2(γ1 − 1). . .(γt−1 − 1) = Z γt−1i i fi1(w)dwfi2 < fi , γ1 > · · · < fit−1, γt−3 > Z γt−2i i fit(w)dw + φ(γ1, . . . , γt−1) (3.36) for some φ ∈ A. Hence for (it−1, it),(i1, . . . , it−2) ∈ I and it−1 < 0 we can set Zi1,...,it := Zit−1,it Z z i Zi1,...,it− (w)dw − A(fit− , fit , fi , . . . , fit− ). 17Further, if i1, i2 < 0 and (i1, i2, i3),(i4, . . . , it) ∈ I, [Zi1,i2,i Z z i Zi4,...,it(w)dw]|2(γ1 − 1). . .(γt−1 − 1) = X (φ,ψ)∈S3,t Z γφ(1)i i fi1(w)dwZ γφ(2)i i fi2(w)dwfi tY− j= < fij, γψ(j) > Z γψ(t)i i fit(w)dw+ φ(γ1, . . . , γt−1) for some φ ∈ A. The only summand that does not appear on the right-hand side of (3.35) and (3.36) for an appropriate permutation of i1, . . . , it, is Z γt−2i i fi1(w)dwZ γt−1i i fi2(w)dwfi3 < fi4, γ1 >· · · Z γt−3i i fit(w)dw. Therefore, by (3.35) and (3.36), there is a linear combination of terms Zj R z i Zj2,...,jt (w)dw's and Zj1,j R z i Zj3,...,jt (w)dw's denoted by B(fi1, . . . , fit), such that [Zi1,i2,i Z z i Zi4,...,it(w)dw − B(fi1, . . . , fit)]|2(γ1 − 1). . .(γt−1 − 1) = Z γt−2i i fi1(w)dwZ γt−1i i fi2(w)dwfi3 < fi4, γ1 >· · · Z γt−3i i fit(w)dw + φ(γ1, . . . , γt−1) for some φ ∈ A. Hence for (it−2, it−1, it),(i1, . . . , it−3) ∈ I and it−2, it−1 < 0 we can set Zi1,...,it:= Zit−2,it−1,it Z z i Zi1,...,it−3(w)dw − B(fit−2, fit−1, fit, fi1, . . . , fit−3). Continuing this way we construct, for all (i1, . . . , it) ∈ I, functions Zi1,...itsatisfying (3.34). The last element, whose indices i1, . . . , it−1 are negative, is obtained directly from Th. 3.9. We also define recursively a similar family of functions involving Z′: Starting with Z′ i = Zi , suppose that, for each s < t, Z′ i1,...,is , ij ∈ {±1, · · · ± g} (is > 0) satisfy Z ′ i1,...,is |2(γ1 − 1). . .(γs−1 − 1) =< fi1, γ1 > · · · < fis−1, γs−1 > fis. (3.34') Then [Z ′ i Z z i Z ′ i2,...,it (w)dw]|2(γ1 − 1). . .(γt−1 − 1) = fi1 < fi2, γ1 > · · · < fit−1, γt−2 > Z γt−1i i fit(w)dw and for ij ∈ {±1, · · · ± g} (it−1 > 0) we set Z ′ i1,...,it := Z ′ it Z z i Z ′ i1,...,it− (w)dw. Next, if i1 < 0, [Z ′ i1,i Z z i Z ′ i3,...,it (w)dw]|2(γ1 − 1). . .(γt−1 − 1) = X (φ,ψ)∈S2,t Z γφ(1)i i fi (w)dwfi tY− j= < fij , γψ(j) > Z γψ(t)i i fit(w)dw. 18As before, there is a linear combination of Z′ j R z i Z′ j2,...,jt (w)dw's denoted by A(fi1, . . . , fit), such that [Z ′ i1,i Z z i Z ′ i3,...,it (w)dw − A(fi1, . . . , fit)]|2(γ1 − 1). . .(γt−1 − 1) = Z γt−1i i fi1(w)dwfi2 < fi3, γ1 > · · · < fit−1, γt−3 > Z γt−2i i fit(w)dw so, if it−1 < 0 we set Z ′ i1,...,it := Z ′ it−1,it Z z i Z ′ i1,...,it− (w)dw − A(fit−1, fit, fi1, . . . , fit−2). Continuing in this way we construct, for all ij ∈ {±1, . . . , ±g} (it > 0), functions Z′ i1,...it satisfying (3.34), but, this time, without a φ. The last element, whose indices i1, . . . , it−1 are negative, is obtained directly by the construction at the end of section 3.3. By construction these functions are holomorphic and satisfy the stated functional equation. They have at most polynomial growth at each cusp a, and vanish at a 6= am. Because of this, they are invariant under πa for a 6= am. To prove that the Z's span S t , we will need a lemma that generalizes Prop. 5.2. of [DO]. Lemma 3.11. Let t ≥ 3. Suppose that for some F ∈ S t 2 and ci3,...,it ∈ C, F|2(γ1 − 1). . .(γt−1 − 1) = Xci3,...,it Z γ1i i f1(w)dw Z γ2i i f1(w)dw < fi3, γ3 > . . . fit for all γi ∈ Γ, where the sum ranges over all ij ∈ {±1, . . . , ±g}. Then all ci3,...,itvanish. Proof: As shown above, Z ′ −1,1,...,it |2(γ1 − 1). . .(γt−1 − 1) = Z γ1i i f1(w)dw Z γ2i i f1(w)dw < fi , γ3 > . . . fit and hence F − Pci3,...,itZ′ −1,1,...,it is annihilated by (γ1 − 1). . .(γt−1 − 1). Since F and Z′ −1,1,... are of at most polynomial growth at the cusps, for every γi ∈ Γ, we have (F − Xci3,...,itZ ′ −1,1,...,it )|2(γ1 − 1). . .(γt−2 − 1) = g+ Xm− i= χi(γ1, . . . , γt−2)fi for χi: Γt−2 → C. The left-hand side is annihilated upon the application of one more γ −1 and hence the identity γδ − 1 = (γ − 1)(δ − 1) + (γ − 1) + (δ − 1) implies that each χiis a group homomorphism in terms of each γj. By Eichler-Shimura isomorphism, χi(γ1, . . . , γt−2) = X j a i j (γ1, . . . , γt−3) Z γt−2i i hj (w)dw + b i j (γ1, . . . , γt−3) Z γt−2i i gj (w)dw! for some a i j , bi j : Γt−3 → C, gj ∈ S2 and hj ∈ M2. The injectivity of the Eichler-Shimura isomorphism implies that each a i j , b i j is a homomorphism on each of the arguments and hence, by induction, we deduce that (F − Xci3,...,itZ ′ −1,1,...,it )|(γ1 − 1). . .(γt−2 − 1) = X i1,...,it− λi1,...,it−1 < fi , γ1 > · · · < fit− , γt−2 > fit− (3.37) 19with ij ∈ {±1, . . . , ±g} ∪ {g + 1, . . . , g + m − 1} and it−1 > 0. Since Z′ i1,...,it is invariant under πai when i 6= m, the identity (γ − 1)(π − 1) = (γπγ−1 − 1)γ − π − 1 implies that Z ′ i1,...,it |2(γ1 − 1). . .(γt−2 − 1) vanishes when one of the γj 's equals πai, i 6= m. Since F ∈ S t , this then also holds for both sides of (3.37). Therefore, none of the fij, j < t − 1 appearing in (3.37) can be non-cuspidal. Indeed, for 0 < k < m, < fij, πak >6= 0 iff ij = g + k (recall the definition of fg+1). Hence, for all γ1, . . . , γj−1, γj+1, . . . , γt−2 ∈ Γ and for γj = πak, (k = 1, . . . , m − 1), the RHS of (3.37) equals X i1,...,ij−1,ij+1,...,it− λi1,...,ij−1,g+k,ij+1,...it−1× < fi1, γ1 > · · · < fij−1, γj−1 >< fg+k, πak >< fij+1 , γj+1 > · · · < fit−2, γt−2 > fit−1 = 0. Therefore, by the injectivity of Eichler-Shimura isomorphism, λi1,...,ij−1,g+k,ij+1,it−1 = 0. Hence, only cusp forms fj appear on the RHS of (3.37), so if {γ1, . . . , γt−2} contains πam, both sides of (3.37) vanish. Since F ∈ S t , this implies that Pci3,...,itZ′ −1,1,...,it |2(γ1 − 1). . .(γt−2 − 1) = 0 if at least one of the γi's is πam . However, we can show, by induction that, when i1 < 0, Z ′ i1,i2,...,it |2(πam − 1). . .(γt−2 − 1) = fit < fit−1, γt−2 >· · · Z πami i Z ′ −i,i(w)dw if (i1, i2) = (−i, i) (i > 0) and 0 otherwise. For t = 3, it is straightforward. If ir > 0, ir+1, . . . , it−1 < 0, then Z′ −i,i,i3,... is by definition equal to Z′ ir+1...it R z i Z′ −i,i,i3,...,ir minus a linear combination of products of the form Z′ ir+k,...,it R z i Z′ j1,j2,j3,... (k > 1) which we denote by C(f−i, fi, fi3, . . .). The indices j1, j2, . . . in the expression of C(fi1, fi2, . . .) are obtained by interspersing, in their original order, subsets of {ir+1, . . . , it−1} among the indices i1, i2, i3, . . . , it. Now, as in Lemma 3.10, we observe that, if one of the γiis parabolic and ir+k, . . . it−1 < 0, ir+k−1 > 0 then, for k ≥ 1, [Z ′ ir+k...it Z z i Z ′ j1,j2,...,ir+k− ]|2(γ1 − 1). . .(γt−2 − 1) = X (φ,ψ)∈S Z ′ ir+k,...it |2(γφ(1) − 1). . .(γφ(t−r−k) − 1)× Z γψ(r+k−2)z z [Z ′ j1,j2,...,ir+k− |2(γψ(1) − 1). . .(γψ(r+k−3) − 1)](w)dw. (3.38) Therefore, by the second part of the inductive hypothesis, the application of (πam − 1). . .(γt−2 − 1) on Z′ −i,i,... will eliminate all terms in C(f−i , fi, fi3, . . .) except for those with j1 = −i, j2 = i, thus obtaining, by (the first part of) the inductive hypothesis, products of the form Z γψ(1)i i Z ′ −i,i(w)dw · · · < fir+k−1, γψ(r+k−2) >< fir+k, γφ(1) > · · · < fit−1, γφ(t−r−k) > fit. These, upon varying k, yield X (φ,ψ)∈Sr,t− Z γψ(1)i i Z ′ −i,i(w)dw · · · < fir , γψ(r−1) >< fir+1 , γφ(1) > · · · < fit− , γφ(t−r−1) > fit+ C(Z ′ −i,i, . . . , fit )|2(γ1 − 1). . .(γt−2 − 1). (3.39) where C(Z ′ −i,i, fi , . . .) is C(f, fi3, . . .) with f formally replaced by Z ′ −i,i. Since the cancellations yielding (3.34') do not rely on fi 's being a cusp form rather than second order modular form, the 20same cancellations imply that (3.39) equals fit < fit− , γt−2 >· · · R πami i Z′ −i,i(w)dw as we wanted to show. The second part of the claim is proved in the same way, once we observe that C(fi1, fi2, . . .) does not contain integrals of Z′ −i,i,... because of the way the indices j1, j2, . . . in the expression of C(fi1, fi2, . . .) are obtained and the fact that ir+1, . . . , it−1 < 0. Therefore the inductive hypothesis can be applied. Therefore, for all γ2, . . . , γt−2 ∈ Γ, Xci3,...,itZ ′ −1,1,...,it |2(πam − 1). . .(γt−2 − 1) = Z πam i i Z ′ −1, (w)dwXci3,...,it < fi , γ2 > · · · < fit−1, γt−2 > fit and since the LHS is 0, the linear independence of the terms < fi3, γ2 > · · · < fit−1, γt−2 > fitfor γ2, . . . , γt−2 ∈ Γ, implies the desired conclusion. Theorem 3.12. Let t ≥ 1. Then the image of {Zi1,...,it; (i1, . . . , it) ∈ I} under the natural projection is a basis of S t /St− . Proof: We first note that by Th. 3.1 of [CD], each Zi1,...,it((i1, . . . , it) ∈ I) is a weight 2, t-th order form cusp because it is the product (\"0-th Rankin-Cohen bracket\") of a weight 2, order r < t cusp form and a weight 0, order t−r + 1 modular form (namely the antiderivative of a weight 2, order t−r cusp form). We now show that our set spans S t 2/St− . The claim is obvious for t = 1. Let now t > 1 and F ∈ S t . Then, for every γi ∈ Γ, F|2(γ1 − 1). . .(γt−1 − 1) = X i χi(γ1, . . . , γt−1)fi for a χi: Γt−1 → C. As in the proof of Lemma 3.11, each χiis a group homomorphism but, in addition, each of them vanishes at the parabolic elements as a function of each γi. Repeated applications of the Eichler-Shimura isomorphism imply that each χi(γ1, . . . , γt−1) is a linear combination of tY− j= < fij, γj > ij ∈ {±1, . . . , ±g}. By the construction of Zi1,...it's and (3.34) (with s = t) we then deduce that there is a linear combination L of these functions satisfying, (F − L)|2(γ1 − 1). . .(γt−1 − 1) = φ(γ1, . . . , γt−1) for some φ ∈ A. We will show that φ ≡ 0. By the definition of A, there are ci1,...,ˆij ,ˆij+1,...,it∈ C such that φ(γ1, . . . , γt−1) equals Xt− j= Xci1,...,ˆij ,ˆij+1,...,it < fi1, γ1 > . . . Z γj i i f1(w)dw Z γj+1i i f1(w)dw < fij+2 , γj+2 > . . . fit for all γi ∈ Γ. The inner sum ranges over all (i1, . . . ,ˆij ,ˆij+1, . . . , it) such that (ij+2 . . . , it) ∈ I and the hat indicates missing index. The term corresponding to j = t − 1 is understood to end with R γt−1i i f1(w)dwf1. With (3.34), an induction shows that, for some a l i1,... , bl ij+2,... ∈ C, the sum can be re-written as Xt− j= X l X 0<|ik|≤g a l i1,...,ij−1 < fi , γ1 > · · · × Z γj i i f1(w)dw Z γj+1i i f1(w)dw X 0<|ik|≤g b l ij+2,...,it−1 < fij+2 , γj+2 > . . . fit (3.40) 21with Z γj+1i i f1(w)dw X 0<|ik|≤g b l ij+2,...,it−1 < fij+2 , γj+2 > . . . fit = G|2(γj+1 − 1). . .(γt−1 − 1) for some G ∈ S t−j . This implies that, if we consider γ1, . . . , γt−2 fixed for the time being, each term in (3.40) except for that corresponding to j = t − 1 is a multiple of a G|2(γt−1 − 1) for some G ∈ S . Hence, if (F −L)|2(γ1 −1). . .(γt−1 −1) = φ(γ1, . . . , γt−1), then there is a second-order form G1 and a µt−1 ∈ C (which will normally depend on γ1, . . . , γt−2) such that G1|2(γt−1 − 1) = µt− Z γt−1i∞ i∞ f1(w)dwf Prop. 5.2 of [DO] implies that µt−1 = 0. Therefore, φ(γ1, . . . , γt−1) equals the expression in (3.40) but with one term less. We can continue the 'descent' this way by noting each term on the right-hand side except for the last one is a multiple of a G|2(γt−2 − 1)(γt−1 − 1) for some G ∈ S . Therefore, there is a G2 ∈ S such that G2|2(γt−2 − 1)(γt−1 − 1) = Xcit Z γt−2i∞ i∞ f1(w)dw Z γt−1i∞ i∞ f1(w)dwfit for some cit ∈ C and this, from Lemma 3.11, implies that all cit vanish. Continuing this way we deduce that φ ≡ 0. We will finally show that the Z's are linearly independent modulo S t− . Suppose that X (i1,...,it)∈I λi1,...,itZi1,...,it = 0. Then X (i1,...,it)∈I λi1,...,itZi1,...,it|2(γ1 − 1). . .(γt−1 − 1) = and by (3.34) (with s = t), we obtain X (i1,...,it)∈I λi1,...,it < fi1, γ1 > · · · < fit−1, γt−1 > fit + φ(γ1, . . . , γt−1) = 0, for some φ ∈ A. Since the set of all χi's is linearly independent and φ is a linear combination of < fi1, γ1 > · · · < fit−1, γt−1 > fit's with (i1, . . . , it) 6∈ I, we deduce that λi1,...,it = 0, for all (i1, . . . , it) ∈ I, i.e. the Z's are linearly independent. Corollary 3.13. Let g be the genus of Γ. The dimension of S t (Γ)/St− (Γ) (t ≥ 1) is 0 if g = 0, and (g + p g 2 − 1)t + (g − p g 2 − 1)t otherwise. Proof: According to the theorem, to prove the corollary in the case g 6= 0, it suffices to compute the cardinality at of I. If bt is the cardinality of I ′ , then, bt − at is the number of vectors in I ′ with it < 0. In particular, it 6= 1 and hence, bt − at = gbt−1. On the other hand, bt = 2gbt−1 − bt−2. (gbt− elements of I ′ have it < 0 and gbt−1 − bt−2 have it > 0 with (it−1, it) 6= (−1, 1)). The solution of this recursive relation with b1 = 2g, b2 = 4g 2 − 1 is bt = p g 2 − (g + p g 2 − 1)t+1 − (g − p g 2 − 1)t+ 22when g 6= 1 and bt = t + 1, when g = 1. The conclusion then follows from bt − at = gbt−1. The proof of the corollary in the case g = 0 follows by the observation that, for F ∈ S t (Γ), F|2(γ1 − 1). . .(γt−1 − 1) ∈ S2(Γ). (3.41) Since S2(Γ) = {0} when g = 0, this implies that F ∈ S t− (Γ) and hence S t (Γ)/St− (Γ) = {0}. Examples (with g 6= 0): t dim(S t (Γ)/St− (Γ)) 1 g 2 2g 2 − 3 4g 3 − 3g 4 8g 4 − 8g2 + 5 16g 5 − 20g3 + 5g 4. Higher Weights Our construction of the base of S t k for k > 2 and t > 1 relies on the base for S t− 2 we have just defined and it parallels the process we employed to construct the latter. We shall maintain the notation developed in the previous sections. First of all we note that Theorem 3.4 can be used just as well to construct forms of higher weight. Specifically, for every k > 2 and f ∈ At we set Yam(z, s; ¯f) := y −k/2Zam(z, s + k/2, 1, k; ¯f) = X γ∈Γa\\Γ Z γa a f(w)dwIm(σa − γz) s e(mσa − γz)j(σa − γ, z) −k . According to Theorem 3.4, it is analytic for Re(s) > 1 − k/2 − δΓ and it is easy to see that Yam(·, 0, F¯ i1,...,it− )|k(γ − 1) = Z γ−1a a Fi1,...,it− Pam(·)k + Xt− r= Z γ−1a a Fi1,...,ir Yam(·, 0, F¯ ir+1,...,it− ) (4.1) Here we set Pam(z)k := y −1Uam(z, 1, k), the Poincar´e series of weight k. There is a set of positive integers M such that {Pam(·)k}m∈M is a basis of Sk. Now, for Re(s) large we have: d dz¯ Yam(z, s; F¯ i1,...,it− ) = is 2y 1+k/ Zam(z, s + k/2, 1, k − 2; F¯ i1,...,it− ) By Theorem 3.4., Zam(z, s + k/2, 1, k − 2; F¯ i1,...,it− ) is holomorphic at s = 0, when k > 2 and hence Yam(z, 0; F¯ i1,...,it− ) is holomorphic in z. Thus we set Ym := Pam(·)k and Y−i1,...,−it−1;m = (−1)t−1Yam(z, 0; F¯ i1,...,it− ). With (4.1) we note that Y−i1,...,−it−1;m|k(γ1 − 1). . .(γt−1 − 1) = Z γ1a a fi . . . Z γt−1a a fit−1 Pam(·)k. 23In exactly the same way as Th. 3.9, we can show that Yi1,...,it;m ∈ S t k for ij ∈ {−1, . . . , −g}. We can now construct a basis for S t+ k by extending the definition of Yi1,...,it;m to all (i1, . . . , it) ∈ I ′ and m > 0: First, with Lemma 3.10, for (i1, . . . , it) ∈ I [Ym(z) Z z i Zi1,...,it(w)dw]|k(γ1 − 1). . .(γt − 1) = Pam(·)k < fi1, γ1 > · · · < fit−1, γt−1 > Z γti i fit(w)dw + φ(γ1, . . . , γt) for some φ ∈ Ak. Hence, for (i1, . . . , it) ∈ I we set Yi1,...,it;m := Ym(z) Z z i Zi1,...,it(w)dw. Next, if i1 < 0, and (i2, . . . , it) ∈ I, [Yi1;m(z) Z z i Zi2,...,it(w)dw]|k(γ1 − 1). . .(γt − 1) = X (φ,ψ)∈S2,t+ R γφ(1)i i fi1(w)dwPam(·)k Qt j=2 < fij , γψ(j) > R γψ(t)i i fit(w)dw + φ(γ1, . . . , γt) for some φ ∈ Ak. Therefore, as in Section 3.4, there is a linear combination of Ym(z) R z i Zj1,...,jt (w)dw's denoted by Ai1,...,it;m, such that [Yi1,m(z) Z z i Zi2,...,it(w)dw − Ai1,...,it;m]|k(γ1 − 1). . .(γt − 1) = Z γti i fi1(w)dwPam(·)k < fi2, γ1 > · · · < fit−1, γt−2 > Z γt−1i i fit(w)dw + φ(γ1, . . . , γt) for some φ ∈ Ak. Hence for (i1, . . . , it−1) ∈ I and it < 0 we can set Yi1,...,it;m(z) := Yit;m(z) Z z i Zi1,...,it−1(w)dw − Ait,i1,...,it−1;m. Further, if i1, i2 < 0 and (i3, . . . , it) ∈ I, [Yi1,i2;m(z) Z z i Zi3,...,it(w)dw]|k(γ1 − 1). . .(γt − 1) = X (φ,ψ)∈S3,t+ Z γφ(1)i i fi (w)dwZ γφ(2)i i fi (w)dwPam(·)k Yt j= < fij , γψ(j) > Z γψ(t)i i fit(w)dw+ φ(γ1, . . . , γt) for some φ ∈ Ak. Therefore, there is a linear combination of terms Ym(z) R z i Zj1,...,jt (w)dw's and Yj1;m(z) R z i Zj2,...,jt (w)dw's denoted by Bi1,...,it;m, such that [Yi1,i2;m(z) Z z i Zi3,...,it(w)dw − Bi1,...,it;m]|k(γ1 − 1). . .(γt − 1) = Z γt−1i i fi1(w)dwZ γti i fi2(w)dwPam(·)k < fi3, γ1 >· · · Z γt−2i i fit (w)dw + φ(γ1, . . . , γt) for some φ ∈ Ak. Hence for (i1, . . . , it−2) ∈ I and it−2, it−1 < 0 we can set Yi1,...,it;m(z) := Yit−1,it;m(z) Z z i Zi1,...,it− (w)dw − Bit−1,it,i1,...,it− . Continuing this way we cover the entire I ′ and hence we construct, for all (i1, . . . , it) ∈ I′ , functions Yi1,...it;m such that Yi1,...,it;m|k(γ1 − 1). . .(γt − 1) =< fi1, γ1 > · · · < fit, γt > Pam(·)k + φ(γ1, . . . , γt) (4.2) for some φ ∈ Ak. 24Theorem 4.1. If k > 4 and g is the genus of Γ, then the image of the set {Yi1,...,it;m; (i1, . . . , it) ∈ I ′ ; m ∈ M} under the natural projection is a basis of S t+ k (Γ)/St k (Γ). Therefore the dimension of S t+ k (Γ)/St k (Γ) is 0 if g = 0, (t + 1) dim(Sk(Γ)) if g = 1, and dim(Sk(Γ)) p g 2 − (g + p g 2 − 1)t+1 − (g − p g 2 − 1)t+ otherwise. Proof: Each Yi1,...,it;m is a (t + 1)-th order cusp form as the product of an order r < t + 1 cusp form and an order t + 2 − r modular form. Now, since the argument does not depend on the weight, we can show exactly as in the proof of Th. 3.12, that if F ∈ S t+ k , then F|k(γ1 − 1). . .(γt − 1) = X i1,...,it+ λi1,...,it < fi1, γ1 > · · · < fit, γt > Fit+1 . (4.3) Here Fi ranges over a basis of Sk. By (4.2) we then conclude that there is a linear combination L of functions in the set under consideration such that (F − L)|k(γ1 − 1). . .(γt − 1) = φ(γ1, . . . , γt) for some φ ∈ Ak. It is easy to see that Lemma 3.11 holds in weights > 2. The only adjustment required in the proof is that the construction of the analogue of Z′is based on Yi1,...,ir;m Z z i Z ′ ir+1,...,it instead of Z′ i1,...,ir R z i Z′ ir+1,...,it . We deduce that φ ≡ 0 and hence, our set spans S t+ k /St k . The proof that the set is linearly independent is deduced directly from (4.2), exactly as in Th. 3.12. The formula for the dimension in the case g > 0 is deduced by the formula for bt := #I ′ established in Cor. 3.13. In the case g = 0, the dimension is 0 because of (4.3). Examples (with g 6= 0): t dim(S t k (Γ)/St− k (Γ)) 2 2g dim(Sk(Γ)) 3 (4g 2 − 1) dim(Sk(Γ)) 4 (8g 3 − 4g) dim(Sk(Γ)) 5 (16g 4 − 12g2 + 1) dim(Sk(Γ)) Acknowledgments. The authors thank Paul Gunnells and Cormac O'Sullivan for several helpful comments. We are also indebted to the referee for a careful reading of the manuscript and for many useful suggestions. References [CD] Y. Choie, N. Diamantis, Rankin-Cohen brackets on higher-order modular forms, Proceedings of the Bretton Woods workshop on Multiple Dirichlet series (AMS Proceedings of Symposia in Pure Mathematics), 2006. [CDO] G. Chinta, N. Diamantis, C. O'Sullivan, Second order modular forms, Acta Arithmetica 103 (2002), 209–223. [CO] G. Chinta, C. O'Sullivan, Non-holomorphic Poincar´e series constructed from derivatives and antiderivatives of cusp forms and bounds on period polynomials (to appear). 25[DKMO] N. Diamantis, M. Knopp, G. Mason, C. O'Sullivan, L-functions of second-order cusp forms, Ramanujan Journal 12 (3) (2006), 327-347. [DO] N. Diamantis, C. O'Sullivan,, The dimensions of spaces of holomorphic second-order automorphic forms and their cohomology (to appear). [DS] N. Diamantis, R. Sreekantan,, Iterated integrals and higher order automorphic forms, Commentarii Mathematici Helvetici 81(2) (2006), 481-494. [FW] D. Farmer, K. Wilson, Converse theorems assuming a partial Euler product, The Ramanujan Journal. [GO] D. Goldfeld, C. O'Sullivan, Estimating additive character sums for Fuchsian groups, Ramanujan J. 7 (2003), 241-267. [I1] H. Iwaniec, Spectral methods of automorphic forms, 2nd ed., vol. 53, Graduate studies in mathematics, Amer. Math. Soc., 2002. [JO] J. Jorgenson, C. O'Sullivan., Convolution Dirichlet series and a Kronecker limit formula for second-order Eisenstein series, Nagoya Math J. 179 (2005), 1-56. [KZ] P. Kleban, D. Zagier, Crossing probabilities and modular forms, J. Stat. Phys. 113 (2003), 431-454. [M] Yu. Manin, Iterated integrals of modular forms and noncommutative modular symbols, Algebraic geometry and number theory, Progr. Math., 253 (2006), 565–597,. [PR] Y. Petridis, M. S. Risager, Modular symbols have a normal distribution, GAFA 14 (5) (2004), 1013–1043. [R] R. Ree, Lie elements and an algebra associated with shuffles., Ann. of Math. (2) 68 (1958), 210–220. [Sh] G. Shimura, Introduction to the Arithmetic Theory of Automorphic Functions, Princeton Univ. Press, 1971. 26\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper ID: 2309.13177v1\n",
      "\n",
      "Abstract: Given any polyhedron from which we select two random points uniformly and\n",
      "independently, we show that all the moments of the distance between those\n",
      "points can be always written in terms of elementary functions. As an\n",
      "illustration, the mean distance is found in the exact form for all Platonic\n",
      "solids.\n",
      "\n",
      "Clean Text: \n",
      "2.1 Crofton Reduction Technique . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2 Auxiliary integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 Irreducible configurations of the reduction technique 3.1 Polygon and a point . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 Two skewed line segments . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3 Overlap formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 General and special polyhedra 4.1 General polyhedra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2 Nonparallel polyhedra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3 Nonparallel convex polyhedra . . . . . . . . . . . . . . . . . . . . . . . . . . 4.4 Tetrahedron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Mean distance in regular polyhedra 5.1 Regular tetrahedron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1.1 L20 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1.2 L11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1.3 L33 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2.1 L20 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2.2 L11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2.3 L21r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2.4 L22r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2.5 L33 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.3 Regular octahedron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.3.1 L20 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.3.2 L11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.3.3 L21r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.3.4 L22r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.3.5 L33 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4 Regular icosahedron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.1 L11d . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.2 L11g . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.3 L11f . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.4 L11t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.5 L20e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.6 L20r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.7 L20f . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.8 L21r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.9 L22r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4.10L33 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5 Regular dodecahedron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.1 L11d . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.2 L11g . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.3 L11f . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.4 L11t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.5 L20e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.6 L20r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.7 L20f . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.8 L22r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.9 L21r . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5.10L33 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 Further remarks 6.1 Weights . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.2 General convex polyhedra . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.3 Bounds on moments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . References A Exact mean distances in regular polyhedra B Auxiliary integrals 21 Introduction Let K be a polyhedron1, from which we select two random points X and Y uniformly and independently. Let L = ∥X − Y ∥ be the distance between them and L (p) KK = E [L p | X ∈ K, Y ∈ K] its p-th statistical moment. Even-power moments are trivial to compute. The value L (p) KK has been known in the exact form only for K being a ball (trivial) or (for p = 1) a unit cube [5], known as the so called Robbins constant E [L] = + 17√ − √ − π + arccoth √2 + arccoth √3 ≈ 0.66170718. (1) Recently, Bonnet, Gusakova, Thäle and Zaporozhets [1] found a sharp optimal bound on the normalised mean distance ΓKK = LKK/V1(K) in convex and compact K, where V1(K) = 2 H ∂B1(0) ∥ projˆr K∥ dˆr is the first intrinsic volume of K. A special case of their result in three dimensions gives 28 < ΓKK < . As stated in [1], although the first intrinsic volume is easy to express in any polyhedron, number of examples for which an exact formula for LKK is available is rather limited. We will show that this might not be the case and indeed one can find LKK (and all natural moments L (p) KK) in an exact form easily for any K being a polyhedron. The main result of our own investigation is thus the following theorem: Theorem 1. For any given polyhedron, the mean distance between two of its inner points selected at random can be always expressed in terms of elementary functions of the location of its vertices and sides. The same holds for all other natural moments. Remark 1. By elementary functions, we mean closed field of functions containing radicals, exponential, trigonometric and hyperbolic functions and their inverses. The theorem is solely based on the Crofton Reduction Technique (CRT), see [3, 6], which under certain conditions enables us to express L (p) KK as some linear combination of L (p) AB = E [L p | X ∈ A, Y ∈ B] over domains A and B with smaller dimension than that of K. In fact very recently, using different methods, Ciccariello [2] showed that the so called chord-length distribution, which is related with the distribution of L, can also be expressed in terms of elementary functions in any polyhedron K. 2 Preliminaries 2.1 Crofton Reduction Technique Definition 1. A polytope A ⊂ R d of dimension dim A = a ∈ {0, 1, 2, . . . , d} and a−volume vol A is defined as a connected and finite union of a-dimensional simplices. We say a polytope is flat if dim A(A) = dim A, where A(A) stands for the affine hull of A. Note that any polytope with a = d is flat automatically. In this paper, a polyhedron is a three-dimensional polytope, not necessarily convex in general. 3Definition 2. We denote Pa(R d ) the set of flat polytopes of dimension a in R d and denote P(R d ) = S 0≤a≤d Pa(R d ) the set of all flat polytopes in R d . Finally, we denote P+(R d ) = P(R d ) \\ P0(R d ) (flat polytopes excluding points). Definition 3. Let A, B ∈ P(R d ) and P : R d × Rd → R, we denote PAB = E [P(X, Y )| X ∈ A, Y ∈ B, uniform and independent]. Whenever it is unambiguous, we write Pab where a = dim A and b = dim B instead of PAB. If there is still ambiguity, we can add additional letters after as superscripts to distinguish between various mean values Pab. Proposition 2. For any A ∈ Pa(R d ) with a > 0, there exist convex ∂iA ∈ Pa−1(R) (sides of A) such that ∂A = S i ∂iA with pairwise intersection of ∂iA having (a−1)-volume equal to zero. Remark 2. The sides of three dimensional polytopes (polyhedra) are called faces. Definition 4. Let A ∈ P+(R d ). Let ˆni be the outer normal unit vector of ∂iA in A(A), then we define a signed distance hC(∂iA) from a given point C ∈ A(A) to ∂iA as a scalar product ⟨vi, ˆni⟩, where vi = xi − C and xi ∈ ∂iA arbitrary. Note that if A is convex, the signed distance coincides with the support function h(A−C, ˆni) defined for any convex domain B as h(B, ˆni) = supb∈B⟨b, ˆni⟩. Remark 3. The signed distance has another geometric interpretation. Put C = O (the origin) and r = 1+ε (with ε small). Denote R (B,A) = R B/A − R A/B, by linearity RB = R A + R (B,A) . Hence vol(rA) = Z rA dx = Z A dx + Z (rA,A) dx = vol A + ε X i vol(∂iA)hO(∂iA) + O(ε ), (2) or in other words, d vol(rA)/dr|r=1 = P i vol(∂iA)hO(∂iA) for A arbitrary (possibly nonconvex). Definition 5. Let A ∈ P+(R d ) with a = dim A. Even though ∂A /∈ P(R d ), we still define P∂A B for a given point (called a scaling point) C ∈ A(A) as a weighted mean via the relation P∂A B = X i wiP∂iA B (3) with weights wi equal to wi = vol(∂iA) a vol A hC(∂iA). (4) Definition 6. Let P : R d × Rd → R. We say P is homogeneous of order p ∈ R, if there exists P˜ : R d → R such that P(x, y) = P˜(x − y) for all x, y ∈ Rd and P˜(rv) = rpP˜(v) for all v ∈ R d and all r > 0. We write p = dim P (although p might not be an integer). We say P is even if P(x, y) = P(y, x). Remark 4. Note that if P is even, then PAB = PBA for any domains A and B. Example 1. If P = L p , or more precisely P(x, y) = L p (x, y) = ∥x − y∥ p , then P is even and homogeneous of dim P = p and with P˜(x) = ∥x∥ p . Whenever P = L p , we will use PAB and L (p) AB interchangeably throughout this paper. 4Lemma 3 (Crofton Reduction Technique). Let P : R d × Rd → R be homogeneous of order p and A, B ∈ P(R d ), then for any C ∈ A(A) ∩ A(B) holds pPAB = a(P∂A B − PAB) + b(PA ∂B − PAB). (5) * Figure 1: Crofton Reduction Technique Proof. The formula is a special case of the extension of the Crofton theorem by Ruben and Reed [6], although it is fairly simple to derive directly. Let r = 1 + ε and put C = O (the origin) without loss of generality. The key is to express PrA,rB in two different ways: • By definition, PrA,rB = E [P(X, Y )| X ∈ rA, Y ∈ rB, uniform] = E [P(rX′, rY ′)| X ′ ∈ A, Y ′ ∈ B, uniform] = r p E [P(X′ , Y ′)| X ′ ∈ A, Y ′ ∈ B, uniform] = rpPAB = PAB + εpPAB + O(ε ). • On the other hand, vol(rA) vol(rB)PrA,rB = vol(rA) vol(rB)E [P(X, Y )| X ∈ rA, Y ∈ rB, uniform] = Z rA Z rB P(x, y) dxdy = Z A Z B P(x, y) dxdy + Z (rA,A) Z B P(x, y) dxdy + Z A Z (rB,B) P(x, y) dxdy + Z (rA,A) Z (rB,B) P(x, y) dxdy = vol A vol BPAB + ε vol B X i vol(∂iA)hO(∂iA)P∂i AB + ε vol A X j vol(∂jB)hO(∂jB)PA ∂jB + O(ε ). Comparing the ε terms of both expressions and using Remark 3, we get the statement of the lemma. If either of dim A or dim B is zero, the lemma holds too. ■ 2.2 Auxiliary integrals Apart from rotations and reflections, any integral encountered in our paper has the following form (h > 0) I (p) f (h, ζ, γ) = Z D(ζ,γ) f(x, y) h 2 + x2 + y p/ dxdy, (6) 5where D(ζ, γ) is the fundamental triangle domain with vertices [0, 0], [ζ, 0], [ζ, ζ tan γ] (ζ > 0, 0 < γ < π/2) and f(x, y) is a polynomial in x and y of degree at most two (quadratic in x and y). We can write f(x, y) = a00 +a10x+a01y +a20x 2 +a11xy +a02y . Based on x and y terms, we have the following I (p) f (h, ζ, γ) = a00I (p) 00 (h, ζ, γ) + a10I (p) 10 (h, ζ, γ) + a01I (p) 01 (h, ζ, γ) + a20I (p) 20 (h, ζ, γ) + a11I (p) 11 (h, ζ, γ) + a02I (p) 02 (h, ζ, γ), (7) where I (p) ij (h, ζ, γ) = Z D(ζ,γ) x i y j h 2 + x2 + y p/ dxdy. (8) The parameters of those integrals are not optimal. We only need to consider the case h = 1. To see this, denote I (p) ij (q, γ) = I (p) ij (1, q, γ) = Z D(q,γ) x i y j 1 + x 2 + y p/ dxdy. (9) By scaling x → hx, y → hy, we can write I (p) ij (h, ζ, γ) = h 2+p+i+j I (p) ij (ζ/h, γ). (10) Thus, with q = ζ/h, I (p) f (h, ζ, γ) = h 2+p a00I (p) 00 (q, γ) + a10hI(p)10 (q, γ) + a01hI(p)01 (q, γ) + a20h I (p) 20 (q, γ) + a11h I (p) 11 (q, γ) + a02h I (p) 02 (q, γ) . (11) Selected values of the auxiliary integrals I (p) ij (q, γ) and the methods how we can derive them are found in the appendix. 3 Irreducible configurations of the reduction technique Repeated use of the latter Lemma we refer to as the Crofton Reduction Technique. To find the moments of L, we put P = L p . In the first step, we choose A = K and B = K. Since the affine hulls of both A and B fill the whole space R d , any point in R d can be selected for C. We then employ the reduction technique to express PAB in PA′B′ where A′ and B′ have smaller dimensions then A and B. The pairs of various A′ and B′ we encounter we call configurations. The process is repeated until the affine hull intersection of A′ and B′is empty. In that case, we have reached an irreducible configuration. From now on in the rest of our paper if not explicitely stated, d = 3. The following configurations are irreducible in R : • A is a polygon and B is a point • A and B are two skew line segments • A and B are two parallel polygons or one polygon and one line segment parallel to it 63.1 Polygon and a point In the first case, A is a polygon and B a point. Denote projA(·) a perpendicular projection onto A(A). Next, denote h the distance between B and A(A). With k = x − projA B where x ∈ A, we have that L (p) AB = vol A Z A (h 2 + k ) p/ dk (12) is expressible in terms of elementary functions. To see this, write and ∂iA, i = 1, . . . , s for the sides of the polygon A, oriented such that the path through the vertices of A is counterclockwise. Then, by inclusion/exclusion, and switching to polar coordinates L (p) AB = vol A Xs i= Z Ti (h 2 + k ) p/ dk = vol A Xs i= Z βi αi Z hi/ cos φ (h 2 + r ) p/ r drdφ (13) where Ti is a signed triangle whose one vertex is the point proj B and the other two vertices are the consecutive endpoints of ∂iA. Rescaling the vector k by h, we can rewrite each integral in the sum in a standard way Z Ti (h 2 + k ) p/ dk = h 2+p I (p) 00 (hi/h, βi) − I (p) 00 (hi/h, αi) (14) where αi and βi are their respective polar angles (in counterclockwise order) and hiis the perpendicular distance from proj B to ∂iA. The polar angles are defined such that the closest point on the line A(∂iA) from proj B has its value equal to zero, increasing in the clockwise direction (see Figure 2). The integral is positive if the angle of consecutive vertices of the polygon increased and negative if it decreased. Figure 2: Point-polygon triangle decomposition Summing all contributions, we finally get our point-polygon formula L (p) AB = h 2+p vol A Xs i= I (p) 00 (hi/h, βi) − I (p) 00 (hi/h, αi) . (15) 73.2 Two skewed line segments The second case is in fact equivalent with the first. If A and B are two skew line segments, write A − B = {u − v | u ∈ A, v ∈ B} (which is a parallelogram). Then, by shifting, we get for any homogeneous P, denoting O as the origin PAB = PO,A−B. (16) So we can always reduce this problem to the polygon and a point problem treated before. 3.3 Overlap formula From now on, in case of no ambiguity, we often write simply proj instead of projA for the perpendicular projection operator onto A(A). Proposition 4. Let A, B ∈ P+(R ), a = 2, b ∈ {1, 2}, such that A(A) and A(B) are parallel with perpendicular separation vector s having length h = ∥s∥. Let P(x, y) be homogeneous and let k be a vector lying in the projection plane A(A), then PAB = vol A vol B Z A Z B P˜(x − y) dxdy = vol A vol B Z R P˜(s + k) vol(A ∩ (proj B + k)) dk. (17) Especially, for P = L p , we get L (p) AB = vol A vol B R R2 (h 2 + k ) p/2 vol(A ∩ (proj B + k)) dk. Figure 3: Overlap formula Remark 5. Since vol(A∩(proj B+k)) is a piece-wise polynomial function of degree at most two on polygonal domains, the double integral is expressible in terms of elementary functions for any integer p > −3. Proof. Let A, B ⊂ R d be compact domains with dimensions a and b, respectively, and P be even homogeneous function R d → R of order p > −3. Let AB(z) = A ∩ (B + z), c = maxz∈Rd dim AB(z) and C = {z ∈ R d | dim AB(z) = c}. Then, by substitution y = x + z and by Fubini's theorem, PAB = vol A vol B Z A Z B P˜(x − y) dxdy = vol A vol B Z C P˜(z) vol AB(z) dz. (18) When A, B are parallel in d = 3, the proposition follows. ■ 8Definition 7. An overlap diagram of A (face) and B (parallel face or edge) consists of partitions of R into open subdomains Di where vol(A ∩ (proj B + k)) can be expressed as a single polynomial function in k of degree at most two. Since A and B are polygons (or a polygon and a polyline, respectively), these subdomains Di are also polygonal (polylinial, respectively). When there is no ambiguity, we denote those subdomains Di by numbers corresponding to the number of sides of the polygon A ∩ (proj B + k) of intersection in case B is a face, or the number of line segments of the polyline A ∩ (proj B + k) of intersection when B is an edge, respectively Remark 6. For brevity, we often write vol(A ∩ proj B + k) instead of vol(A ∩ (proj B + k)). 4 General and special polyhedra 4.1 General polyhedra Theorem 5. Let K ∈ P(R ), Ej, Fk, j ∈ {1, . . . , e}, k ∈ {1, . . . , f}, denote the edges and faces of K, respectively, and let P : R d × Rd → R be even and homogeneous of order p > −3. Then PKK = (6 + p)(5 + p) X k<k′ PFkFk′wFkFk′ + X j PKEjwKEj , (19) with weights wAB (independent on P and p) given as follows: We fix C any point in R , Ck any point on A(Fk) and Dj any point on A(Ej ). Denote Fk(j), Fk ′(j) the two faces on which lies the edge Ej , then wFkFk′ = vol(Fk) vol(Fk ′) vol2K (hC(Fk)hCk(Fk ′) + hC(Fk′)hCk′ (Fk)), (20) wKEj = vol K vol(Ej ) vol2K hC(Fk(j))hCk(j)(Dj ) + hC(Fk ′(j))hCk′(j) (Dj ) . (21) Proof. Use the Crofton Reduction Technique twice. ■ Remark 7. Note that the weights are not unique as they depend on the position of scaling points. Remark 8. Note that if P = L p and for any polyhedron K, all terms PAB in Equation (19) are either further reducible or A and B are parallel. In both cases, we can express L (p) AB in terms of auxiliary integrals. Theorem 1 follows. 4.2 Nonparallel polyhedra For polyhedra which have some special properties, we are able to further reduce Theorem 5 above. Definition 8. Let P ∗ (R ) denote the set of all polyhedra having the property that affine hulls of any of its three faces of meet at a single point. We call them nonparallel polyhedra. Also, we denote P ∗ convex(R ) a subset of those which are convex. 9Theorem 6. Let K ∈ P∗ (R ) and Vi, Ej, Fk, i ∈ {1, . . . , v}, j ∈ {1, . . . , e}, k ∈ {1, . . . , f}, denote the vertices, edges and faces of K, respectively, and P be even and homogeneous of order p > −3. Then PKK = (6 + p)(5 + p)(4 + p)(3 + p) X ik Vi∈A/ (Fk) PViFkwViFk + X j<j′ A(Ej )∩A(Ej ′ )=∅ PEjEj ′wEjEj′ (22) for some weights wAB which are independent on P and p. Proof. Since no pair of faces nor edges are parallel, we can further reduce PFkFk′ and PKEj from Theorem 5 twice. The weights are easily computable by choosing appropriate scaling points. Note that again the weights are not unique and depend on the selection of those scaling points. For example, let C ∈ A(Fk) ∩ A(Fk ′), k < k′ . Then by CRT, we get PFkFk′ = 4 + p P∂FkFk′ + PFk∂Fk′ . (23) Note that both P∂FkFk′ and PFk∂Fk′ are expressible as some linear combination of PEiFk with A(Ei) ∩ A(Fk). Finally, we can reduce even this term. Let C ′ ∈ A(Ei) ∩ A(Fk), then P EiFk = 2 + p (P∂EiFk + 2PEi∂Fk), (24) which in turn is expressible as a linear combination of PViFk and PEiEi ′ with Vi ∈ A/ (Fk) and A(Ei) ∩ A(Ei ′) = ∅. The reduction of terms PKEj is similar. ■ 4.3 Nonparallel convex polyhedra In the case of convex nonparallel polyhedra, we can find very simple relations for weights wAB. First, we start with a known formula (a simple generalisation of [4, Eq. 34] in d = 3) Lemma 7. Let K be a convex and compact set in R 3 and P even homogeneous of order p > −3, then PKK = 1/ vol2K (4 + p)(3 + p) I B1(0) Z Σ⊥(ˆr) P˜(ˆr) Λ4+p Q (ˆr) dQdˆr, (25) where the integration in carried over all directions ˆr on the unit sphere B1(0) with surface measure dˆr having Hdˆr = 4π and over all points Q on plane Σ⊥(ˆr) passing through the origin and being perpendicular to ˆr. Finally, ΛQ(ˆr) denotes the length of the intersection of K and the line passing through Q in the direction of unit vector ˆr. Corollary 7.1. By Fubini's theorem, lim p→−3+ (3 + p)PKK = vol K I B1(0) P˜(ˆr) dˆr (26) Remark 9. Similar formulae are available in higher dimensions as well. 10Theorem 8. Let K ∈ P∗ convex(R ) and Vi, Ej, Fk, P, wAB be defined exactly as in Theorem 6. Denote hik the distance between Vi and A(Fk), similarly denote hjj′ the distance between O and A(Ej − Ej ′) and θjj′ the angle between Ej and Ej ′ (on the same plane under perpendicular projection). Then PKK = 12/ vol K (6 + p)(5 + p)(4 + p)(3 + p) X ik Vi∈A/ (Fk) PViFk nViFk vol(Fk)hik + X j<j′ A(Ej )∩A(Ej ′ )=∅ PEjEj ′nEjEj′ vol(Ej ) vol(Ej ′)hjj′ sin θjj′ , (27) with weights nAB satisfying the following projection relation: Choose a direction ˆn and project K onto a plane perpendicular to it. Then the weights corresponding to vertex-face pairs which overlap and to pairs of edges which cross add up to one. Symbolically, 1 = X ik Vi∈A/ (Fk) nViFk1ˆn∈ViFk + X j<j′ A(Ej )∩A(Ej ′ )=∅ nEjEj ′ 1ˆn∈EjEj′ , (28) where 1ˆn∈AB = 1 if there are points x ∈ A, y ∈ B such that x − y is parallel with ˆn, otherwise 1ˆn∈AB = 0. On top of that, the extreme case where one of the points x, y lies on the boundary of A or B leaves the value 1ˆn∈AB undefined. Proof. The key observation is that the weights are independent of the choice of the function P as long it is even and homogeneous. Let ε > 0 be small and ˆn be a fixed unit vector, Ωε = πε2 + O(ε ) then denotes a solid angle with apex half angle equal to ε. We define R(p)(ε, ˆn, x, y) = ∥x−y∥ p if the angle between ˆr and x−y is smaller than ε and zero otherwise. Alternatively, denote C(ε, V, ˆn) a double-cone region whose vertex is V , apex angle 2ε and the axis has direction ˆn. Then for any domains A and B, R (p) AB(ε, ˆn) = Z A Z B R (p) (ε, ˆn, x, y) dy dx = Z A Z B∩C(ε,x,ˆn) ∥x − y∥ p dy dx. (29) Note that R is even and homogeneous in x, y of order p. Hence, by Lemma 7, lim p→−3+ (3 + p)R (p) KK(ε, ˆn) = vol K I B1(0) R˜(−3)(ε, ˆn,ˆr) dˆr = 2Ωε vol K + O(ε ). (30) On the other hand, via Theorem 6, lim p→−3+ (3 + p)R (p) KK(ε, ˆn) = 2 X ik Vi∈A/ (Fk) R (−3) ViFk (ε, ˆn)wViFk + X j<j′ A(Ej )∩A(Ej ′ )=∅ R (−3) EjEj ′ (ε, ˆn)wEjEj ′ . (31) We are able to express R (−3) ViFk (ε, ˆn) and R (−3) EjEj ′ (ε, ˆn) in the following way: R (−3) ViFk (ε, ˆn) = Ωε1ˆn∈ViFk vol(Fk)hik + O(ε ), R(−3) EjEj ′ (ε, ˆn) = Ωε1ˆn∈EjEj ′ vol(Ej ) vol(Ej ′)hjj′ sin θjj′ + O(ε ). (32) 11We will prove only the first equality as the other one is get simply by shifting (edge-edge configuration is equivalent to vertex-face configuration by means of Equation (16)). Let Vi ∈ A / (Fk) for some (polygonal) face Fk and vertex Vi. We denote by r the distance between Vi and the point of intersection of A(Fk) and the line passing through the vertex Viin the direction of ˆn. Note that the perpendicular distance hik between Vi and A(Fk) is independent on the direction of ˆn. Since ε is small, we can write R (p) ViFk (ε, ˆn) = vol(Fk) Z Fk R (p) (ε, ˆn, x, Vi) dx = r p vol(Fk ∩ C(ε, Vi , ˆn)) vol(Fk) + O(ε ) (33) Assuming ˆn ∈ ViFk, the point of intersection lies in the interior of Fk. Hence, for sufficiently small ε, we get that Vi ∩ C(ε, Vi , ˆn) is an ellipse with area vol(Vi ∩ C(ε, Vi, ˆn)) = 1ˆn∈ViFk Ωεr hik + O(ε ) (34) Hence R (p) ViFk (ε, ˆn) = vol(Fk) Z Fk R (p) (ε, ˆn, x, Vi) dx = r 3+pΩε1ˆn∈ViFk vol(Fk)hik + O(ε ) (35) when p = −3, the dependency on r vanishes. Finally, comparing this relation with (30), we get the equation for weights vol K = X ik Vi∈A/ (Fk) wViFk1ˆn∈ViFk vol(Fk)hik + X j<j′ A(Ej )∩A(Ej ′ )=∅ wEjEj ′ 1ˆn∈EjEj ′ vol(Ej ) vol(Ej ′)hjj′ sin θjj′ (36) valid for any ˆn for which all the values 1ˆn∈AB are well defined. Lastly, defining auxiliary weight nAB via wViFk = vol(Fk)hiknViFk vol K , wEjEj ′ = vol(Ej ) vol(Ej ′)hjj′nEjEj ′ sin θjj′ vol K , (37) we get 1 = X ik Vi∈A/ (Fk) nViFk1ˆn∈ViFk + X j<j′ A(Ej )∩A(Ej ′ )=∅ nEjEj ′ 1ˆn∈EjEj′ . (38) This constrain alone enables us to determine admissible weights for any convex nonparallel polyhedron via set of linear equations got by varying the direction of ˆn. ■ 4.4 Tetrahedron As an example, we express the random distance moments in the case of a tetrahedron. There are two possible ways how a planar projection of a tetrahedron could look like (almost surely) with respect to the number of intersecting pairs of edges and vertices/faces in the projection (see Figure 4). In the first case, one vertex covers one face. There are no other vertex/face nor edge/edge coverings. Similarly, in the second case, one edge is covered by another 12Figure 4: Tetrahedron projection orientations edge. There are again no other coverings. Thus, in order to satisfy Equation (28), we can simply choose nViFk = nEjEj ′ = 1 for each vertex Vi, face Fk and edges Ej , Ej ′. Hence, by Theorem 8, PKK = 12/ vol K (6 + p)(5 + p)(4 + p)(3 + p) X ik Vi∈A/ (Fk) PViFk vol(Fk)hik + X j<j′ A(Ej )∩A(Ej ′ )=∅ PEjEj ′ vol(Ej ) vol(Ej ′)hjj′ sin θjj′ . (39) 5 Mean distance in regular polyhedra To apply our general method, we shall derive the mean distance in all five regular polyhedra (also known as Platonic solids). Among those solids, only the tetrahedron is nonparallel convex, so Theorem 8 applies here. Hence, we used this theorem to find the mean distance in a general (possibly irregular) tetrahedron. In the rest of our paper, we calculate the mean distance in all other Platonic solids (including the regular tetrahedron again). Since they are an example of parallel polyhedra, we cannot use Theorem 8 due to presence of irreducible configurations of type face-face and edge-face. However, we can still calculate the mean distance. The calculation relies the Overlap formula as well as the symmetries of those regular polyhedra which drastically reduce the number of configurations needed to be considered. Throughout this section, we denote ν the area of (any) face of K and l the length (any) of its edge. These values makes sense because K is a regular polyhedron. Furthermore, ϕ = 1+√ is the Golden ratio. 5.1 Regular tetrahedron Let us have P even homogeneous of order p dependent on two random points picked from K a regular tetrahedron given by vertices V1[1, 0, 0], V2[0, 1, 0], V3[0, 0, 1], V4[1, 1, 1], edges connecting them E12, E13, E14, E23, E24, E34 (Eij = ViVj , where i ̸= j) and with opposite faces F1, F2, F3, F4. Note that vol K = 1/3, so if we want to express the mean of P in a tetrahedron of unit volume, we must multiply all our results by p/ . We put P = L p . For the definition of various mean values Pab = L (p) ab , see Figure 5. We also included the position of the scaling point C in cases reduction is possible. The arrows indicate which configurations reduce to which. 13* * * * * * * * Figure 5: All different L (p) ab configurations encountered for K being a regular tetrahedron Based on CRT, let us write our reduction system of equations: pP33 = 6(P32 − P33) pP32 = 3(P22 − P32) + 2(P31 − P32) pP22 = 4(P21 − P22) pP31 = 3(P21 − P31) + 1(P30 − P31) pP21 = 2(P11 − P21) + 1(P20 − P21) pP30 = 3(P20 − P30), where P33 = PKK and by symmetry, we can put P32 = PKF1, P31 = PKE12 , P30 = PKV1, P22 = PF1F2, P21 = PF4V14 , P20 = PF4V4, P11 = PE12E34 . This linear system has a solution P33 = 72(3P11 + 2P20) (6 + p)(5 + p)(4 + p)(3 + p) . (40) To demonstrate our technique for irreducible configurations, we derive the value of L33. That means, we choose P = L p with p = 1. 5.1.1 L By (15), by symmetry and using vol(F4) = √ 3/2, h1 = 1/ √ 6, h = 2/ √ 3, P20 = L (p) F4V4 = 6h 2+p vol(F4) I (p) 00 √ , π ! . (41) Using the recursion relations, I (1) 00 √ , π ! = 16√ − π + arcsin r + 96√ arcsinh √ , (42) so, further using arcsin p2/3 = arctan √2 and arcsinh(1/ √ 3) = ln 3, L20 = √ − 32π + arctan √2 + 25 ln 18√ . (43) 145.1.2 L By shifting (16), we get L11 = LAB, where B is the origin and A is a parallelogram with vertices [1, 0, −1], [0, 1, −1], [−1, 0, −1], [0, −1, −1]. Therefore, by the point-polygon formula (15) with h = 1 and vol A = 2, L11 = 8h vol A I (1) 00 √ , π ! , (44) where by recurrences, I (1) 00 √ , π ! = √ − π + arcsin √ + 12√ arcsinh √ . (45) Hence, writing arcsin 1/ √ = π 2 − arctan √ 2 and arcsinh(1/ √ 3) = ln 3, L11 = √ + π − arctan √2 + 7 ln √ . (46) 5.1.3 L Substituting L20 and L11 into (40) with P = L p and p = 1, we get, finally L33 = (3L11 + 2L20) = √ − 37π + arctan √2 + 113 ln 210√ . Or, re-scaling to the unit volume tetrahedron, L vol K=1 = √ √ − 37π + arctan √ 2 + 113 ln 210√ ! ≈ 0.72946242, (47) which is an exact expression of an approximation given by Weisstein [7]. Similarly, we would proceed in the case of the second moment: L (2) vol K=1 = 10√ . (48) Alternatively, we can express the result as the normalised mean distance ΓKK. Since V1(K) = 3√ 2 arccos − /π (see Table 3 with a = √ 2), we have ΓKK = L V1(K) = π √ 2 arccos − √ − 37π + arctan √2 + 113 ln 210√ ! ≈ 0.19601928. (49) Of course, using the reduction technique, we could get other moments (replacing I (1) ij by I (p) ij integrals), and even for a general edge-length tetrahedron. 155.2 Cube We present a re-derivation of the Robbins constant for K being a cube via our method. Here, we demonstrate the Crofton Reduction Technique including the overlap formula. A standard way how to choose its vertices is [0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 0], [1, 1, 1]. Under this choice, the edge length l = 1, face area ν = 1 and the volume vol K = 1. We put P = L p . For the definition of various mean values Pab = L (p) ab , see Figure 6. Note that in L21r configuration, we let B to be four edges (boundary of an opposite face) rather than just one edge. * * * * * * Figure 6: All different L (p) ab configurations encountered for K being a cube Performing the reduction, we get the set of equations, where pP33 = 6(P32 − P33), pP32 = 3(P22 − P32) + 2(P31 − P32), pP22e = 4(P ′ 21 − P22e), pP31 = 3(P21 − P31) + 1(P30 − P31), pP21v = 2(P11 − P21v) + 1(P20 − P21v), pP30 = 3(P20 − P30) with P22 = P22e + P22r, P21 = P21v + P21r, P ′ 21 = P21v + P21r. Solving the system, we get P33 = 72(P11 + P20) (3 + p)(4 + p)(5 + p)(6 + p) + 48P21r (4 + p)(5 + p)(6 + p) + 6P22r (5 + p)(6 + p) . (50) 16When p = 1, we get for the mean distance L33 = (3L11 + 3L20 + 8L21r + 5L22r). (51) 5.2.1 L Without loss of generality, we can write L20 = LAB, where A is the cube's upper face defined as a square with vertices [0, 0, 1], [1, 0, 1], [1, 1, 1], [0, 1, 1] and B is the origin [0, 0, 0]. Domains A and B are separated by distance h = 1. The face A is having area vol A = 1. By (15) and by symmetry, L20 = vol A I (1) 1, π . (52) Using recurrence relations (see Table 5 in Appendix), L20 = √ − π + arccoth √ 3. (53) 5.2.2 L The value L11 can be defined as a mean distance between egde E1 = [0, 0, 0][0, 1, 0] and edge E2 = [0, 1, 1][1, 1, 1]. Shifting E1 by vector −E2 (See shifting relation (16)), we can rewrite this as L11 = LAB, where again A is the upper face of the cube and B is the origin. Hence L11 = L20. 5.2.3 L21r Since the reduction technique cannot be applied on AB being parallel, we use the overlap formula with A being one face of the cube. In case of L21r, the other domain B is an opposite edge. By symmetry, we can add to this edge also three other edges opposite to A (see Figure 6). Hence, B is a boundary of the face opposite to A with length vol B = 4. Let k = (x, y) then proj A = proj B is a square with vertices [ , ], [− , ], [− , − ], [ , − ]. In order to proj A and proj B + k have nonzero intersection, k must be confined in the region −1 < x < 1 ∧ −1 < y < 1. By symmetry, we can chose k to lie in the fundamental triangle domain D(1, π/4) (we then multiply the values by 8). symmetry Figure 7: Overlap of the opposite face and edges of a cube 17Setting up the integral, L21r = vol A vol B Z D √ h 2 + k2 vol(A ∩ proj B + k) dk, (54) where h = 1, vol A = 1, vol B = 4 and D = D(1, π/4) is a domain in Figure 7 on the right (labeled with the number 2). In this domain, we can write for the length of the polyline of intersection vol(A ∩ proj B + k) = 2 − x − y, (55) which gives us in terms of our auxiliary integrals L21r = vol A vol B \" 2I (1) 1, π − I (1) 1, π − I (1) 1, π # (56) Via recursions (see Table 5 in Appendix), we get L21r = √ − √ − π + arccoth √ 2 + arccoth √ 3. (57) 5.2.4 L22r Again, we use the overlap formula for AB being opposite faces. By symmetry, we again integrate vol(A ∩ proj B + k) over one eighth of all positions of k (see Figure 8). symmetry Figure 8: Overlap of the opposite faces of a cube Setting up the integral, L22r = vol A vol B Z D √ h 2 + k2 vol(A ∩ proj B + k) dk, (58) where h = 1, vol A = vol B = 1 and D = D() is a fundamental triangle domain (labeled in Figure 11 on the right). In this domain, we have for the polygon of intersection vol(A ∩ proj B + k) = (1 − x)(1 − y), (59) and therefore L22r = vol A vol B \" I (1) 1, π − I (1) 1, π − I (1) 1, π + I (1) 1, π # . (60) Going through all recursions, we get, after simplifications L22r = + √ − √ − 2π + arccoth √ + arccoth √3. (61) 185.2.5 L Putting everything together by using (64), we finally arrive at the Robin's constant L33 = + 17√ − √ − π + arccoth √2 + arccoth √3 ≈ 0.66170718. (62) 5.3 Regular octahedron A standard way how to select vertices of an regular octahedron the vertices is [±1, 0, 0], [±1, 0, 0], [±1, 0, 0]. Under this choice, the edge length is l = √ 2, the area of each face is ν = √ 3/2 and the volume of K is vol K = 4/3. Again, we put P = L p . For the definition of various mean values Pab = L (p) ab , see Figure 9. We also included the position of the scaling point C in cases when the reduction is possible. * * * * * * * Figure 9: All different L (p) ab configurations encountered for K being a regular octahedron Performing the reduction, we get the set of equations, where pP33 = 6(P32 − P33), pP32 = 3(P22 − P32) + 2(P31 − P32), pP22e = 4(P21v − P22e), pP22v = 4(P21r − P22v), pP31 = 3(P21 − P31) + 1(P30 − P31), pP21v = 2(P11 − P21v) + 1(P20 − P21v), pP30 = 3(P20 − P30) 19with P22 = P22e + P22r + P22v, P21 = P21v + P21r. Solving the system, we get P33 = 72(P20 + P11) (3 + p)(4 + p)(5 + p)(6 + p) + 54P21r (4 + p)(5 + p)(6 + p) + 9P22r 2(5 + p)(6 + p) . (63) When p = 1, we get for the mean length L33 = (4L20 + 4L11 + 12L21r + 5L22r). (64) 5.3.1 L More precisely, we can write L20 = LAB, where face A has vertices [−1, 0, 0], [0, −1, 0], [0, 0, −1] and B = [0, 0, 1] (see Figure 9). Vertex B is separated from A(A) by distance h = 2/ √ 3. By (15) and by symmetry, L20 = 2h vol A I (1) 00 √ , π ! − I (1) 00 √ , π !! , (65) where vol A = ν = √ 3/2 is the area of A. Using recurrence relations on I (1) 00 (·, ·), I (1) 00 √ , π ! = − π + 7 arcsinh 12√ = − π + 7 arccoth √ 12√ . (66) The other I (1) 00 integral is already given by (42) (we just write arcsin p 2/3 = π/2−arccot √2), hence L20 = − √ − 8π − 25 ln 54√ + arccot √2 + √ 2 arccoth √2 (67) 5.3.2 L By shifting (16), we get L11 = LAB, where B is the origin and A is a parallelogram with vertices [1, 0, 1], [0, 1, 1], [0, 2, 0], [1, 1, 0]. Therefore, by the point-polygon formula (15) with h = 2/ √ 3 and vol A = √ 3, L11 = h vol A 4I (1) 00 √ , π ! + 2I (1) 00 √ , π !! , (68) Hence, since the I's are already given by (42) and (66), we get, simplifying, L11 = + √ + 4π + 25 ln 54√ − arccot √2 + √ 2 arccoth √2 (69) 205.3.3 L21r Since the reduction technique cannot be applied on AB being parallel, we use the overlap formula with A being one face of the octahedron. By symmetry, we can choose B as all three opposite edges to A instead of just one, the mean value stays the same (see Figure 9). This choice makes the overlap formula simpler. To compute vol(A ∩ proj B + k), we slide the projection B across A. To get L21r, we then integrate over the length of their intersection with respect to all vectors k. By symmetry, we can integrate over just one sixth of all sliding domains (see Figure 10 for our overlap diagram, in which white numbers represent the number of line segments in the AB projection intersection with respect to position of the shift vector k – black dot). symmetry Figure 10: Overlap of the opposite face and edges of an octahedron Hence, setting up the integral, L21r = vol A vol B Z D √ h 2 + k2 vol(A ∩ proj B + k) dk, (70) where h = 2/ √ 3, vol A = √ 3/2, vol B = 3√2 and D is a domain in Figure 10 on the right consisted of two subdomains Dj where j ∈ {2, 3} denotes the number of line segments of the intersection A ∩ (proj B + k), which is a polyline. We have D = D2 ⊔ D3. Let k = (x, y) with the origin coinciding with the centroid of proj A triangle with vertices [0, √ ], [− √ , √ ], [− √ , − √ ] (see Figure 10). Let us denote vj = vol(A ∩ proj B + k) for all k ∈ Dj , then we have for the subdomains: • D3 is a triangle with vertices [0, 0], [ √ , 0], [ √ , √ ] in which v3 = √ • D2 is a triangle with vertices [ √ , 0], [ √ , 0], [ √ , √ ] in which v2 = √ 3 − √ 2x Note that in general, vol(A ∩ proj B + k) is linear in (x, y) in the subdomains. By inclusion/exclusion, we can write our integral as L21r = vol A vol B Z Z D3∪D v p h 2 + x2 + y2 dxdy + Z Z D (v3 − v2) p h 2 + x2 + y2 dxdy = vol A vol B \"Z Z D3∪D √ − 2x √ ! p h 2+x2+y2dxdy+ Z Z D 2x √ − √ ! p h 2+x2+y2dxdy # . (71) 21Note that the second integral over domain 3 is already in the form of an integral over standard fundamental triangle domain since D3 = D( √ , π ). The first integral over domain 3 ∪ 2 can be written in such manner after rotation and reflection. To obtain the correct transformation, we let φ ′ to start (be zero) for the half-line connecting the origin with point [ √ , √ ], increasing in the clockwise direction. That is φ = π/3 − φ ′ and thus x = r cos( π 3 − φ ′ ) and y = r sin(π 3 − φ ′ ). Expanding out the trigonometric functions and writing x ′ = r cos φ′ and y′ = r cos φ′ , we get x = r cos π cos φ ′ + r sin π sin φ ′ = x′ cos π + y ′ sin π = x ′ + √ y ′ , y = r sin π cos φ ′ − r cos π sin φ ′ = x′ sin π − y ′ cos π = √ x ′ − y ′ (72) and so v2 = √ − 2x √ = √ − x ′ √ − y ′ . (73) Our integration domain D3⊔D2 in (x ′ , y′) is simply D( √ , π ). Note that x 2 +y is invariant with respect to this transformation so x 2 + y2 = x′2 + y′ . By scaling with h, we can write L21r in terms of the auxiliary integrals as L21r = 6h vol A vol B \" √ I (1) 00 √ 3h , π ! − h √ I (1) 10 √ 3h , π ! − hI(1) 01 √ 3h , π ! + 2h √ I (1) 10 √ 6h , π ! − √ I (1) 00 √ 6h , π ! # (74) with √ 3h = √ and √ 6h = √ . Via recursions (see Table 5 in Appendix), we get L21r = − + 54√ − 16π + 143 ln 648√ + arccot √2 + √ 2 arccoth √2 (75) 5.3.4 L22r Again, we use the overlap formula for A and B being opposite faces of K. By symmetry, we again integrate vol(A∩proj B +k) over one sixth of all positions of vector k (see Figure 11, in which white numbers represent the number of sides of a polygon of intersection of AB projections with respect to position of the shift vector k – black dot). Setting up the integral, L22r = vol A vol B Z D √ h 2 + k2 vol(A ∩ proj B + k) dk, (76) where h = 2/ √ 3, vol A = vol B = ν = √ 3/2 and D is a domain in Figure 11 on the right consisted of two subdomains labeled 6 and 4 according to the number of sides of the intersection (which is a polygon). That is, D = D6 ⊔ D4. Let k = (x, y) and denote vj = vol(A ∩ proj B + k) for those k which lie in ∈ Dj , then the subdomain 22symmetry Figure 11: Overlap of the opposite faces of an octahedron • D6 is again a triangle with vertices [0, 0], [ √ , 0], [ √ , √ ] in which v6 = √ − √ x 2− √ y • D4 is a triangle with vertices [ √ , 0], [ √ , 0], [ √ , √ ] in which v4 = √ − √ 2x 3 + x √ − √ 3y Domains 6, 4 coincide with 3, 2 in L21r case, that is D6 = D3 and D4 = D2. Note that in general, vol(A ∩ proj B + k) is quadratic in (x, y) in the subdomains. By inclusion/exclusion, we can write the integral as L22r = vol A vol B h Z Z D6∪D v p h 2 + x2 + y2 dxdy + Z Z D (v6 − v4) p h 2 + x2 + y2 dxdy # = vol A vol B h Z Z D6∪D √ − √ 2x + x √ − √ 3y ! p h 2 + x2 + y2 dxdy + Z Z D − √ + √ 2x − 2x √ ! p h 2 + x2 + y2 dxdy i . (77) Again, the integral over domain 6 is in a standard form. The other integral must be first transformed using x = x ′ + √ y ′ , y = √ x ′ − y ′ , which gives v4 = √ − √ 2x + x √ − √ 3y = √ − √ 2x ′ − r y ′ − x ′ √ + x ′ y ′ (78) and therefore L22r = 6h vol A vol B \" √ I (1) 00 √ , π ! − √ 2h I (1) 10 √ , π ! − r hI(1) 01 √ , π ! − h √ I (1) 20 √ , π ! + h I (1) 11 √ , π ! − √ I (1) 00 √ , π ! + √ 2h I (1) 10 √ , π ! − 2h √ I (1) 20 √ , π ! #. (79) Going through all recursions, we get, after simplifications L22r = + √ − 32π + 293 ln 270√ − arccot √2 + √ 2 arccoth √2 (80) 235.3.5 L Putting everything together by using (64), we finally arrive at L33 = + 13√ − 4π + 109 ln 630√ + 16 arccot √ + 158 arccoth √ √ 2. (81) Rescaling, we get our mean distance in a regular octahedron having unit volume L vol K=1 = r + 13√ − 4π + 109 ln 630√ + 16 arccot √ + 158 arccoth √ √ ! ≈ 0.65853073. (82) 5.4 Regular icosahedron Regular icosahedron shares many features with regular octahedron. We have already seen that the Crofton Reduction Technique itself is very powerful to reduce the the mean distance until two domains from which we select two points have empty affine hull. As a consequence, the only remaining terms in the icosahedron expansion are the parallel edge-face and parallel face-face configurations. Note that these two parallel configurations have the same overlap diagram as the octahedron has. Let ϕ = (1 + √ 5)/2 be the Golden ratio. A standard selection of vertices is [±ϕ, ±1, 0] and all of their cyclic permutations. That way, our edges have length l = 2. The volume is equal to vol K = 10(3 + √ 5)/3 and the face area ν = √ 3. Again, we put P = L p . For the definition of various mean values Pab = L (p) ab , see Figure 12. Performing the reduction, we get the set of equations: pP33 = 6(P32 − P33), pP32 = 3(P22 − P32) + 2(P31 − P32), pP31 = 3(P21 − P31) + 1(P30 − P31), pP22e = 4(P21v − P22e), pP22v = 4(P21d − P22v), pP22d = 4(P ′ 21 − P22d), pP22i = 4(P ′′ 21 − P22i), pP30 = 3(P20 − P30), pP21v = 2(P11d − P21v) + 1(P20u − P21v), pP21w = 2(P11f − P21w) + 1(P20l − P21w), pP21f = 2(P11 − P21f ) + 1(P ′ 20 − P21f ), pP21d = 2(P ′ 11 − P21d) + 1(P ′′ 20 − P21d), pP21e = 2(P ′′ 11 − P21e) + 1(P ′′′ 20 − P21e), 24* * * * * * * * * * * * * Figure 12: All different L (p) ab configurations encountered for K being a regular icosahedron with P22 = 2P22d + P22r + P22v + P22e 10ϕ + ϕ 2P22i , P21 = ϕP21e + P21f 2ϕ √ + P21r + P21d + P21v 5ϕ + P21w 10ϕ , P ′ 21 = P21f − ϕP21d + ϕ 2P21e , P ′′ 21 = ϕ 2P21r − ϕP21e, P20 = P20f 2ϕ + P20e 2ϕ + P20r , P ′ 20 = ϕP20r − P20f ϕ , 25P ′′ 20 = ϕ 2P20e − ϕP20f , P ′′′ 20 = ϕ 2P20r − ϕP20e, P11 = 2P11t − P11f , P ′ 11 = ϕ 2P11f − ϕP11d, P ′′ 11 = ϕ 2P11g − ϕP11t . Solving the system, we get, after simplifications, P33 = 18 (12ϕ 2P11d − 12ϕ4P11f + 4ϕ8P11g + 12ϕ2P11t − 6ϕ4P20e + 4ϕ8P20r + 6P20f ) 5ϕ4(3 + p)(4 + p)(5 + p)(6 + p) + 108ϕ 2P21r 5(4 + p)(5 + p)(6 + p) + 9P22r 5(5 + p)(6 + p) . (83) When p = 1, we get for the mean distance L33 = 3L22r − 9L11f − 9L20e + 9L20f 350ϕ + 9L11d 175ϕ + 9L11t 175ϕ + 18ϕ 2L21r + 3ϕ 4L11g + 3ϕ 4L20r . (84) 5.4.1 L11d Let A′ = [1, 0, ϕ][−1, 0, ϕ] and B′ = [0, ϕ, 1][ϕ, 1, 0] be edges of K, then L11d = LA′B′. By shifting, LA′B′ = LOA, where O = [0, 0, 0] is the origin and A = A′ − B′is a polygon with vertices [1, −ϕ, ϕ ], [− ϕ , −1, ϕ], [−ϕ , −1, ϕ], [−1, −ϕ, ϕ ] (a parallelogram) having area vol A = p 10 − √ 5. Projecting O onto A(A), we obtain projA O = [0, −1 − √ , √ ] and separation h = q 2 + √ . Point-Polygon formula yields L11d = 2h vol A 2I (1) 2ϕ , 2π − I (1) , π + I (1) , 2π ! ≈ 2.0431430525135. (85) Explicitly, after series of simplifications on I (1) 00 (·, ·) by recursion formulae, we obtain L11d = + √ + (2π) 3 + √ − 3 + √ arccot ϕ − 3 + √ arccot ϕ + 31 − √ ln 3 + 3 + √ ln 5. (86) 5.4.2 L11g Let A′ be the same edge as in L11d and B′ = [1, 0, ϕ][−1, 0, ϕ], then L11g = LA′B′. By shifting, LA′B′ = LOA, where O = [0, 0, 0] and A = A′ − B′is a polygon with vertices [0, 0, 2ϕ], [1, −ϕ, ϕ2], [−1, −ϕ, ϕ2], [−2, 0, 2ϕ] having area vol A = 2√3. Projecting O onto A(A), we obtain projA O = [0, − 2ϕ , 2ϕ ] and separation h = q 3 + 2√ 5. Point-Polygon formula yields L11g = 2h vol A 2I (1) 2ϕ , π + I (1) ϕ , π ! ≈ 3.1806727116118. (87) 26Explicitly, after series of simplifications, L11g = + √ + r 5 + √ + 9 + 4√ π − 9 + 4√ arccot ϕ + + √ ! arccoth ϕ + 23 + 9√ arccsch ϕ − + √ ! ln 5. (88) 5.4.3 L11f Let A′ be the same edge as in L11d and B′ = [ϕ, 1, 0][ϕ, −1, 0], then L11f = LA′B′. By shifting, LA′B′ = LOA, where O = [0, 0, 0] and A = A′ − B′is a polygon with vertices [− ϕ , −1, ϕ], [− ϕ , 1, ϕ], [−ϕ , 1, ϕ], [−ϕ , −1, ϕ] having area vol A = 4. Projecting O onto A(A), we obtain projA O = [0, 0, ϕ] and separation h = ϕ. Point-Polygon formula yields L11f = 2h vol A I (1) ϕ , arctan ϕ + I (1) ϕ, arctan ϕ − I (1) ϕ , arctan ϕ − I (1) ϕ , arctan ϕ ! ≈ 2.3977565034445. (89) Explicitly, after series of simplifications, L11f = + √ − π 1 + √ + 2 + √ arccot ϕ − 2 + √ arccot ϕ + 39 + 17√ arccoth ϕ + 1 − √ ln 3 − 17 + 11√ ln 5. (90) 5.4.4 L11t Again, let A′ be the same edge as in L11d and B′ = [1, 0, −ϕ][ϕ, 1, 0], then L11t = LA′B′. By shifting, LA′B′ = LOA, where O = [0, 0, 0] and A = A′ − B′is a polygon with vertices [0, 0, 2ϕ], [− ϕ , −1, ϕ], [−ϕ , −1, ϕ], [−2, 0, 2ϕ] having area vol A = q 5 + √ . Projecting O onto A(A), we obtain projA O = [0, −1− √ , √ ] and separation h = q 2 + √ . Point-Polygon formula yields L11t = 2h vol A I (1) , π − I (1) , 2π + I (1) ϕ, π ! ≈ 2.8940519649490. (91) Explicitly, after series of simplifications, L11t = s 1 + √ − − √ − 8π 1 + √ + 1 + √ arccot ϕ + 8 + 3√ arccsch ϕ − 1 + √ ln 5. (92) 275.4.5 L20e Let A be the face of K with vertices [1, 0, ϕ], [−1, 0, ϕ], [0, ϕ, 1] (an equilateral triangle) and let B be vertex [ϕ, −1, 0], then L20e = LAB. Projecting B onto A(A), we obtain projA B = [ϕ, − , 2ϕ ] and separation h = 2ϕ/√3. By Point-Polygon formula, L20e = 2h ν I (1) 2ϕ , π − I (1) 2ϕ , arctan √15 + 2√ + I (1) ϕ , arctan √15 − √ ! ≈ 2.688729552544. (93) Explicitly, after series of simplifications, L20e = + √ + 8π 2 + √ − 2 + √ arccot ϕ + 104 + 47√ arccoth ϕ − 112 + 61√ ln 5. (94) 5.4.6 L20r Let A be the same face of K as in the section on L20e and let B be vertex [1, 0, −ϕ], then L20r = LAB. Projecting B onto A(A), we obtain projA B = [1, 2ϕ , √ 5ϕ ] and separation h = 2ϕ 2/ √ 3. By Point-Polygon formula, L20r = 2h ν I (1) ϕ , π − I (1) 2ϕ , π ! ≈ 3.28394367574. (95) Explicitly, after series of simplifications, L20r = r 5 + √ − − √ − 16π 9 + 4√ + 9 + 4√ arccot ϕ − + √ ! arccoth ϕ + 23 + 9√ arccsch ϕ + + √ ! ln 5. (96) 5.4.7 L20f Let A be the same face of K as in the section on L20e and let B be vertex [ϕ, 1, 0], then L20f = LAB. Projecting B onto A(A), we obtain projA B = [ϕ, ϕ , 2ϕ ] and separation h = 2/ √ 3. By Point-Polygon formula, L20f = 2h ν I (1) ϕ , π − I (1) 00 √ , arctan r ! − I (1) ϕ , arctan √15 − √ ! ≈ 2.2472771159735. (97) 28Explicitly, after series of simplifications, L20f = + √ − 8π + arccot ϕ + arccot(ϕ ) − √ 5 ln 3 + + √ 27 ! ln 5. (98) 5.4.8 L21r Let A be a face of K and B be a boundary of the opposite face. In icosahedron K, two faces are separated by the distance 2ϕ 2/ √ 3. Since the overlap diagram of these faces is the same as the one associated to two opposite faces of an octahedron (see Figure 10), the coefficients of the expansion of irreducible L21r term into auxiliary integrals I (1) ij match. However, this is only valid provided the edge length is √ 2. Since our icosahedron K has l = 2, we first rescale our icosahedron by 1/ √ 2. In the final step, since the mean distance scales linearly, we have just rescale Lab back by multiplying it by √2. Hence, by using Equation (74), L21r = L21r l=2 = √ 2L21r l= √ = √ 6h vol A vol B \" √ I (1) 00 √ 3h , π ! − h √ I (1) 10 √ 3h , π ! − hI(1) 01 √ 3h , π ! + 2h √ I (1) 10 √ 6h , π ! − √ I (1) 00 √ 6h , π ! # ≈ 3.1819213671057, (99) where h = √ 2ϕ 2/ √ 3, vol A = √ 3/2 and vol B = 3√2 are the rescaled icosahedron opposite faces separation, rescaled face area and face perimeter, respectively. Contrary to the octahedron case, we now have √ 3h = 1/ϕ2 and √ 6h = 1/(2ϕ ). Via recursions, we get after some simplifications, L21r = + 107√ − 27s 10 + √ − 8π 9 + 4√ + 9 + 4√ arccot ϕ + + 13√ ! arccoth ϕ + + √ ! arccsch ϕ − 1043 + 468√ ln 5. (100) 5.4.9 L22r Again, Overlap diagram of L21r configuration matches that of an octahedron. Immediately from Equation (79), by rescaling and replacing √ 2/2 by 1/ϕ2 and √2/4 by 1/(2ϕ ) in the first argument of I (p) ij integrals, we get L22r = √ 6h vol A vol B \" √ I (1) ϕ , π − √ 2h I (1) ϕ , π − r hI(1) ϕ , π − h √ I (1) ϕ , π + h I (1) ϕ , π − √ I (1) 2ϕ , π + √ 2h I (1) 2ϕ , π − 2h √ I (1) 2ϕ , π # ≈ 3.12998447304770, (101) 29where h = √ 2ϕ 2/ √ 3 and vol A = vol B = √ 3/2. Explicitly, after some simplifications, L22r = 3 + 2√ s 10 + √ − − √ + 16π 78 + 35√ − 67 + 30√ arccot ϕ + + 164√ 27 ! arccoth ϕ − 9 + 5√ arccsch ϕ − + 41√ 27 ! ln 5. (102) 5.4.10 L Putting everything together by using (84), we finally arrive at L33 = + 525√ − 525s 2 + √ − 17226 + 6269√ π − 2186 + 1413√ arccot ϕ + 82 − 75√ arccot (ϕ ) + 15969 + 7151√ arccoth ϕ + 2139 + 881√ arccsch ϕ + 4449 − 1685√ ln − 75783 + 37789√ ln ≈ 1.66353152568500. (103) Rescaling, we get our mean distance in a regular icosahedron having unit volume L vol K=1 = L q 3 + √ ≈ 0.64131248551. (104) 5.5 Regular dodecahedron Finaly, we will calculte the mean distance in the regular dodecahedron. Let us choose the vertices as [±ϕ, ±ϕ, ±ϕ], [0, ±1, ±ϕ ] and all their cyclic permutations (ϕ = (1 + √ 5)/ as usual). Under this choice, each edge has length l = 2 and each face has area ν = p 25 + 10√5. Performing CRT, we get the configurations shown in Figure 13. Even though there are less configurations than for the icosahedron, the dodecahedron has more complicated overlap diagram (see Figure 14, there is ten-fold symmetry with respect to rotation and reflection). Distance moments are again connected through CRT via the following set of reduction equations pP33 = 6(P32 − P33), pP32 = 3(P22 − P32) + 2(P31 − P32), pP31 = 3(P21 − P31) + 1(P30 − P31), pP22e = 4(P ′ 21 − P22e), pP22i = 4(P ′′ 21 − P22i), 30* * * * * * * * * Figure 13: All different L (p) ab configurations encountered for K being a regular icosahedron pP30 = 3(P20 − P30), pP21v = 1(P20e − P21v) + 2(P11 − P21v), pP21f = 2(P ′ 11 − P21f ) + 1(P ′ 20 − P21f ), pP21d = 2(P ′′ 11 − P21d) + 1(P ′′ 20 − P21d) with P22 = 6ϕ √ 5P22e + ϕP22r + ϕ √ 5P22i , P21 = P21r + P21d + ϕP21f + P21v 6ϕ , P ′ 21 = ϕ √ P21v + ϕ 2P21d , 31P ′′ 21 = √ (ϕP21f + ϕP21r − P21d), P20 = 2ϕ P20e + ϕP20f + ϕ 2P20r , P ′ 20 = ϕ 2P20r − ϕP20f , P ′′ 20 = ϕ 2P20f − ϕP20e, P11 = ϕ √ (2P11d + ϕP11f ), P ′ 11 = √ (2ϕP11t − P11f ), P ′′ 11 = √ (ϕP11g + ϕP11f − P11d). Solving the system, we get, after simplifications, P33 = 12 √ 5P11d + 5ϕP20e + 2ϕ 3P11g − 2ϕ √ 5P11f − 5ϕ 5P20f + 4√ 5ϕ 6P20r + 2ϕ9P11t ϕ √ 5 (3 + p)(4 + p)(5 + p)(6 + p) + 60ϕP21r √ 5(4 + p)(5 + p)(6 + p) + 3P22r (5 + p)(6 + p) . (105) When p = 1, we get for the mean distance L33 = L11d 35ϕ + L20e 14√5ϕ + L11g 35√5ϕ − L11f + L22r − ϕL20f 14√ + 2ϕL21r √ + 2ϕ 2L20r + ϕ 5L11t 35√ . (106) 5.5.1 L11d Let A′ = [0, ϕ , 1][0, ϕ2, −1] and B′ = [ϕ, ϕ, −ϕ][1, 0, −ϕ2] be edges of K, then L11d = LA′B′. By shifting, LA′B′ = LOA, where O = [0, 0, 0] is the origin and A = A′ − B′is a polygon with vertices [−ϕ, 1, ϕ2], [−1, ϕ2, √ 5ϕ], [−1, ϕ2, ϕ], [−ϕ, 1, 1/ϕ] having area vol A = 2√3. Projecting O onto A(A), we obtain projA O = [−1 − √ , , 0] and separation h = (1 + √5)/ √ 3. PointPolygon formula yields L11d = 2h vol A I (1) 2ϕ , π + I (1) 00 √ , π ! − I (1) 2ϕ , arctan √ 2 + √ − I (1) 00 √ , arctan r ! ! ≈ 3.1367199950978. (107) Explicitly, after series of simplifications, L11d = 10√ − √ + √ − − 2π 2 + √ − 5 + 2√ ln 3 − 4 + 7√ ln + 2 + √ 2 arccot 2 + 2 arccot √2 − arccos + 5 + 2√ arccosh . (108) 325.5.2 L11g Let A′ be the same edge as in L11d and B′ = [ϕ, −ϕ, ϕ][ϕ , −1, 0], then L11g = LA′B′. By shifting, LA′B′ = LOA, where O = [0, 0, 0] and A = A′ − B′ is a polygon with vertices [−ϕ, ϕ3, −1/ϕ], [−ϕ , √ 5ϕ, 1], [−ϕ , √ 5ϕ, −1], [−ϕ, ϕ3, −ϕ ] having area vol A = p 10 − √ 5. Projecting O onto A(A), we obtain projA O = [−1 − √ , 2 + √ , 0] and separation h = q 10 + √ . Point-Polygon formula yields L11g = 2h vol A 2I (1) 2ϕ , 2π − I (1) 2ϕ , π + I (1) 2ϕ , 2π ! ≈ 4.60478605392525. (109) Explicitly, after series of simplifications, L11g = − √ + √ + √ − + √ π + 219 + 97√ ln + 47 + 21√ arccos + 2 arccos √ + 2 arccos √ − 2 arccot √ + 219 + 97√ arccosh − arccosh + 91 + 33√ arccosh √ − arccosh √ . (110) 5.5.3 L11f Let A′ be the same edge as in L11d and B′ = [1, 0, −ϕ2][−1, 0, −ϕ2], then L11f = LA′B′. By shifting, LA′B′ = LOA, where O = [0, 0, 0] and A = A′ − B′is a polygon with vertices [−1, ϕ2, √ 5ϕ], [1, ϕ2, √ 5ϕ], [1, ϕ2, ϕ], [−1, ϕ2, ϕ] having area vol A = 4. Projecting O onto A(A), we obtain projA O = [0, ϕ2, 0] and separation h = ϕ . Point-Polygon formula yields L11f = 2h vol A I (1) ϕ , arctan √5ϕ + I (1) 00 √ ϕ , arctan √ 5ϕ ! − I (1) ϕ , arctan ϕ − I (1) ϕ , arctan ϕ ! ≈ 3.770095521642. (111) Explicitly, after series of simplifications, L11f = √ − + r − √ + + √ ! π + 125 + 53√ arccos √ + + √ ! 2 arccos √ + 2 arccot 2 − arccos − 2 arccos − 2 arccos √ + 23 + 9√ arccosh − 125 + 53√ arccosh √ − 37 + 17√ arcsinh 2 − 23 + 9√ log(3) + 37 + 17√ ln 5. (112) 335.5.4 L11t Again, let A′ be the same edge as in L11d and B′ = [ϕ, −ϕ, −ϕ][0, −ϕ2, −1], then L11t = LA′B′. By shifting, LA′B′ = LOA, where O = [0, 0, 0] and A = A′ − B′ is a polygon with vertices [−ϕ, ϕ3, ϕ2], [0, 2ϕ , 2], [0, 2ϕ , 0], [−ϕ, ϕ3, 1/ϕ] having area vol A = q 5 + √ . Projecting O onto A(A), we obtain projA O = [−1 − √ , 2 + √ , 0] and separation h = q 10 + √ . PointPolygon formula yields L11t = 2h vol A I (1) ϕ , π + I (1) 2ϕ , π − I (1) 2ϕ , 2π ! ≈ 5.04162416571318. (113) Explicitly, after series of simplifications, L11t = q − + 2r + √ − √ − π 29 + 13√ + 29 + 13√ 2 arccot √2 − arccos + + √ (arccosh 4 − arccosh 2) + 133 + 61√ arccosh 3 − arccosh − ln 3. (114) 5.5.5 L20e Let A be the face of K with vertices [1, 0, −ϕ ], [ϕ, ϕ, −ϕ], [0, ϕ2, −1], [−ϕ, ϕ, −ϕ], [−1, 0, −ϕ ] (a regular pentagon) and let B be vertex [0, ϕ2, 1], then L20e = LAB. Projecting B onto A(A), we obtain projA B = [0, ϕ √ , − √ ] and separation h = q 2 + √ . By Point-Polygon formula, L20e = 2h ν I (1) , π − I (1) , 2π − I (1) ϕ , π + I (1) 3ϕ , arctan p 5 − √ ! + I (1) ϕ , arctan r 5 − √ ! ! ≈ 3.346942678627. (115) Explicitly, after series of simplifications, L20e = q + 13√ − − √ + 4π 15√ − + 10√ ln 3 − 13 ln 30√ + 8 arccos 15√ + + 10√ arccosh − 25 + 8√ arccosh √ + 25 + 8√ arccosh √ − 16 arccot 15√ + 8 arctan √ 15√ − 8 arctan √ 15√ − 8 arctan √ 15√ − 8 arctan √ 15√ . (116) 345.5.6 L20r Let A be the same face of K as in the section on L20e and let B be vertex [0, −ϕ , 1], then L20r = LAB. Projecting B onto A(A), we obtain projA B = [0, 10 √ 5 − , −1 − √ ] and separation h = q 10 + √ . By Point-Polygon formula, L20r = 2h ν I (1) ϕ , π + I (1) 2ϕ , 2π − I (1) 2ϕ , π − I (1) 2ϕ , 2π ! ≈ 4.87605984948. (117) Explicitly, after series of simplifications, L20r = − √ + √ + √ + √ + 16π + 4π √ − 20 + 9√ arccot √ + + 30√ ln 3 + 20 + 9√ arccos − arccos √ − arccos √ − 85 + 37√ arccosh 2 + + 30√ arccosh − arccosh + 85 + 37√ arccosh 4 + + 10√ arccosh √ − arccosh √ (118) 5.5.7 L20f Let A be the same face of K as in the section on L20e and let B be vertex [0, −ϕ , −1], then L20f = LAB. Projecting B onto A(A), we obtain projA B = [0, − 5+3√ 10 , −2 − √ ] and separation h = 2q 1 + √ . By Point-Polygon formula, L20f = 2h ν I (1) ϕ , π − I (1) 2ϕ , 2π + I (1) 2ϕ , arctan r 5 + 2√ ! − I (1) , π − I (1) ϕ , arctan q85 − 38√ ! ≈ 4.000363965317. (119) Explicitly, after series of simplifications, L20f = 1 + q − √ + √ + 4π + 8π 15√ + 2 + √ ln 3 + 5 + 2√ ln − 5 + 2√ arccos + 5 + 2√ arccot 2 + arctan √ − arctan √ ! + + 15√ arccosh − + 15√ arccosh 3 + 35 + 4√ arccosh − 5 + 2√ arcsinh 2. (120) 355.5.8 L22r Finally, let us take a closer look on parallel configurations L21r and L22r. We start with the latter. Let A and B be opposite faces of dodecahedron K with separation h = q 10 + √ then L22 = LAB with overlap diagram as seen in Figure 14. Note that, due to symmetry, only one tenth of the diagram is sufficient to be considered. The subdomains where vol(A ∩ proj B + k) can be written as a single polynomial are shown in the diagram. Again, they are labeled by number of sides of polygon of intersection A∩(proj B +k), sliding proj B +k across proj A by letting k to vary (vector k is shown by a black dot). Let us denote D as the union of the labeled subdomains. Then, by Overlap formula, L22r = vol A vol B Z D √ h 2 + k2 vol(A ∩ proj B + k) dk, (121) Figure 14: Overlap diagram for opposite-faces configuration in dodecahedron Let us express vol(A ∩ proj B + k) in the aforementioned subdomains. We denote vj = vol(A ∩ proj B + k) for all k ∈ Dj . Let us restrict ourselves to the plane A(A), in which we put k = (x, y) and in which proj A is a regular pentagon with vertices hq 2 + √ cos 2πi , q 2 + √ sin 2πi i , i ∈ {0, 1, 2, 3, 4} and area vol A = q 5 + 2√ . Similarly, proj B is another pentagon with vertices hq2 + √ cos 2π(i+1/2) , q 2 + √ sin 2π(i+1/2) i and area vol B = vol A = q 5 + 2√ . Under this projection, the labeled subdomains Dj are triangles with vertices 36• (subdomain D4) hq 2 + √ , 1 + √ i , hq 2 − √ , i , hq 8 + √ , i , in which v4 = q 50 + 22√5 − 5 + 3√ x + r 5 + 2√ x 2 − q 5 − √ 5y ! , (122) • (subdomain D6) hq 2 + √ , 1 + √ i , hq 1 − √ , √ 5 − i , hq 2 − √ , i , in which v6 = q 145 + 62√5 − 5 + 3√ x − r 10 5 + √ x − r 10 5 + √ y + 10 1 + √ xy − r 5 + √ y , (123) • (subdomain D8) hq 1 − √ , √ 5 − i , hq 1 − √ , i , hq 2 − √ , i , in which v8 = q 130 + 58√5 − √ 5x − s 1 + √ x 2 − r 5 + 2√ y ! , (124) • (subdomain D10) hq 1 − √ , √ 5 − i , [0, 0] , hq 1 − √ , i , in which v10 = q 5 + 2√ 4 − √ 5x 2 − √ 5y . (125) In order to use the Overlap formula effectively, that is, to integrate vj = vol(A ∩ proj B + k), k ∈ Dj over all subdomains Dj , it is convenient to first perform appropriate rotation transformations and inclusion/exclusions. First, by inclusion/exclusion, L22r = vol A vol B Z D u10ph 2 + x2 + y2 dxdy + Z D10∪D u p h 2 + x2 + y2 dxdy + Z D10∪D8∪D u p h 2 + x2 + y2 dxdy + Z D10∪D8∪D6∪D u p h 2 + x2 + y2 dxdy , (126) where u4 = v4, u6 = v6 − v4, u8 = v8 − v6 and u10 = v10 − v8. Explicitly u4 = √ q 25 + 11√5 − 2x 5 + 3√ + x 10r 5 + 2√ − y q 5 − √ 5, (127) u6 = − q 5 + 2√5 + x 1 + √ − y s 2 + √ + xy 1 + √ − x √ s 5 + √ − y √ q 5 − √ 5, (128) u8 = − q 5 − √ 5 + x 1 − √ + y s 2 + √ − xy 1 + √ (129) 37− x √ s 1 − √ − y √ q 25 + 11√5, (130) u10 = − q 5 − √ 5 + 4x √ − 2x s 1 + √ . (131) Note that domain D10 is already in the form of the fundamental triangle domain D ζ, π with ζ = q 1 − √ . Since ζ/h = 1/(2ϕ ), we immediately get in terms of auxiliary integrals, Z D u10p h 2 + x2 + y2 dxdy = h − q 5 − √ 5I (1) 2ϕ , π + 4h √ I (1) 2ϕ , π − 2h s 1 + √ I (1) 2ϕ , π ! . (132) Domain D = D10 ∪ D8 ∪ D6 ∪ D4 in (x, y) is transformed to the fundamental domain D(ζ, π ) with ζ = 2q 1 + √ in (x ′ , y′) via polar angle substitution φ = π/5 − φ ′ , that is x = r cos( π 5 − φ ′ ) and y = r sin(π 5 − φ ′ ). Expanding out the trigonometric functions and writing x ′ = r cos φ′ and y′ = r cos φ′ , we get the following transformation relations x = 1 + √ x ′ + s − √ y ′ , y = s − √ x ′ − 1 + √ y ′ (133) and so u4 = q 50 + 22√5 − x ′ 2 + √ − 2y ′ s 1 + √ + x ′ y ′ + x′ s 1 − √ . (134) Since ζ/h = 1/ϕ, we immediately get Z D u p h 2 + x2 + y2 dxdy = h q 50 + 22√5I (1) ϕ , π − h 2 + √ I (1) ϕ , π − 2h s 1 + √ I (1) ϕ , π + h I (1) ϕ , π + h s 1 − √ I (1) ϕ , π ! . (135) In order to express the remaining integrals, we write D10∪D8∪D6 = E4 \\E6 and D10∪D8 = E8 \\ E10, where • E4 is a triangle with vertices hq 2 + √ , 1 + √ i , [0, 0], h q 1 + √ , − i , • E6 is a triangle with vertices hq 2 − √ , i , [0, 0], h q 1 + √ , − i , • E8 is a triangle with vertices h q 2 − √ , √ 5 − i , [0, 0], h q 2 − √ , √ 5 − i , 38• E10 is a triangle with vertices h q 2 − √ , √ 5 − i , [0, 0], hq 1 − √ , √ 5 − i . Note that E6 ⊂ E4 and E10 ⊂ E8 and thus Z D10∪D8∪D u p h 2 + x2 + y2 dxdy = Z E u p h 2 + x2 + y2 dxdy − Z E u p h 2 + x2 + y2 dxdy, Z D10∪D u p h 2 + x2 + y2 dxdy = Z E u p h 2 + x2 + y2 dxdy − Z E u p h 2 + x2 + y2 dxdy. (136) Domains E4, E6, E8 and E10 can be rotated to fundamental triangle domains after appropriate rotations. First, let φ = φ ′ − π/5, so x = 1 + √ x ′ + s − √ y ′ , y = − s − √ x ′ + 1 + √ y ′ (137) and thus, after simplifications, u6 = − q 5 + 2√5 + 2x ′ 1 + √ − x ′ s 2 + √ . (138) Suddenly in (x ′ , y′), we have E4 = D(ζ, 2π ) and E6 = D(ζ, π ) with ζ = q 5 + √ , hence ζ/h = 1/(2ϕ ) and immediately in terms of auxiliary integrals, Z D10∪D8∪D u p h 2 + x2 + y2 dxdy = h − q 5 + 2√ I (1) 2ϕ , 2π − I (1) 2ϕ , π +2h 1+ √ I (1) 2ϕ , 2π −I (1) 2ϕ , π −h s 2+ √ I (1) 2ϕ , 2π −I (1) 2ϕ , π ! . (139) Next, let φ = 2π 5 − φ ′ , from which we obtain transformation relations x = √ 5 − x ′ + s + √ y ′ , y = s + √ x ′ − √ 5 − y ′ , (140) so u8 = − q 5 − √ 5 + 4x ′ √ − 2x ′ s 1 + √ . (141) In (x ′ , y′), we have E8 = D(ζ, 2π ) and E10 = D(ζ, π ) with ζ = q 1 − √ , hence ζ/h = 1/(2ϕ ) and immediately in terms of auxiliary integrals, Z D10∪D u p h 2 + x2 + y2 dxdy = h − q 5 − √ I (1) 2ϕ , 2π − I (1) 2ϕ , π + 4h √ I (1) 2ϕ , 2π − I (1) 2ϕ , π − 2h s 1 + √ I (1) 2ϕ , 2π − I (1) 2ϕ , π ! . (142) 39Therefore, in total, L22r = 10h vol A vol B q 5 + 2√5I (1) 2ϕ , π − q 5 + 2√5I (1) 2ϕ , 2π − q 5 − √ 5I (1) 2ϕ , 2π + q 50 + 22√5I (1) ϕ , π − r 5 + 2√ hI(1) ϕ , π + 4hI(1) 2ϕ , 2π √ − 2hI(1) 2ϕ , π √ − 2hI(1) 2ϕ , π + 2hI(1) 2ϕ , 2π √ + 2hI(1) 2ϕ , 2π − 4hI(1) ϕ , π √ − 2hI(1) ϕ , π + h I (1) ϕ , π − s 1 + √ h I (1) 2ϕ , 2π + s 2 + √ h I (1) 2ϕ , π − s 2 + √ h I (1) 2ϕ , 2π + s 1 − √ h I (1) ϕ , π ! ≈ 4.69357209587. Or explicitly, after a lot of simplifications, L22r = q − − √ + 25√ − 75√ + 25√ − 1839 + 820√ π + 67 + 30√ arccos + 388 + 173√ arccos √ + arccos √ + 817 + 371√ (arccosh 2 − arccosh 4) + 1833 + 820√ arccosh − arccosh + 3538 + 1523√ arccosh √ − arccosh √ − 67 + 30√ arccot √ + 1833 + 820√ ln 3. (143) 5.5.9 L21r By definition, L21r = LAB, where A is a face of K and B is the perimeter of its corresponding opposite face. Again, we use the Overlap formula to deduce the value of L21r, that is, by symmetry, L21r = vol A vol B Z D √ h 2 + k2 vol(A ∩ proj B + k) dk, (144) where vol A = q 5 + 2√ is the area of A and vol B = 10 is the length of B. The overlap diagram is the same as in the case of L22r, although the value vol(A ∩ proj B + k) now corresponds to the total length of polyline A ∩ (proj B + k) of intersection. In order to keep the naming of the subdomains Dj and functions vj = vol(A ∩ proj B + k), k ∈ Dj 40the same as in the case of L22r, we let j, exceptionally, to denote twice the number line segments of A ∩ (proj B + k) in this section. That way, we get D = D10 ∪ D8 ∪ D6 ∪ D4 and v4 = 4 + √ − x s 2 + √ , v6 = 4 + √ − x s 2 + √ + y 1 − √ , v8 = 2 + √ − 2x s 1 − √ , v10 = 2√5. Let u4 = v4, u6 = v6 − v4, u8 = v8 − v6, u10 = v10 − v8, that is u4 = 4 + √ − x s 2 + √ , u6 = − √ + x s 2 + √ + y 1 − √ , u8 = −2 + √ + x s − √ − y 1 − √ , u10 = −2 + √ + 2s1 − √ x. Overall, by inclusion/exclusion, L21r = vol A vol B Z D u10ph 2 + x2 + y2 dxdy + Z D u p h 2 + x2 + y2 dxdy + Z E u p h 2 + x2 + y2 dxdy − Z E u p h 2 + x2 + y2 dxdy + Z E u p h 2 + x2 + y2 dxdy − Z E u p h 2 + x2 + y2 dxdy , (145) The first integral can be immediately expressed in terms of auxiliary integrals Z D u10p h 2 + x2 + y2 dxdy = h −2 + √ I (1) 2ϕ , π + 2h s 1 − √ I (1) 2ϕ , π ! . (146) Performing the same set of transformations as in the previous case of L22r, that is • φ = π/5 − φ ′ , we get u4 = 4 + √ − x ′ q 1 + √ − y ′ , • φ = φ ′ − π/5, we get u6 = − √ + x ′ q 2 − √ , • φ = 2π 5 − φ ′ , we get u8 = −2 + √ + 2x ′ q 1 − √ and as a result, since all the subdomains are now expressed as fundamental triangle domains, we get Z D u p h 2+x2+y2 dxdy = h 4+ √ I (1) ϕ , π −h s 1+ √ I (1) ϕ , π −hI(1) ϕ , π ! , 41Z D10∪D8∪D u p h 2+x2+y2 dxdy = h − √ I (1) 2ϕ , 2π − I (1) 2ϕ , π + h s 2 − √ 1 + √ I (1) 2ϕ , 2π − I (1) 2ϕ , π ! , Z D10∪D u p h 2+x2+y2 dxdy = h √ − I (1) 2ϕ , 2π − I (1) 2ϕ , π + 2h s 1 − √ I (1) 2ϕ , 2π − I (1) 2ϕ , π ! . Therefore, in total Therefore, in total, L21r = 10h vol A vol B √ − I (1) 2ϕ , 2π + 2I (1) 2ϕ , π √ − 2I (1) 2ϕ , 2π √ + 5 + √ I (1) ϕ , π − hI(1) ϕ , π + 2s 1 − √ hI(1) 2ϕ , 2π − s 2 − √ hI(1) 2ϕ , π + s 2 − √ hI(1) 2ϕ , 2π − s 1 + √ hI(1) ϕ , π ! ≈ 4.808558828667. Or explicitly, L21r = − 29q − √ − √ + 15√ + √ − 4π 19 + 8√ − 9 + 4√ arccos − 2 + √ arccos √ + arccos √ + 1043 + 468√ arccosh − arccosh + 271 + 117√ (arccosh 4 − arccosh 2) + 746 + 283√ arccosh √ − arccosh √ + 9 + 4√ arccot √2 + 1043 + 468√ ln 3. (147) 5.5.10 L Putting everything together by using (106), we finally arrive, after another series of simplifications and inverse trigonometric and hyperbolic identities, at L33 = + q − 124q − 71√ − 12√ + 175√ + 493π + 67π 945√ + 397 − 244√ arccot + 24023 + 11788√ arccos 3 − arccos 42− 461 + 212√ arccos 41 + arccos − 1031 + 521√ arccosh + 367 + 163√ arccosh + 22197 + 8149√ arccosh 41 − arccosh + 15763 + 7063√ arccosh 3 − arccosh + 423 + 187√ (arccosh 4 − arccosh 2) + 288889 + 129739√ ln + 109 − 3143√ ln ≈ 2.533488631644. Rescaling, we get our mean distance in a regular dodecahedron having unit volume L vol K=1 = L p 30 + 14√ ≈ 0.65853073. (148) 6 Further remarks 6.1 Weights We believe that the equation for weights (36) possesses a closed form solution in terms of geometrical properties of convex non-parallel polyhedra. However, we were unable to deduce that. 6.2 General convex polyhedra Let K ∈ R d , then for any fixed p > −d, L (p) KK is continuous with respect to continuous transformations of K. Hence, in principle, we could obtain the formula for convex parallel polyhedra by a continuous limit from some convex non-parallel polyhedron. However, were not able to perform this limit. 6.3 Bounds on moments Also, we believe, since the value p = 1 is not special, there could be a bound on L (p) KK similar that of Bonnet, Gusakova, Thäle and Zaporozhets [1]. References [1] Bonnet G, Gusakova A, Thäle C, Zaporozhets D. 2021. Sharp inequalities for the mean distance of random points in convex bodies. Advances in Mathematics 386:107813. [2] Ciccariello S. 2020. The chord-length distribution of a polyhedron. Acta Crystallographica Section A: Foundations and Advances 76.4:474–488. [3] Dunbar SR. 1997. The average distance between points in geometric figures. The College Mathematics Journal 28.3:187–197. 43[4] Kingman JF. 1969. Random secants of a convex body. Journal of Applied Probability:660–672. [5] Robbins D, Bolis T. 1978. Average Distance between Two Points in a Box. Amer. Math. Monthly 85:278. [6] Ruben H, Reed W. 1973. A more general form of a theorem of Crofton. Journal of Applied Probability:479–482. [7] Weisstein EW. Tetrahedron Line Picking. From MathWorld – A Wolfram Web Resource. accessed 21/11/2020. URL: https://mathworld.wolfram.com/TetrahedronLineP html. 44A Exact mean distances in regular polyhedra Mean distances in solids of unit volume The table below summarises all new results of exact mean distance in various polyhedra. For completeness, the previously known cases of a ball and a cube have been added as well. Each solid K has vol K = 1. As usual, ϕ = (1 + √5)/2 is the Golden ratio. balla 0. r π icosahedron 0. s − √ + 525√ − 525s 2 + √ − 17226 + 6269√ π − 2186 + 1413√ arccot ϕ + 82 − 75√ arccot (ϕ ) + 2139 + 881√ arccsch ϕ + 15969 + 7151√ arccoth ϕ + 4449 − 1685√ ln − 75783 + 37789√ ln dodecahedron 0. p 30 + 14√ + q − 124q − 71√ − 12√ + 175√ + 493π + 67π 945√ + 397 − 244√ arccot + 24023 + 11788√ arccos 3 − arccos − 461 + 212√ arccos 41 + arccos − 1031 + 521√ arccosh + 367 + 163√ arccosh + 22197 + 8149√ arccosh 41 − arccosh + 15763 + 7063√ arccosh 3 − arccosh + 288889 + 129739√ ln + 423 + 187√ (arccosh 4 − arccosh 2) + 109 − 3143√ ln octahedron 0. r + 13√ − 4π + 109 ln 630√ + 16 arccot √ + 158 arccoth √ √ ! cubeb 0. + 17√ − √ − π + arccoth √2 + arccoth √ tetrahedron 0. √ √ − 37π + arctan √2 + 113 ln 210√ ! a trivial bRobbins D, Bolis T. 1978. Average Distance between Two Points in a Box. Amer. Math. Monthly 85:278. Table 1: Mean distance in various solids of unit volume, ϕ = (1 + √ 5)/2 is the Golden ratio. 45Normalised mean distance We could select normalisation in which V1(K) = 1 rather than vol K = 1. In order to express the normalised mean distance ΓKK, we just rescale our values in Table 1 by √ vol K/V1(K). Both vol(K) and V1(K) can be expressed easily. The following Table shows the volume of the regular polyhedra with edge length equal to l. To express K tetrahedron cube octahedron dodecahedron icosahedron vol K l √ √ 15 + 7√ 3 + √ Table 2: First intrinsic volume of Platonic solids with unit edge length V1(K), we use the formula V1(K) = 2π P i li(π − δi), where the sum is carried over all edges Ei of K having length li and dihedral angle δi. The following table shows the value of V1(K) for the five regular polyhedra (Platonic solids) with common edge length li = l for all i. K tetrahedron cube octahedron dodecahedron icosahedron V1(K) l 3 arccos − π 6 arccos π 15 arctan π 15 arcsin π Table 3: First intrinsic volume of Platonic solids with unit edge length When K is a ball, √3vol K/V1(K) = p3 π trivially. Finally, performing the scaling, in Table 4 we show numerical values of ΓKK for the same solids K as in Table 1. The lower and the upper bound of ΓKK for K convex compact (based on [1]) are set to 5/ and 1/3, respectively. K lower bound tetrahedron octahedron cube ΓKK 0.17857143 0.19601928 0.21800285 0. K icosahedron dodecahedron ball upper bound ΓKK 0.23872552 0.23963024 0.25714286 0. Table 4: Normalised mean distance in Platonic solids with unit first intrinsic volume 46B Auxiliary integrals Reccurrence relations for auxiliary integrals Recall that D(ζ, γ) is the fundamental triangle domain with vertices [0, 0], [ζ, 0], [ζ, ζ tan γ] (ζ > 0, 0 < γ < π/2). To express the integrals I (p) ij (q, γ) = Z D(q,γ) x i y j 1 + x 2 + y p/ dxdy, (149) we mainly employ recursive relations. However, I (p) 11 (q, γ) can be expressed directly without recursions. We parametrise the domain D(q, γ) as y ∈ (0, x tan γ), x ∈ (0, q), by integrating out y and then x, we get I (p) 11 (q, γ) = sin γ + cos2 γ (1 + q sec2 γ) 2+ p 2 − (1 + q ) 2+ p (2 + p)(4 + p) . (150) K's In case of I (p) 10 (q, γ) and I (p) 10 (q, γ), we cannot integrate twice. To overcome this, we first define our first auxiliary integral K(p)(r) = Z r 1 + t 1+p/ dt (151) satisfying symmetry K(p)(−r) = −K(p)(r) (152) and, via integration by parts, the recurrence relation K(p)(r) = 2 + p 3 + p K(p−2)(r) + r 3 + p (1 + r ) 1+p/ (153) with boundary conditions K(−2)(r) = r, K(−3)(r) = arcsinh r. (154) We can then express our I (p) 10 (q, γ) and I (p) 10 (q, γ) in terms of K′ s as I (p) 10 (q, γ) = 2 + p \" 1 + q 3+p 2 K(p) q tan(γ) p 1 + q ! − sin γ K(p)(q sec γ) # , (155) I (p) 01 (q, γ) = 2 + p cos γK(p)(q sec γ) − K(p)(q) . (156) 47J's We denote J (p) (q, γ) = −γ + Z γ (1 + q sec2 φ) 1+p/ dφ, (157) satisfying symmetry J (p) (q, −γ) = −J (p) (q, γ) (158) and, via integration by parts, the recurrence relations J (p) (q, γ) = J (p−2)(q, γ) + q (1 + q) 1+p 2 K(p−2) q tan γ p 1 + q ! , (159) with boundary conditions J (−2)(q, γ) = 0, J(−3)(q, γ) = −γ + arcsin sin γ p 1 + q . (160) Remark 10. Note that we can write J (p) (q, γ) = R γ (1 + q sec2 φ) 1+p/2 − dφ. We transform I (p) 00 (q, γ) by substitution into polar coordinates x = r cos φ, y = r sin φ, our domain D(ζ, γ) becomes parametrised as r ∈ (0, q sec φ), φ ∈ (0, γ) and thus I (p) 00 (q, γ) = Z γ Z q sec φ r 1 + r p/ drdφ, (161) Integrating out r, we get I (p) 00 (q, γ) = 2 + p Z γ (1 + q sec2 φ) 1+p/2 − 1 dφ = 2 + p J (p) (q, γ). (162) Note that, by this integral formula, we can extend the definition of I (p) 00 (q, γ) for negative γ as well. M's The last set of auxiliary integrals we define is M(p)(q, γ) = Z γ cos2 φ (1 + q sec2 φ) 1+p/2 − dφ, (163) satisfying the recurrence relation M(p)(q, γ) = M(p−2)(q, γ) + q γ + J (p−2)(q, γ) . (164) Using standard techniques of calculus it is not hard to derive their specific values for p = −2 and p = −3, M(−2)(q, γ) = 0, M(−3)(q, γ) = 1 − q arcsin sin γ p 1 + q − γ + sin γ p cos2 γ + q 2 − cos γ . (165) 48Finally, we can express I (p) 20 (q, γ) and I (p) 02 (q, γ). Note that we only need to express the former as I (p) 02 (q, γ) can be extracted from other integrals since I (p) 00 (q, γ) + I (p) 20 (q, γ) + I (p) 02 (q, γ) = Z D(q,γ) 1 + x 2 + y 1+p/ dxdy = I (p+2) 00 (q, γ). (166) Again, by using the polar coordinates substitution, we transform the integral into I (p) 20 (q, γ) = Z γ Z q sec φ r cos2 φ 1 + r p/ drdφ, (167) Integrating out r, we get I (p) 20 (q, γ) = Z γ cos2 φ h (1 + q sec2 φ) 2+ p 2 − i 4 + p − cos2 φ h (1 + q sec2 φ) 1+ p 2 − i 2 + p dφ = 4 + p M(p+2)(q, γ) − 2 + p M(p)(q, γ). (168) Selected values of the auxiliary integrals I (p) ij (q, γ) can be found below in the next section. Special values of auxiliary integrals The following Table 5 lists some of the values of I (1) ij (q, γ) used throughout our paper. List of equivalent values Note that the values in Table 5 are get by not only recursions alone, but also with addition to the following rules (equivalent replacement rules). These rules are only aesthetic and have no effect on the correctness of our results. arcsin √ → π − arctan √ arcsin r → π − arccot√ arcsinh 1 → arccoth √ arcsinh √ → ln arcsinh √ → arccoth √ 49I (1) 1, π √ − π + arccoth √ I (1) 00 √ , π − π + 7 arccoth √ 12√ I (1) 00 √ , π 16√ + π + 25 ln 192√ − arccot √ I (1) 00 √ , π √ − π + 7 ln 24√ + arccot √ I (1) , π √ − + π − 13 ln − arccot 2 + arcsinh I (1) , 2π √ − + π − 13 ln − arccot 2 + arcsinh I (1) 1, π √ − arcsinh √ √ + arccoth √ I (1) 10 √ , π 16√ − √ arcsinh √2 + arccoth √ I (1) 10 √ , π + 81 ln − √ arccoth √ I (1) 1, π − 12√ + √ + arcsinh √ √ − arccoth √ I (1) 01 √ , π r − √ − arccoth √3 + arcsinh √ I (1) 1, π − √ + √ I (1) 11 √ , π − 20r + √ I (1) 20 √ , π + 20√ + π + 13 arccoth √ 120√ I (1) 20 √ , π 20√ − 640√ − π + 43 ln 7680√ + arccot √ Table 5: Selected values of I (1) ij (q, γ) for various arguments 50\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper ID: 1909.03289v1\n",
      "\n",
      "Abstract: We consider the problem of data race prediction where the program's behavior\n",
      "is represented by a trace. A trace is a sequence of program events recorded\n",
      "during the execution of the program.\n",
      "  We employ the schedulable happens-before relation to characterize all pairs\n",
      "of events that are in a race for the schedule as manifested in the trace.\n",
      "  Compared to the classic happens-before relation, the schedulable\n",
      "happens-before relations properly takes care of write-read dependencies and\n",
      "thus avoids false positives.\n",
      "  The challenge is to efficiently identify all (schedulable) data race pairs.\n",
      "  We present a refined linear time vector clock algorithm to predict many of\n",
      "the schedulable data race pairs.\n",
      "  We introduce a quadratic time post-processing algorithm to predict all\n",
      "remaining data race pairs.\n",
      "  This improves the state of the art in the area and our experiments show that\n",
      "our approach scales to real-world examples.\n",
      "  Thus, the user can systematically examine and fix all program locations that\n",
      "are in a race for a particular schedule.\n",
      "\n",
      "Clean Text: \n",
      "2019. In this work, we follow the happens-before [Lamport 1978] line of work for dynamic data race prediction based on a specific program trace. Our goal is to efficiently identify all data race pairs for a specific schedule. This is something that has not been addressed by any prior happens-before based data race predictors. To illustrate the issue and show the usefulness of our method, we consider the following example. // Thread 1 // Thread { { x = 5; // E1 acquire(y); // E x = 6; // E2 x = 7; // E } release(y); // E } We record the trace of events that arises during the interleaved execution of both threads. We assume a program run where first the writes on shared variable x in thread 1 are executed followed by the acquire mutex y, write x and release mutex y in thread 2. The resulting trace is of the form [E1, E2, E3, E4, E5] where we simply record the program locations connected to each event. FastTrack [Flanagan and Freund 2010a] and SHB [Mathur et al. 2018] are state-of-the art happens-before based race predictors. For the above trace, both race predictors only report that E4 is part of a write-write race. This information is not very helpful as location E4 is protected by a mutex. Our method reports the pair (E2, E4) by enjoying the same O(n ∗ k) time complexity as the earlier works. Parameter n refers to the size of the trace and parameter k to the number of threads. Based on the pair (E2, E4), the user can easily see that E2 is unprotected and concludes that this location needs to be fixed. Assuming some additional processing step, our method is able to identify all pairs of events that are in a race for the schedule represented by the trace [E1, E2, E3, E4, E5]. For the above example, we additionally report the pair (E1, E4). By having such complete diagnostic information, the user can systematically fix the program. For example, by protecting E1 and E2 via a mutex. The additional processing step requiresO(n∗n) time. This extra cost is worthwhile as the more detailed diagnostic information potentially avoids further incremental re-runs to 1, , Martin Sulzmann and Kai Stadtmüller fix one race after the race. More seriously, incremental fixing of races might obfuscate some races. For example, consider a quick incremental fix based on the pair (E2, E4) where we guard location E2 via a mutex but E1 remains unguarded. The resulting program is as follows. // Thread 1 // Thread { { x = 5; // E1 acquire(y); // E acquire(y) // E2a x = 7; // E x = 6; // E2b release(y); // E release(y) // E2c } } Suppose, we re-run the program where we assume a similar interleaved execution as before. First thread 1 and then thread 2. This leads to the trace [E1, E2a, E2b , E2c , E3, E4, E5]. For this trace, both FastTrack and SHB report that there is no race. The reason for this is that the acquire event at location E3 must happen after the preceding release event at location E2c . Hence, the write at location E1 appears to happen before the write at location E4. Hence, there is no data race for this schedule. However, under a different schedule where thread 2 executes first, we find that (E1, E4) are in a write-write race. The issue is that the happens-before order relation is sensitive to the schedule of events as recorded in the trace. We say that the happens-before order is trace/schedule-specific. Recent works such as [Kini et al. 2017; Roemer et al. 2018] attempt to derive some further data races for as many alternative schedules as possible. These works, like FastTrack and SHB, only report some of the events involved in a race. Further re-runs to fix races that result from already explored schedules are necessary. Our approach is to report all pairs of events that are in a race for the trace-specific schedule. This enables the user to systematically examine and fix all races for a specific schedule. We achieve this via a novel two-phase data race predictor where in the first phase we (a) predict as many conflicting pairs of events, and (b) generate a compact, variablespecific representation of the happens-before relation to which we refer to as edge constraints. The second phase uses the reported conflicting pairs of events and edge constraints to identify all remaining races via a simple graph traversal. In summary, our contributions are: • We formalize and rigorously verify our two-phase method to identify all races for a trace-specific schedule (Sections 5 and 6). • We have fully implemented the approach and provide for a comparison with the state of the art in this area (Section 7). The upcoming section reviews the idea behind prior happensbefore based data race predictors and highlights the main idea behind our approach. Background on events, run-time 1♯ [1, 0] 2♯ [0, 1] Write(x) 1. w(x) [1, 0] [1, 0] 2. w(x) [2, 0] [2, 0] 3. w(x) [0, 1] [2, 1] Figure 1. Vector Clock Construction (SHB) traces and the happens-before relation is introduced in Section 3. Section 8 concludes and summarizes related work. Additional material such as proofs of results stated are given in the appendix. 2 Technical Overview 2.1 Data Race Prediction via Vector Clocks Vector clocks are a popular method to establish the happensbefore relation among events. A vector clock V is an array of time stamps (clocks) where each array position belongs to a specific thread. For each event we compute its vector clock and can thus identify the relative order among events by comparing vector clocks. Definition 2.1 (Vector Clocks). A vector clock V is a list of time stamps of the following form. V ::= [i1, . . . ,in] We assume vector clocks are of a fixed size n. Time stamps are natural numbers and each time stamp position j corresponds to the thread with identifier j. We define vector clock V1 to be smaller than vector clock V2, written V1 < V2, if (1) for each thread i, i's time stamp in V1 is smaller or equal compared to i's time stamp in V2, and (2) there exists a thread i where i's time stamp in V1 is strictly smaller compared to i's time stamp in V2. If the vector clock assigned to event e is smaller compared to the vector clock assigned to f , then we can argue that e happens before f . Figure 1 shows an example of how vector clocks are constructed. We consider a trace with events from two threads. The trace resembles the trace from the introduction where for brevity we omit acquire/release events. Events are recorded in linear order as they take place during program execution. For each event, we record the position in the trace as well as the id of the thread in which the event took place. We use a tabular notation to record this information. For the first thread we find a write followed by another write. In the trace, the write in the second thread appears after the writes in the first thread. As the writes lack any synchronization, we conclude that(w(x)1,w(x)3) and (w(x)2,w(x)3) are two pairs of events that represent a race. Let us carry out the vector clock construction steps. The initial vector clock for thread 1 is [1, 0] and for thread 2 it is [0, 1]. For each event, we record the vector clock when 2Predicting All Data Race Pairs for a Specific Schedule (extended version) , , 1♯ [1, 0] 2♯ [0, 1] W(x) E 1. w(x) [1, 0] {1♯1} 2. w(x) [2, 0] {1♯2} {1♯1 ≺ 1♯2} 3. w(x) [0, 1] {1♯2, 2♯1} Figure 2. Epochs and Edge Constraints (SHBE+E) processing the event. After processing, we increment the time stamp of the thread. We ignore the column Write(x) for the moment. How to check for a write-write data race? Assuming that each event carries a vector clock, we simply need to compare the vector clocks of events. For example, [1, 0] ≮ [0, 1] and [1, 0] ≯ [0, 1]. Hence, there is a trace reordering where we can place w(x)1 and w(x)3 right next to each other. The above reasoning implies that (1) for each event we need to store its vector clock, and (2) consider all possible combinations of events that might form a race and then compare their vector clocks. This requires timeO(n∗n∗k) where n is the size of the trace and k the number of threads. A rather costly computation and therefore data race predictors such as FastTrack and SHB perform a different approach that only requires time O(n ∗ k). SHB keeps track of all writes that took place via the vector clock Write(x). For the first write w(x)1, we simply set Write(x) to [1, 0]. Each subsequent write synchronizes with Write(x). Before synchronization, each write checks if its vector clock is greater or equal to the vector clock recorded in Write(x). If not, we report a race, as the current write must be concurrent to an earlier write. Hence, SHB reports that w(x)3 is part of a data race. But SHB neither reports the full pair that represents the race such as (w(x)2,w(x)4), nor reports all events that are part of a race. The same observations applies to FastTrack. 2.2 Our Idea: Epochs and Edge Constraints We make two major adjustments to the SHB algorithm to compute (1) pairs of events that are in a race and (2) all such pairs for the given schedule. We refer to the resulting algorithm as SHBE+E . We explain the adjustments based on our running example. First, instead of using a vector clock Write(x) to maintain the concurrent writes, we use a set W(x) of time stamps per concurrent write (referred to as epoch). Thus, we can report some conflicting pairs of events that form a data race while still guaranteeing the O(n ∗ k) time complexity like SHB. Some data race pairs are still missing. Our second adjustment of the SHB algorithm builds up a set of edge constraints. Each time a write happens after some of the currently recorded writes in W(x) and edge is added among the two writes involved. By traversing edges starting from an existing race pair, we report all conflicting pairs of events that form a data race. This (post-processing) step takes time O(n ∗ n) as we will show in detail later. We first consider the issue of reporting a pair of events that form a race, instead of just reporting some event that is part of race as it is done in SHB. To achieve this more refined reporting, we use epochs. An epoch is a pair of thread id and time stamp for that thread. Definition 2.2 (Epoch). Let j be a thread id and k be a time stamp. Then, we write j♯k to denote an epoch. Each event can be uniquely associated to an epoch. Take its vector clock and extract the time stamp k for the thread j the event belongs to. For each event this pair of information represents a unique key to locate the event. We revisit our earlier example. See Figure 2. We ignore the component E for the moment. In the first step, we add w(x)1's epoch 1♯1 to W(x). We maintain the invariant that W(x) is the set of recently processed writes that are concurrent to each other. Hence, after processing the second write we find W(x) to be equal 1♯2 as 1♯1 < 1♯2. Consider the processing of w(x)3 where 2♯1 is its epoch and [0, 1] is its vector clock. The time stamp of thread 1 for vector clock [0, 1] is smaller than the time stamp recorded by epoch 1♯2. Hence, we argue that the write represented by 1♯2 is concurrent to the write represented by 2♯1. Then, W(x) becomes equal to {1♯2, 2♯1}. We conclude that the associated events are in a writewrite race and report the write-write race pair(w(x)2,w(x)3). So, via epochs we can provide more refined data race reports. The complexity remains the same compared to the original SHB algorithm. The set of epochs grows as much as O(k). Hence, we require time O(n ∗ k) to report the same conflicting events as SHB but we additionally also report the complete conflicting pair of events. To compute all races, we require one further adaptation of the SHB algorithm. Each time we replace an epoch in W(x) by an epoch that happens later, we add an edge from the epoch to its replacement. Definition 2.3 (Edge). Leti♯k and j♯k be two epochs. Then, we write i♯k ≺ j♯k to denote the edge from i♯k to j♯k. We sometimes refer to i♯k ≺ j♯k as an edge constraint. We write ≺ ∗ to denote the transitive closure among edge constraints. These edge constraints are collected in E. In our example, we add 1♯1 ≺ 2♯2. Edge constraints represent a condensed view of the happens-before relation restricted to a specific variable. We employ edge constraints in a post-processing phase to identify all missing race pairs. When checking for further races starting with an existing race pair (e, f ), we look for events д that are reachable via edge constraints from e and f . 3, , Martin Sulzmann and Kai Stadtmüller If д ≺ ∗ e and д ≺ ∗ f , then neither (д, e) nor (д, f ) form another pair of conflicting events. This is the case because events in edge constraint relation are in the happens-before relation. Ifд ≺ ∗ e and д 6≺∗f , then (д, f ) is a potential pair of conflicting events. Potential because while edge constraints are sound but they are not complete w.r.t. the happens-before relation as we will explain in detail later. For our running example, we have the race pair(w(x)2,w(x)3) and find 1♯1 ≺ ∗ 2♯1. Hence, we conclude that (w(x)1,w(x)3) is another race pair. We can show that we thus compute all race pairs for the trace-specific schedule and the construction takes time O(n ∗ n). Experiments show that our approach is effective and provides much more detailed diagnostic information to the user compared to SHB and FastTrack. 3 Events and Run-Time Traces We introduce some background material on events and runtime traces. We consider concurrent programs that make use of threads, lock-based primitives, acquire and release of a mutex, and shared memory reads and writes. We assume that reads and writes follow the sequential consistency memory model. Execution of a program yields a trace. A trace is a sequence of events that took place and represents the interleaved execution of the various threads found in the program. Below, we formalize the shape of a trace and the kind of events we consider. Details of how to obtain a trace are discussed in the later Section 7. Definition 3.1 (Run-Time Traces and Events). T ::= [] | i♯e : T Trace e, f ,д ::= r(x)j| w(x)j| acq(y)j| rel(y)j Events A trace T is a list of events. We adopt Haskell notation for lists and assume that the list of objects [o1, . . . , on] is a shorthand for o1 : · · · : on : []. We write ++ to denote the concatenation operator among lists. For each event e, we record the thread id numberi in which the event took place, written i♯e, and the position j of the event in the trace. We sometimes omit the thread id and position for brevity. We write r(x)j andw(x)j to denote a read and write event on shared variable x at position j. We write acq(y)j and rel(y)j to denote a lock and unlock event on mutex y at position j. For brevity, we omit intra-thread synchronization primitives such as fork and join. They are dealt with by our implementation and do not pose any challenges in terms of the underlying theory as their treatment is very similar to acquire and release. For details see Appendix B. For trace T, we assume some helper functions to access the thread id and position of e. We define threadT (e) = j if T = T1 ++ [j♯e] ++ T2 for some traces T1,T2. We define posT(r(x)j) = j and so on. We assume that the trace position is accurate: If posT(e) = n then T = i1♯e1 : · · · : in−1♯en−1 : i♯e : T ′ for some events ik ♯ek and trace T ′ . We sometimes drop the component T and write thread(e) and pos(e) for short. Given a trace T, we can also access an event at a certain position k. We define T[k] = e if e ∈ T where posT(e) = k. For trace T, we define events(T) = {e | ∃T1,T2, j.T = T1 ++[j♯e] ++T2 } to be the set of events in T. We write e ∈ T if e ∈ events(T). For trace T, we define proj♯i(T) = T ′ the projection of T onto thread j where (1) for each e ∈ T where threadT (e) = i we have that e ∈ T ′ , and (2) for each e, f ∈ T ′ where posT ′(e) < posT′(f ) we have that posT (e) < posT(f ). That is, the projection onto a thread comprised of all events in that thread and the program order remains the same. Besides accurate trace positions, we demand that acquire and release events are in a proper acquire/release order. For each acquire there must be a matching release in the same thread and atomic sections cannot overlap. In case an acquire event lacks a matching release because the program has been terminated prematurely, we assume a dummy release event. Definition 3.2 (Proper Acquire/Release Order). We say a traceT enjoys a proper acquire/release order iff the following conditions are satisfied: • For each i♯acq(y)j1 ∈ T there exists i♯rel(y)j2 ∈ T where j1 < j2. For the event with the smallest position j2, we have that no other acquire/release event on y occurs in between trace positions j1 and j2. • For each i♯rel(y)j2 ∈ T there exists i♯acq(y)j1 ∈ T where j1 < j2. For the event with the greatest position j1, we have that no other acquire/release event on y occurs in between trace positions j1 and j2. We say a traceT is well-formed iff trace positions in T are accurate and T enjoys a proper acquire/release order. Each well-formed trace implies a happens-before relation among events. We follow [Mathur et al. 2018] and employ a happens-before relation that guarantees that all trace reorderings that satisfy this happens-before relation are schedulable. Definition 3.3 (Schedulable Happens-Before [Mathur et al. 2018]). Let T be a well-formed trace. We define a relation < H B(T) among trace events as the smallest partial order such that the following holds: Program order (PO): Let e, f ∈ T. Then, e < H B(T) f iff thread(e) = thread(f ) and pos(e) < pos(f ). Write-read dependency (WRD): Letr(x)j,w(x)k ∈ T. Then, w(x)j < H B(T) r(x)k iff j < k and for all e ∈ T where j < pos(e) and pos(e) < k we find that e is not a write event on x. Release-acquire dependency (RAD): Let rel(y)j, acq(y)k ∈ T. Then, rel(y)j < H B(T) acq(y)k iff j < k where thread(rel(y)j) , thread(acq(y)k ) and 4Predicting All Data Race Pairs for a Specific Schedule (extended version) , , for all e ∈ T where j < pos(e), pos(e) < k and thread(rel(y)j) , thread(e) we find that e is not an acquire event on y. We refer to < H B(T) as the schedulable happens-before relation. We generally say happens-before for short. If traceT is fixed based on the context, we write < H B for short. We say two events e, f ∈ T are concurrent to each other if neither e < H B(T) f , nor f < H B(T) e holds. In such a situation, we write e k f . Like earlier happens-before relations, e.g. consider [Flanagan and Freund 2010a], we demand that events must be ordered based on the program order (PO). An acquire event must happen after the nearest release event in the trace (RAD). As observed in [Mathur et al. 2018], write-read dependencies (WRD) must be respected. Otherwise, events are not necessarily schedulable. Consider the following example taken from [Mathur et al. 2018]. Example 3.4. Consider the well-formed trace T = [1♯r(x)1, 1♯w(y)2, 2♯r(y)3, 2♯w(x)4] Based on the schedulable happens-before relation, we have that w(y)2 < H B(T) r(y)3. In combination with the program order, we find find that r(x)1 < H B(T) w(x)4. So, the read on x happens before the write on x. Hence, there is no race that involves variable x. This is a conservative approximation of the program's behavior. The specific value y read at trace position 3 may affect the program's control flow. Hence, the earlier write on y must remain in the (relative) same position with respect to the subsequent read. The FastTrack algorithm [Flanagan and Freund 2010a] ignores WRD relations and therefore may yield false positives. Without WRD the following trace reordering is possible: [2♯r(y)3, 2♯w(x)4, 1♯r(x)1, 1♯w(y)2]. But there is no schedule resulting from some program run under which we encounter this sequence of events. To summarize. The schedulable happens-before relation ensures that all data races are indeed schedulable. We give a more precise description of data races. Definition 3.5 (Read/Write Events). LetT be a well-formed trace. We define T rw x as the set of all read/write events in T on some variable x. Let M ⊆ T be a subset of events in T. Then, we define M ↓ T rw x = M ∩T rw x . Definition 3.6 (Data Races). Let T be a well-formed trace. Let x be some variable and e, f ∈ T rw x be two read/write events on x. We say that (e, f ) are in a write-write data race if e and f are both write events and e and f are concurrent to each other. We say that (e, f ) are in a write-read data race if e is a write event and f is a read event where either (1) e and f are concurrent to each other, or (2a) e < H B(T) f and (2b) ¬∃e ′ ∈ T .e <H B(T) e ′ ∧ e′ <H B(T) f , and (2c) thread(e) , thread(f ). We denote by R T the set of all pairs of events (e, f ) where e, f ∈ T and (e, f ) are in write-write or write-read data race relation. Our definition of a data race implies that the trace can be reordered such that both (conflicting) events appear next to each other in the trace. This clearly applies for races where events involved are concurrent to each other. In case of a write-read dependency, the read must follow the write. This leads to a race if no other event appears in between (2b), and the write and read take place in different threads (2c). Example 3.7. Consider the following trace where we use a tabular notation. Events belonging to a specific threads appear in a separate column. 1♯ 2♯ 3♯ 1. w(x) 2. w(x) 3. r(x) 4. r(x) We find that R T = {(w(x)1,w(x)2), (w(x)1,r(x)3), (w(x)2,r(x)4)} where we omit symmetric cases. For the pairs(w(x)1,w(x)2) and (w(x)1,r(x)3), the events involved are concurrent to each other. The pair (w(x)2,r(x)4) is in write-read dependency relation and satisfies conditions (2a-c) Definition 3.6. The pair (w(x)2,r(x)3) is also in a write-read dependency relation but only satisfies (2b) and not (2c). Hence, this pair is not part of R T . 4 SHB Algorithm We give a recast of the SHB vector clock algorithm introduced in [Mathur et al. 2018] to predict data races under the schedulable happen-before relation. In addition, we show how to extend SHB to identify races due to write-read dependencies. Algorithm 1, referred to as the SHB algorithm, processes events in a stream-based fashion. The algorithm maintains several vector clocks. For each thread i we maintain a vector clock Š(i). For each variable x, we use a vector clock Write(x) to maintain the write access history to x. Similarly, we use Read(x) to maintain the read access history. We use a vector clock LW (x) to maintain the last write access as in the order specified in the trace. Similarly, for each mutex y, we use vector clock Rel(y) to maintain the last release event on y. Initially, for each vector clock Š(i) all time stamps are set to 0 but position i where the time stamp is set to 1. For Write(x), Read(x), LW (x) and Rel(y) all time stamps are set to 0. We define some helper functions to access and update the time stamp of a specific thread as well as a (point-wise) join 5, , Martin Sulzmann and Kai Stadtmüller operation of two vector clocks. [i1, . . . ,ij−1,ij,ij+1, . . . ,in][j] = ij [i1, . . . ,in][j 7→ k] = [i1, . . . ,ij−1, k,ij+1, . . . ,in] [i1, . . . ,in] ⊔ [j1, . . . , jn] = [max(i1, j1), . . . , max(in, jn)] It is easy to see that the join operation is associative. Hence, we will write V1 ⊔V2 ⊔V3 as a short-hand for V1 ⊔ (V2 ⊔V3). We write inc(V,i) as a short-hand for V := V [i 7→ V [i] + 1]. We write raceCheck(V1,V2) as a short-hand for \"if ¬V1 ⊑ V2 then race detected\" where [i1, . . . ,in] ⊑ [j1, . . . , jn] iff i1 ≤ j1 ∧ · · · ∧ in ≤ jn. We consider the various cases of Algorithm 1. For acquire and release events, parameter i refers to the thread id and x refers to the name of the mutex. Similarly, for writes and reads, i refers to the thread id and x refers to the name of the variable. Parameter k refers to the trace position. This is parameter is only necessary for reads and writes. We use the trace position to uniquely identify each event. Vector clocks are updated as follows. In case of an acquire event we synchronize the thread's vector clock with the most recent (prior) release event by building the union of the vector clocks Š(i) and Rel(x). In case of a release event, we update Rel(x). In case of a write event, we compare the thread's vector clock against the read and write histories Read(x) and Write(x)to check for a write-read and write-write race. Then, we update LW (x) to record the vector clock of the most recent write on x. For the write history Write(x), we update the time stamp at position i to the thread's time stamp at that position. In case of a read event, check for read-write races by comparing the thread's vector clock against Write(x). Only then we synchronize the thread's vector clock with the vector clock LW (x) of the most recent write. The history of reads is updated similarly as in case of writes. Example 4.1. We consider a run of the SHB algorithm. The example does not involve any mutex and the last write always takes place in the same thread. Hence, the components Rel(x) and LW (x) can be ignored. We underline events for which a call to raceCheck(, ) issues a race. The subscript indicates if the event is in a race with a read (r) or a write (w). For presentation purposes, we first show the annotated trace where the columns Write(x) and Read(x) follow below. 1♯ [1, 0, 0] 2♯ [0, 1, 0] 3♯ [0, 0, 1] 1. w(x) [1, 0, 0] 2. r(x) [2, 0, 0] 3. w(x) rw [0, 1, 0] 4. r(x) w [0, 2, 0] 5. r(x) w [0, 0, 1] Algorithm 1 SHB algorithm 1: procedure acqire(i, x) 2: Š(i) = Š(i) ⊔ Rel(x) 3: end procedure 1: procedure write(i, x, k) 2: raceCheck(Write(x), Š(i)) 3: raceCheck(Read(x), Š(i)) 4: LW (x) = Š(i) 5: Write(x)[i 7→ Š(i)[i]] 6: inc(Š(i),i) 7: end procedure 1: procedure release(i, x) 2: Rel(x) = Š(i) 3: inc(Š(i),i) 4: end procedure 1: procedure read(i, x, k) 2: raceCheck(Write(x), Š(i)) 3: Š(i) = Š(i) ⊔ LW (x) 4: Read(x)[i 7→ Š(i)[i]] 5: inc(Š(i),i) 6: end procedure Write(x) Read(x) 1. [1, 0, 0] 2. [2, 0, 0] 3. [1, 1, 0] 4. [2, 2, 0] 5. [2, 2, 1] We first find a write followed by a read and update the thread's vector clock as well as Write(x) and Read(x) accordingly. As both events are in the same thread, there is no race issued. In the third step, we find another write. The event is underlined with rw as both calls raceCheck(Write(x), [0, 1, 0]) and raceCheck(Read(x), [0, 1, 0]) issue a race. The read in the fourth step is in a race with a write. The same applies to the read in the fifth step. We observe that events w(x)1 and r(x)2 are part of a race but not underlined. For example, the vector clock [1, 0, 0] of w(x)1 and the vector clock [0, 1, 0] of w(x)3 are incomparable. Hence, both events form a write-write data race pair. Based on the above example, we conclude that the SHB algorithm reports some events that are involved in a race but not all. The time and space complexity of the SHB algorithm is O(n ∗ k) where n is the length of the trace and k the number of threads. We assume that each vector clock requires 6Predicting All Data Race Pairs for a Specific Schedule (extended version) , , O(k)space and comparing two vector clocks takes timeO(k). For each event n we maintain a constant number of vector clocks including some comparisons. Hence, O(n ∗ k). 5 SHBE+E Algorithm Our goal is to identify all pairs of events that are in a race and identify all such conflicting pairs for the given schedule. We focus on conflicting pairs where the events involved are concurrent to each other. The special case of write-read races due to write-read dependencies is dealt with by the adaptation described above. To achieve our goal we require two phases. Algorithm 2 SHBE+E Algorithm 1: procedure acqire(i, x) 2: Š(i) = Š(i) ⊔ Rel(x) 3: end procedure 1: procedure release(i, x) 2: Rel(x) = Š(i) 3: inc(Š(i),i) 4: end procedure 1: procedure write(i, x, k) 2: evt = {(k, Š(i))} ∪ evt 3: conc(x) = {(j♯k,i♯Š(i)[i]) | j♯k ∈ RW(x) ∧ k > Š(i)[j]} ∪ conc(x) 4: edges(x) = edges(x) ∪ {j♯k ≺ i♯Š(i)[i] | j♯k ∈ RW(x) ∧ k < Š(i)[j]} 5: RW(x) = {i♯Š(i)[i]} ∪ {j♯k | j♯k ∈ RW(x) ∧ k > Š(i)[j]} 6: LW (x) = Š(i) 7: inc(Š(i),i) 8: end procedure 1: procedure read(i, x, k) 2: Š(i) = Š(i) ⊔ LW (x) 3: evt = {(k, Š(i))} ∪ evt 4: conc(x) = {(j♯k,i♯Š(i)[i]) | j♯k ∈ RW(x) ∧ k > Š(i)[j]} ∪ conc(x) 5: edges(x) = edges(x) ∪ {j♯k ≺ i♯Š(i)[i] | j♯k ∈ RW(x) ∧ k < Š(i)[j]} 6: RW(x) = {i♯Š(i)[i]} ∪ {j♯k | j♯k ∈ RW(x) ∧ k > Š(i)[j]} 7: inc(Š(i),i) 8: end procedure The first phase is carried out by Algorithm 2, referred to as the SHBE+Ealgorithm. The (second) post-processing phase is described in the upcoming section. Like SHB, algorithm SHBE+Eemploys vector clocks Š(i), Rel(x) and LW (x). In addition, SHBE+E outputs three types of sets where two sets are indexed by shared variable x: conc(x), edges(x) and evt. Set conc(x) holds pairs of concurrent reads/writes. As motivated in Section 2, via a linear pass through the events the set conc(x) might not necessarily include all pairs of events that are in a race. However, the missing pairs are reachable via edge constraints accumulated by edges(x). Edge constraints are sound but not complete w.r.t. the happens-before relation. Hence, we might need to filter out some candidate pairs. For filtering, we require the set evt where evt records for each event its vector clock, The details of post-processing based on these three sets are explained in the upcoming section. Besides the three sets conc(x), edges(x) and evt, SHBE+E maintains some other set RW(x) to record the most recent concurrent set of reads/writes. Initially, all sets are empty. The treatment of acquire and release is the same as in case of SHB. In case of a write event, we record the writer's vector clock by updating evt. We use the trace position to uniquely identify each event and thus record its associated vector clock as pairs in evt. We record the most recent write by updating LW (x). Each read event, synchronizes with LW (x) to ensure that write-read dependencies are respected. Next, we consider the update of sets conc(x) and RW(x). Recall that each event can be identified by its epoch and vice versa. When processing event e in thread i with vector clock Š(i), the epoch associated to e is i♯Š(i)[i]. We add new pairs to conc(x) by comparing the current epoch (event) i♯Š(i)[i] against epochs j♯k in RW(x). A new pair is added if k > Š(i)[j]. Similarly, we adjust the set RW(x). The epoch i♯Š(i)[i] is added to RW(x) and we only keep epoch j♯k in the set RW(x) if k > Š(i)[j]. The treatment is the same for writes and reads. For each read and write, we add an edge from an epoch j♯k in RW(x)to the currently being processed epochi♯Š(i)[i] if k < Š(i)[j]. 5.1 Properties The following result establishes that the events (epochs) reported in RW(x) and the pairs of events (epochs) reported in conc(x) are concurrent to each other. Proposition 5.1. Let T be a well-formed trace and x some variable. Then, for any subtrace T ′ ⊆ T the sets conc(x) and RW(x) obtained after running Algorithm 2 on T ′ enjoy the following properties. All events in RW(x) are concurrent to each other and for each (e, f ) ∈ conc(x) we have that e and f are concurrent to each other. We note that by construction, for each (e, f ) ∈ conc(x) we have that e appears before f in the trace. That is, pos(e) < pos(f ). As shown by the following example, the set conc(x) does not necessarily contain all concurrent pairs of events for the schedule implied by < H B(T) . Example 5.2. Consider the following annotated trace after processing via Algorithm 2. For clarity, epochs are annotated with their corresponding events, e.g. 1♯1w . 7, , Martin Sulzmann and Kai Stadtmüller 1♯ 2♯ RW(x) conc(x) 1. w(x)[1, 0] {1♯1w1} 2. w(x)[2, 0] {1♯2w2} 3. w(x)[0, 1] {1♯2w , 2♯1w3} {(1♯2w2, 2♯1w3)} Algorithm 2 reports the concurrent pair(1♯2w2, 2♯1w3) but fails to report the (missing) concurrent pair (1♯1w1, 2♯1w3). While conc(x)lacks certain pairs of concurrent events, we can provide for a sufficient condition under which a pair (e, f ) is added to conc(x). In essence, a pair (e, f ) is added to conc(x) whenever f has no other concurrent partner that appears within e and f in the trace. Lemma 5.3. Let T be a well-formed trace. Let e, f ∈ T rw x for some variable x such that (1) e and f are concurrent to each other, (2) pos(f ) > pos(e), and (3) ¬∃д ∈ T rw x where д and f are concurrent to each other and pos(f ) > pos(д) > pos(e). Let conc(x) be the set obtained by running Algorithm 2 on T Then, we find that (e, f ) ∈ conc(x). Recall Example 5.2. The reported pair (w2,w3) satisfies this property. However, (w1,w3) is not reported because w appears in between. As we show in the up-coming section, such missing pairs can be reached via edge constraints because edges approximate the happens-before relation. Proposition 5.4 (Soundness of Edge Constraints). Let T be a well-formed trace and x be some variable. Let edges(x) be the set of edge constraints obtained by running Algorithm onT. Then, for each e, f ∈ T where e ≺ ∗ f based on the edges in edges(x) we find that e < H B(T) f . 5.2 Time and Space Complexity Let n be the size of the trace T and k be the number of threads. We assume that the number of distinct variables x is a constant. We consider the time and space complexity of running SHBE+E. The size of the vector clocks and the set RW(x)is bounded byO(k). In each step of SHBE+E, adjustment of vector clocks takes time O(k). Adjustment of sets conc(x), edges(x) and RW(x) requires to consider O(k) epochs where each comparison among epochs is constant. So, in each step this requires time O(k). Adjustment of set evt takes constant time. Overall, Algorithm 2 runs in time O(n ∗ k). We consider the space complexity. The sets evt, conc(x) and edges(x) take space O(n ∗k). This applies to evt because for each event the size of the vector clock is O(k). Each element in conc(x) and edges(x) requires constant space. In each step, we may add O(k) new elements because the size of RW(x) is bounded byO(k). Overall, Algorithm 2 requires space O(n ∗ k). 6 SHBE+E Post-Processing Based on the setsconc(x) and edges(x) computed by SHBE+E we compute all remaining concurrent reads/writes. The important property is that all pairs of concurrent reads/writes are either already contained in conc(x) or can be reached via some edges. Definition 6.1 (All Concurrent Reads/Writes). Let T be a well-formed trace and x be some variable. We define C T (x) = {(e, f ) | e, f ∈ T rw x ∧ e k f ∧ pos(e) < pos(f )} the set of all reads/writes on x that are concurrent to each other. It is clear that if (e, f ) is a concurrent pair, so is the pair (f , e). For technical reasons, we only keep the pair where the first component appears first in the trace. Lemma 6.2. LetT be a well-formed trace and x be some variable. Let conc(x) be the set of concurrent pairs of events and edges(x) be the set of edge constraints obtained by running Algorithm 2 on T. Let (e, f ) ∈ CT(x) where (e, f ) < conc(x) and pos(e) < pos(f ). Then, there exists д such that e ≺ ∗ д and (д, f ) ∈ conc(x). Based on results stated in Lemmas 5.3 and 6.2, we can effectively compute all concurrent writes/reads by scanning through the sets conc(x) and RW(x). We use symbols α, β,γ to denote epochs. As we know, each epoch uniquely corresponds to an event and vice versa. Hence, for epoch α, we write pos(α) to obtain the trace position of the event that corresponds to α. Definition 6.3 (SHBE+E Post-Processing). Let conc(x) and edges(x) be obtained by running Algorithm 2 on some wellformed trace T. We first introduce a total order among pairs of epochs (α, β) ∈ conc(x) and (α ′ , β ′ ) ∈ conc(x). We define (α, β) < (α ′ , β ′ ) if pos(α) < pos(α ′ ). This defines a total order among all pairs of epochs where the event corresponding to the epoch in the first position appears before the event corresponding to the epoch in the second position. Then, repeatedly perform the following steps where we initially assume that P(x) := {}. 1. If conc(x) = {} stop. 2. Otherwise, let(α, β) be the smallest element in conc(x). 3. LetG = {γ1, . . . ,γn } be maximal such thatγ1 ≺ α, . . . ,γn ≺ α ∈ edges(x) and pos(γ1) < · · · < pos(γn). 4. P(x) := {(α, β)} ∪ P(x). 5. conc(x) := {(γ1, β), . . . , (γn, β)} ∪ (conc(x) − {(α, β)}). 6. Repeat. Theorem 6.4. Let T be a well-formed trace of size n. Let x be a variable. Then, construction of P(x) takes time O(n ∗ n) and C T (x) ⊆ P(x). The set P(x) is a superset of C T (x) because pairs (α, β) added to P(x) may not necessarily be concurrent to each 8Predicting All Data Race Pairs for a Specific Schedule (extended version) , , other. For space reasons, we refer to Appendix C for an example. We can easily eliminate such cases by comparing α's time stamp against the time stamp of β's vector clock. Proposition 6.5 (Eliminate Non-Concurrent Pairs). Let x be some variable. Let (i♯k, j♯l) ∈ P(x) Let pos(j♯l) = m and (m,V) ∈ evt. Then, remove (i♯k, j♯l) from P(x) if k < V [j]. Applying this check to all pairs in P(x) yields that P(x) = C T (x). Example 6.6. We consider a run of SHBE+E. We omit vector clocks and the component evt. Instead of epochs, we refer to the corresponding event and its trace position. For conc(x) we write down the newly added elements in each step. For space reasons, we omit an extra column for edges(x) and report this set below. 1♯ 2♯ 3♯ RW(x) conc(x) 1. w(x) {w(x)1} 2. r(x) {r(x)2} 3. w(x) {r(x)2,w(x)3} (r(x)2,w(x)3) 4. r(x) {r(x)2,r(x)4} (r(x)2,r(x)4) 5. r(x) {r(x)2,r(x)4,r(x)5} (r(x)2,r(x)5) (r(x)4,r(x)5) where edges(x) = {w(x)1 ≺ r(x)2,w(x)3 ≺ r(x)4}. So, after processing the trace we obtain conc(x) = {(r(x)2,w(x)3), (r(x)2,r(x)4), (r(x)2,r(x)5), (r(x)4,r(x)5)} and edges(x) = {w(x)1 ≺ r(x)2,w(x)3 ≺ r(x)4} We apply the post-processing described in Definition 6. to obtain the set P(x). Elimination as described in Proposition 6.5 is not necessary for this example. Via (r(x)2,w(x)3) and edgew(x)1 ≺ r(x)2 we add the pair (w(x)1,w(x)3). Via similar reasoning, we finally obtain P(x) = {(r(x)2,w(x)3), (r(x)2,r(x)4), (r(x)2,r(x)5), (r(x)4,r(x)5), (w(x)1,w(x)3), (w(x)1,r(x)4), (w(x)1,r(x)5), (w(x)3,r(x)5)} 6.1 Data Race Optimization The set conc(x) and the construction in Definition 6.3 also includes pairs of concurrent reads. Such pairs are generally not interesting as they do not represent a data race. However, we cannot simply ignore read-read pairs. Recall Example 6.6 where via the pair(r(x)2,r(x)5) we obtain (w(x)1,r(x)5). To ignore read-read pairs during the post-processing construction of all (concurrent) data races, we need to adapt our method as follows. In SHBE+E, in case of a read event e, we only remove events from RW(x) if these events happen before e and are not write events. That is, a write event in RW(x) can only be removed by a subsequent write. See Algorithm 3 where we only show the case of read as all other parts are unaffected. Algorithm 3 SHBE+E Algorithm (Data Race Optimization) 1: procedure read(i, x, k) 2: Š(i) = Š(i) ⊔ LW (x) 3: evt = {(k, Š(i))} ∪ evt 4: conc(x) = {(j♯k,i♯Š(i)[i]) | j♯k ∈ RW(x) ∧ k > Š(i)[j] ∧ j♯k is a write} ∪ conc(x) 5: edges(x) = edges(x) ∪ {j♯k ≺ i♯Š(i)[i] | j♯k ∈ RW(x) ∧ k < Š(i)[j]} 6: RW(x) = {i♯Š(i)[i]} ∪ {j♯k | j♯k ∈ RW(x) ∧ (k > Š(i)[j] ∨ j♯k is a write} 7: inc(Š(i),i) 8: end procedure Thus, we effectively build the transitive closure of writes that can be reached via a read. Hence, any concurrent writeread pair (e, f ) that would be obtained via edge f ≺ д and the read-read pair(f ,д), is already present in conc(x). Hence, there is no need to record read-read pairs in conc(x). Example 6.7. We consider the trace from Example 6.6 where we use the adapted Algorithm 3. We omit the trace and show only components RW(x) and conc(x). RW(x) conc(x) 1. {w(x)1} 2. {w(x)1,r(x)2} 3. {w(x)1,r(x)2,w(x)3} (w(x)1,w(x)3) (r(x)2,w(x)3) 4. {w(x)1,r(x)2,w(x)3,r(x)4} (w(x)1,r(x)4) 5. {w(x)1,r(x)2,w(x)3,r(x)4,r(x)5} (w(x)1,r(x)5) (w(x)3,r(x)5) Unlike in the earlier calculations in Example 6.6, w(x)1 is not eliminated from RW(x) in the second step. Hence, we add (w(x)1,w(x)3) to conc(x). Similarly, in the fourth step we keep w(x)3 and therefore add (w(x)3,r(x)5) to conc(x). After processing the trace we obtain conc(x) = {(w(x)1,w(x)3), (r(x)2,w(x)3), (w(x)1,r(x)4), (w(x)1,r(x)5), (w(x)3,r(x)5)} Post-processing does not yield any further data races for this example. 6.2 Time and Space Complexity We investigate the complexity to predict all data races that are schedulable as defined by Definition 3.6. Algorithm 3, optimized for data race prediction, enjoys the same time and space complexity results as SHBE+E. This is the case because the size of RW(x) is still bounded by O(k). A read no longer removes a write, so for k concurrent reads we may have a maximum of k additional writes in RW(x). Hence, O(k) elements in the worst-case. Hence, the time complexity of the first phase is O(n ∗ k). 9, , Martin Sulzmann and Kai Stadtmüller It is easy to integrate the prediction of all write-read races due to write-read dependencies without affecting the time and space complexity of Algorithms 2 and 3. We consider the (second) post-processing phase where we only consider the time complexity. Based on the data race optimization describe above, read-read pairs no longer arise. In practice, this is a huge improvement. The construction of P(x)still takes timeO(n∗n) as stated by Theorem 6. because the worst-case number of pairs to consider remains the same. The elimination step as described in Proposition 6. requires to compare time stamps. This takes constant time. Then, the post-processing phase takes time O(n ∗ n). In summary, the prediction of all schedulable data races based on SHBE+Eand post-processing takes time O(n ∗k) + O(n ∗ n). 7 Implementation and Experiments We have implemented SHBE+Eincluding post-processing to obtain all data race pairs. For comparison, we have also implemented SHB [Mathur et al. 2018]. We have also implemented a variant of SHB referred to as SHB∀ . SHB∀additionally builds the set evt that records for each event its vector clock. In some post-processing phase, we build the set of all data races pairs by comparing vector clocks for each candidate pair. This variant has been briefly sketched in [Mathur et al. 2018]. The post-processing requires time O(n ∗ n ∗ k) as there are O(n ∗ n) candidate pairs to consider and each comparison takes time O(k). The input for all algorithms is a trace in CSV format containing read, write, acquire, release as well as fork and join events. Instead of events, we report the code locations connected to each event. We avoid reporting of repeated code locations. The same applies to pairs of code locations. All algorithms are implemented in the Go programming language. It is in terms of syntax and performance similar to C but offers garbage collection, memory safety and CSP-style concurrency. The implementations can be found at hps://github.com/KaiSta/shbee. 7.1 Benchmarks We benchmark the performance of SHBE+E, SHB and SHB∀. For benchmarking we use two Intel Xeon E5-2650 and gb of RAM with Ubuntu 18.04 as operating system. Following [Mathur et al. 2018], we use tests from the Java Grande Forum ([Smith et al. 2001]) and from the DaCapo (version 9.12, [Blackburn et al. 2006]) benchmark suite. All benchmark programs are written in Java and use up to 58 threads. For instrumentation and tracing we make use of the RoadRunner tool [Flanagan and Freund 2010b]. The entire trace is kept in memory and then (off-line) each algorithm processes the trace. Table 1 shows the benchmark results. We measure the time, memory consumption and number of predicted data races. The first row for each algorithm contains the overall execution time. This includes the start up of the program, parsing the trace etc. We use the standard 'time' program in Ubuntu to measure this time. The memory consumption is also measured for the complete program and not only for the single algorithms. We include 'TReplay' to measure the time (seconds) and memory consumption (megabytes) for trace replay without any attached race prediction algorithm. For example, for the xalan benchmark TReplay takes time 85s and 11052mb. For SHB we measure 92s and 11114mb. The difference is the actual time and space spent for data race prediction applying Algorithm 1. For SHBE+E we additionally provide the time for each (data race prediction) phase. Phase 1 corresponds to running Algorithm 2 and phase 2 to the post-processing step described in Section 6. Additional processing steps such as parsing, reporting data races and so on are not included. For example, the xalan benchmark takes 85 seconds with TReplay while SHBE+Etakes 105 seconds overall and 11 seconds for phase 1. The time 0s in phase 2 arises because for most benchmarks data races arise very early during the execution of benchmark programs. Hence, the post-processing step only needs to cover small portions of the trace and the time spent is negligible. There is a difference of nine seconds, if we compare the 85 seconds with TReplay against SHBE+E's 105 seconds minus 11 seconds for phase 1+2. The difference arises because TReplay does not report any data races nor keeps track of any other statistical data. For the moldyn benchmark, SHBE+Erequires 64 seconds whereas SHB's race prediction phase requires 10 seconds (by subtracting TReplay's 71 seconds from the 81 seconds overall SHB running time). For the other benchmarks, SHBE+E's phase 1 is comparable with SHB. The difference for the moldyn benchmark arises because we predict a huge number of race pairs where the events involved all refer to the same code locations. For moldyn, SHBE+E only reports 18 unique race pairs in phase 1. The management and elimination of duplicates causes some overhead in SHBE+E. This is something we plan to optimize in the future. In terms of time and memory consumption, SHB performs best followed. SHBE+Eshows competitive performance compared to SHB. SHB∀ does not seem to scale for larger benchmarks. For moldyn, avrora and h2, we aborted the test after one hour (marked with *). We consider the number of predicted races. SHBE+Eand SHB∀report complete pairs of code locations that are in a race. For both, the number of predicted data races is written as X+Y where X are the data races found in the first phase and Y those found in the post-processing phase. In case of SHB∀, X always equals 0 as the calculation of races is completely carried by the post-processing phase. As can be seen, for most benchmarks, a large portion of race pairs are already predicted in the first phase via SHBE+E. 10Predicting All Data Race Pairs for a Specific Schedule (extended version) , , moldyn raytracer xalan lusearch tomcat avrora h TReplay (s) 71 0 85 3 37 19 Memory (mb) 9514 46 11052 576 5200 2672 SHBE+E(s) 117 1 105 4 63 53 Memory (mb) 19415 81 12566 579 10404 12669 Phase1+2 (s) 64+2 0+0 11+0 1+0 24+0 36+0 135+ #Races 18+6 1+0 44+5 24+0 677+324 32+0 285+ SHB∀(s) >1h* 18 1206 4 957 >1h* >1h* Memory (mb) 16594 69 12691 585 8986 4787 #Races 0+21 0+1 0+49 0+24 0+1001 0+30 0+ SHB (s) 81 0 92 5 54 28 Memory (mb) 11492 55 11114 586 6614 3585 #Races* 9 1 35 23 492 20 Table 1. Benchmark Results If we are only interested in the race pairs predicted in phase 1, we could optimize SHBE+Eas follows. We drop evt and edges(x) and only maintain RW(x). Then, we achieve O(k) memory consumption and it is possible to run SHBE+E online (like SHB). 7.2 SHB versus SHBE+E We carry out a more detailed analysis between SHB and SHBE+Eregarding the quality and quantity of races reported. We examine the following questions. How often does SHB report locations f that are already protected by some mutex? Recall the discussion from the introduction. Reporting a protected location f is not very helpful in fixing the data race. Rather, we wish to identify the race partner e that lacks protection. Another interesting question is the following. How many additional race locations are detected by SHBE+Eand its post-processing phase? As argued in the introduction, knowing all race locations is useful in systematically fixing a buggy schedule. We consider the first question. Based on Theorem 4.2. from [Mathur et al. 2018], we observe that for each race location f reported by SHB we have that SHBE+Ereports the race pair (e, f ) for some location e. Hence, it suffices to consider race pairs (e, f ) reported by SHBE+Ein the following refined analysis. We employ a variant of SHBE+E where for each read/write event e we compute the set of locks (mutexes) that have been acquired by the thread by the time we process e. We refer to this set as lockset(e). Computation of lockset(e) is straightforward. Each thread i maintains lockset(i). Each acquire in thread i adds the respective mutex to lockset(i). Each release removes the mutex from lockset(i). When processing write/read event e in thread i, we set lockset(e) = lockset(i). For each data race pair(e, f )reported by SHBE+E we must have that lockset(e) ∩ lockset(f ) = ∅. To check if e, or f or both e and f lack protection, we distinguish among the following cases: (C1) lockset(e) = {} and lockset(f ) , {}, (C2) Test C1 C2 C3 #Race pairs (e, f ) moldyn 0 0 18 tomcat 43 28 606 xalan 1 0 43 raytracer 1 0 0 lusearch 6 0 18 avrora 13 4 15 h2 8 7 270 Table 2. Lockset analysis lockset(e) , {} and lockset(f ) = {}, and (C3) lockset(e) , {}, lockset(f ) , {} and lockset(e) ∩ lockset(f ) = {}. As SHB only reports f for a pair (e, f ), case (C1) means that the location reported by SHB is rather useless for fixing the data race. In case of (C2) the location reported by SHB is sufficient to fix the race (assuming the fix involves a mutex). For case (C3), we might also need to inspect the race partner e. We carry out this additional analysis for our benchmark programs and measure how often the various cases (C1-3) arise. Results are reported in Table 2. As can be seen, case (C3) arises most frequently. Case (C1) arises in general less frequent. Thanks to the refined analysis provided by our method, the user can more easily navigate to the source location that requires fixing. We examine the second question. How many additional race locations are detected by SHBE+Eand its post-processing phase in comparison to SHB? For example, consider the trace [1♯w(x)1, 1♯w(x)2, 2♯w(x)3] for the example in Section 2. Assuming that trace positions refer to code locations, SHB reports the location 3. SHBE+E reports the locations 2 and because the race pair (2,3) is detected. The post-processing phase of SHBE+Eadditionally reports location 1 as post-processing yields the race pair (1,3). Table 3 shows these additional analysis results for our benchmark programs. As can been seen, SHBE+Ealone (first 11, , Martin Sulzmann and Kai Stadtmüller Test SHB SHBE+E SHBE+E + post-processing moldyn 9 23 tomcat 492 644 xalan 35 55 raytracer 1 1 lusearch 23 39 avrora 20 28 h2 105 123 Table 3. Number of distinct locations reported phase) covers more code locations than SHB and these locations are mostly all locations that are involved in a data race. 8 Related Works and Conclusion Vector clocks are the main technical method to establish the happens-before ordering. Originally, vector clocks were introduced in the message-passing setting, see works by Fidge [Fidge 1988] and Mattern [Mattern 1989]. In the context of data race prediction, vector clocks are employed by Pozniansky and Schuster [Pozniansky and Schuster 2003]. The FastTrack algorithm by Flanagan and Freund [Flanagan and Freund 2010a] employs an optimized representation of vector clocks where only the thread's time stamp, referred to as an epoch, need to be traced. It is folklore knowledge, that vector clock based race predictors are only sound for the first data race found. This is due to improper treatment of write-read dependencies that leads to an overapproximation of the happensbefore relation. ThreadSanitizer (Tsan) by Serebryany and Iskhodzhanov [Serebryany and Iskhodzhanov 2009] is a hybrid race predictor that combines happens-before (for fork-join) with lockset [Dinning and Schonberg 1991] to identify conflicting memory accesses. Like FastTrack, Tsan yields potentially false positives. Banerjee, Bliss, Ma and Petersen [Banerjee et al. 2006] develop criteria which data races can be found with a limited (trace) history. The history options considered are keeping track of the last event (independent if its a read or a write), last read and write event, last event for each thread and last write and all concurrent reads. They observe that none of the limited histories is able to predict all data races. Mathur, Kini and Viswanathan [Mathur et al. 2018] introduce a variant of the standard vector clock algorithm that properly deals with write-read dependencies. The thus strengthened happens-before relation is referred to as the schedulable happens-before relation. The algorithm in [Mathur et al. 2018] identifies some events that are involved in a data race. The question of how to efficiently infer (all) pairs of events that are in a schedulable data race is not addressed. There are several recent works that employ happens-before methods to derive further data races for as many alternative schedules as possible. See the works Smaragdakis,Evans, Sadowski, Yi and Flanagan [Smaragdakis et al. 2012], Kini, Mathur and Viswanathan [Kini et al. 2017] as well as Roemer, Genç and Bond [Roemer et al. 2018]. Huang, Luo and Rosu [Huang et al. 2015] go a step further to obtain even more races and trace values to guarantee that write-read dependencies are respected. They employ SMT-based solving methods to enumerate as many races as possible. Recent work by Kalhauge and Palsberg [Kalhauge and Palsberg 2018] follows a similar approach. The issue with these methods is that the computational cost is very high. See the benchmark results reported in [Kalhauge and Palsberg 2018]. We attack a different problem that is complementary to the above works. For a trace-specific schedule, we wish to efficiently find all pairs of events that are in a race and that are schedulable w.r.t. the happens-before relation defined in [Mathur et al. 2018]. Thus, the user is able to systematically examine and fix all data races for a specific schedule. Our experiments show that the approach is effective and provides the user with detailed diagnostic information. Acknowledgments We thank referees for OOPSLA'19 and MPLR'19 for their helpful comments on previous versions of this paper. References Utpal Banerjee, Brian Bliss, Zhiqiang Ma, and Paul Petersen. 2006. A theory of data race detection. In Proceedings of the 2006 workshop on Parallel and distributed systems: testing and debugging. ACM, 69–78. Stephen M. Blackburn, Robin Garner, Chris Hoffmann, Asjad M. Khang, Kathryn S. McKinley, Rotem Bentzur, Amer Diwan, Daniel Feinberg, Daniel Frampton, Samuel Z. Guyer, Martin Hirzel, Antony Hosking, Maria Jump, Han Lee, J. Eliot B. Moss, Aashish Phansalkar, Darko Stefanović, Thomas VanDrunen, Daniel von Dincklage, and Ben Wiedermann. 2006. The DaCapo Benchmarks: Java Benchmarking Development and Analysis. In Proceedings of the 21st Annual ACM SIGPLAN Conference on Object-oriented Programming Systems, Languages, and Applications (OOPSLA '06). ACM, New York, NY, USA, 169–190. hps://doi.org/10.1145/1167473. Anne Dinning and Edith Schonberg. 1991. Detecting Access Anomalies in Programs with Critical Sections. SIGPLAN Not. 26, 12 (Dec. 1991), 85–96. hps://doi.org/10.1145/127695. Colin J. Fidge. 1988. Timestamps in message-passing systems that preserve the partial ordering. Proceedings of the 11th Australian Computer Science Conference 10, 1 (1988), 56–66. hp://sky.scitech.qut.edu.au/~fidgec/Publications/fidge88a.pdf Cormac Flanagan and Stephen N Freund. 2010a. FastTrack: efficient and precise dynamic race detection. Commun. ACM 53, 11 (2010), 93–101. Cormac Flanagan and Stephen N Freund. 2010b. The RoadRunner dynamic analysis framework for concurrent programs. In Proceedings of the 9th ACM SIGPLAN-SIGSOFT workshop on Program analysis for software tools and engineering. ACM, 1–8. Jeff Huang, Qingzhou Luo, and Grigore Rosu. 2015. GPredict: Generic Predictive Concurrency Analysis. In Proc. of ICSE '15. IEEE Press, 847–857. Christian Gram Kalhauge and Jens Palsberg. 2018. Sound Deadlock Prediction. Proc. ACM Program. Lang. 2, OOPSLA, Article 146 (Oct. 2018), 29 pages. hps://doi.org/10.1145/ Dileep Kini, Umang Mathur, and Mahesh Viswanathan. 2017. Dynamic Race Prediction in Linear Time. SIGPLAN Not. 52, 6 (June 2017), 157– 170. 12Predicting All Data Race Pairs for a Specific Schedule (extended version) , , Leslie Lamport. 1978. Time, clocks, and the ordering of events in a distributed system. Commun. ACM 21, 7 (1978), 558–565. Umang Mathur, Dileep Kini, and Mahesh Viswanathan. 2018. What Happens-after the First Race? Enhancing the Predictive Power of Happens-before Based Dynamic Race Detection. Proc. ACM Program. Lang. 2, OOPSLA, Article 145 (Oct. 2018), 29 pages. hps://doi.org/10.1145/ Friedemann Mattern. 1989. Virtual Time and Global States of Distributed Systems. In Parallel and Distributed Algorithms. North-Holland, 215– 226. Eli Pozniansky and Assaf Schuster. 2003. Efficient On-the-fly Data Race Detection in Multithreaded C++ Programs. SIGPLAN Not. 38, 10 (June 2003), 179–190. hps://doi.org/10.1145/966049. Jake Roemer, Kaan Genç, and Michael D. Bond. 2018. High-coverage, Unbounded Sound Predictive Race Detection. SIGPLAN Not. 53, 4 (June 2018), 374–389. hps://doi.org/10.1145/3296979. Konstantin Serebryany and Timur Iskhodzhanov. 2009. ThreadSanitizer: data race detection in practice. In Proceedings of the workshop on binary instrumentation and applications. ACM, 62–71. hps://github.com/stephenfreund/RoadRunner Yannis Smaragdakis, Jacob Evans, Caitlin Sadowski, Jaeheon Yi, and Cormac Flanagan. 2012. Sound Predictive Race Detection in Polynomial Time. SIGPLAN Not. 47, 1 (Jan. 2012), 387–400. Lorna A Smith, J Mark Bull, and J Obdrizalek. 2001. A parallel java grande benchmark suite. In SC'01: Proceedings of the 2001 ACM/IEEE Conference on Supercomputing. IEEE, 6–6. A Proofs A.1 Auxiliary Results Based on our construction of the happens-before relation derived from the trace, we can state that a later in the trace appearing read/write event can never happen before an earlier in the trace appearing read/write event on the same variable. Lemma A.1. Let T be a well-formed trace. Let e, f ∈ T rw x such that pos(e) > pos(f ). Then, ¬(e < H B(T) f ). The statement follows by construction. See Definition 3.3. Lemma A.2 (Criteria for Write-Read Dependency Races). Let T be a well-formed trace. Let (e, f ) ∈ RT where e is a write, e a read on some variable x and (e, f ) is a write-read data race satisfying the criteria (2a-c) in Definition 3.6. Let j = thread(e). Then, when processing event f we find that ¬(LW (x)[j] ≤ Š(i)[j]). Proof. Event e is processed before f . Consider the vector clock LW (x) of e and Š(i) of f (before synchronization with LW (x)). Suppose LW (x)[j] ≤ Š(i)[j]. This implies that there must have been some form of synchronization via e's and f 's thread. This contradicts the assumptions (2b) and (2c) from Definition 3.6. Hence, we have that ¬(LW (x)[j] ≤ Š(i)[j]). A.2 Proof of Proposition E. Proof. Suppose e is the write and f the read event where the variable involved is named x. Event e is processed before f . Suppose j = thread(e). The write history Write(x) is updated by adjusting the time stamp at position j. Based on Lemma A.2, we find that ¬Write(x) ⊑ Š(i). Hence, the SHB algorithm reports a race when processing f . A.3 Lemma A. Lemma A.3 (Concurrent Epoch-VC Criteria). Let T be a well-formed trace. Let e, f ∈ T rw x for some variable x. Let j♯k be the epoch of e and V the vector clock of f as calculated by running Algorithm 2 on T. If (1) pos(e) < pos(f ) and (2) k > V [j], then e and f are concurrent to each other. Proof. We assume the contrary. Suppose f < H B e. This immediately leads to a contradiction as we assume (1) pos(e) < pos(f ). See Lemma A.1. Suppose e < H B f . Then, e's thread must have been synced with f 's thread. Hence, the time stamp at position j for f 's thread must be greater or equal than k. This is in contradiction to the assumption (2) k > V [j]. A.4 Proof of Proposition 5. Proof. From Lemma A.3 we follow that events in RW(x) are concurrent to each other. Based on the same Lemma we can argue that the set conc(x) accumulates pairs of concurrent events. A.5 Proof of Lemma 5. Proof. By induction onT. Consider the point where e is added to RW(x). We assume that e's epoch is of the form j♯k. We show that e is still in RW(x) at the point in time we process f . Assume the contrary. So, e has been removed from RW(x). This implies that there is some д such that e < H B д and pos(f ) > pos(д) > pos(e). We show that д must be concurrent to f . Assume the contrary. Suppose д < H B f . But then e <H B f which contradicts the assumption that e and f are concurrent to each other. Suppose f < H B д. This contradicts the fact that pos(f ) > pos(д). We conclude that д must be concurrent to f . This is a contradiction to (3). Hence, e has not been removed from RW(x). By assumption e and f are concurrent to each other. Then, we can argue that k > Š(i)[j] where by assumption Š(i) is f 's vector clock and e has the epoch j♯k. Hence, (e, f ) is added to conc(x). A.6 Lemma A. Lemma A.4 (Happens-Before Epoch-VC Criteria). LetT be a well-formed trace. Let e, f ∈ T rw x for some variable x. Let j♯k be the epoch of e and V be the vector clock of f as calculated by running Algorithm 2 on T. If (1) pos(e) < pos(f ) and (2) k < V [j], then e < H B f . 13, , Martin Sulzmann and Kai Stadtmüller Proof. We assume the contrary. Suppose f < H B e. This immediately leads to a contradiction as we assume (1) pos(e) < pos(f ). See Lemma A.1. Suppose f and e are concurrent to each other. This is also impossible because due to assumption (2) k < V [j], the thread event e is in must have been synced with f 's thread. A.7 Proof of Proposition 5. Proof. Result follows from Lemma A.4. For each primitive edge e ≺ f ∈ edges(x) we that pos(e) < pos(f ) and k < V [j] where j♯k is e's epoch and V is f 's vector clock. A.8 Proof of Lemma 6. Proof. We consider the point in time event e is added to RW(x) when running Algorithm 2. By the time we reach f , event e has been removed from RW(x). Otherwise, (e, f ) ∈ conc(x) which contradicts the assumption. Hence, there must be some д1 in RW(x) where pos(e) < pos(д1) < pos(f ). As д1 has removed e, there must exist e ≺ д1 ∈ edges(x). By the time we reach f , either д1 is still in RW(x), or д has been removed by some д2 where д1 ≺ д2 ∈ edges(x) and д2 ∈ RW(x). As between e and f there can only be a finite number of events, we must reach some дn ∈ RW(x) where д1 ≺ . . . ≺ дn. Event дn must be concurrent to f . Otherwise, by soundness of edge constraints we conclude e < H B f which contradicts the assumption. Hence, дn is concurrent to f . Hence, (дn, f ) ∈ conc(x). Furthermore, we have that e ≺ д1 ≺ . . . ≺ дn ∈ edges(x). A.9 Proof of Theorem 6. Proof. We first show that the construction of P(x) terminates by showing that no pair is added twice. Consider(e, f ) ∈ conc(x) where д ≺ e. We remove (e, f ) and add (д, f ). Do we ever encounter (f , e)? This is impossible as the position of first component is always smaller than the position of the second component. Do we re-encounter (e, f )? This implies that there must exist д such that e ≺ д where (д, f ) ∈ conc(x) (as computed by Algorithm 2). By Lemma 5.3 this is in contradiction to the assumption that (e, f ) appeared in conc(x). We conclude that the construction of P(x) terminates. Pairs are kept in a total order imposed by the position of the first component. As shown above we never revisit pairs. For each e any predecessor д where д ≺ e ∈ edges(x) can be found in constant time (by using a graph-based data structure). Then, a new pair is built in constant time. There are O(n ∗ n) pairs overall to consider. We conclude that the construction of P(x)takes timeO(n∗n). By Lemma 6. we can guarantee that all pairs in C T (x) will be reached. Then, C T (x) ⊆ P(x). A.10 Proof of Proposition 6. Proof. By construction pos(i♯k) < pos(j♯l). Let α = i♯k and β = j♯l. By Lemma A.4 we have that α happens before β. So, the pair (α, β) is removed. If ¬(k < V [j]) we can argue that the time stamps cannot be equal. Hence, Lemma A.3 applies and all remaining pairs in P(x) must be concurrent to each other. Hence, P(x) = C T (x). B Fork and Join We add fork and join to our language. Definition B.1 (Fork and Join Events). e ::= . . . | f ork(i)k | join(i)k We write f ork(i)k to denote a fork event at position k where the thread the event is in forks a new thread with thread id i. We write join(i)k to denote a fork event at position k where the thread the event is in waits for all events in the thread with the tread id i to complete. Similar to Definition 3.2, we require that fork and join events are properly ordered. All events to be forked occur before the fork event and the join event occurs after all events. Definition B.2 (Proper Fork/Join Order). We say a trace T enjoys a proper fork/join order iff the following conditions are satisfied: • For each j♯f ork(i)k ∈ T we have that ¬∃e ∈ T such that thread(e) = i and pos(e) < k. • For each j♯join(i)k ∈ T we have that ¬∃e ∈ T such that thread(e) = i and pos(e) > k. We say a traceT is well-formed iff trace positions in T are accurate andT enjoys a proper acquire/release order as well as a proper fork/join order. We extend Definition 3.3 as follows. Definition B.3 (Fork/Join Happens-Before). LetT be a wellformed trace. Fork order (FO): Let j♯f ork(i)k ∈ T. Let e ∈ T where thread(f ) = i. Then, f ork(i)k < H B(T) e. Join order (JO): Let j♯join(i)k ∈ T. Let e ∈ T where thread(e) = i. Then, e < H B(T) join(i)k . Algorithm 4 Fork and Join 1: procedure join(i, j) 2: Š(i) = Š(i) ⊔ Š(j) 3: end procedure 1: procedure fork(i, j) 2: Š(j) = Š(i) 3: Š(j)[j 7→ 1] 4: inc(Š(i),i) 5: end procedure 14Predicting All Data Race Pairs for a Specific Schedule (extended version) , , The necessary adjustments to construct the happens-before relation based on vector clocks are shown in Algorithm 4. In case of a join, we synchronize the current thread's vector clock with the vector clock of the to be joined events. In case of a fork, we initialize the time stamp of the to be forked thread. All results stated carry over as the treatment of fork/join is very similar to the treatment of acquire/release. C Incomplete Edge Constraints and Elimination Step Edge constraints are sound but not complete w.r.t. the happensbefore relation. Consider two read/write events e and f on the same shared variable. If event f happens-before event e, there might not be an edge relation f ≺ ∗ e. Consider the example in Figure 3. The eventw(x)1 belonging to 1♯1 happens before the event w(x)9 belonging to 3♯ but there is no corresponding edge constraint. Another observation is that the candidate pairs obtained via the post-processing step described by Definition 6.3 may not necessarily represent concurrent pairs. For example, we find that 1♯1 ≺ ∗ 2♯2 and 1♯1 ≺ ∗ 3♯2. However, the pair (1♯1, 3♯2) obtained via post-processing does not form a conflicting (concurrent) pair of events. The eventw(x)1 belonging to 1♯1 happens before the eventw(x) belonging to 3♯2. To eliminate pairs such as (1♯1, 3♯2), we use the following reasoning as described by Proposition 6.5 . Fromw(x)9's vector clock [2, 1, 2] we extract the time stamp of thread 1. We find that this time stamp is greater than the time stamp of epoch 1♯1. Hence, we conclude that w(x)1 happens before w(x)9. So, there is no race. D Tracing For benchmarking we use tests from the Java Grande Forum ([Smith et al. 2001]) and the DaCapo (version 9.12, [Blackburn et al. 2006]) benchmark suite. Many tests produce more than million events in the given test case. For data race prediction, only events on variables that are shared between threads are interesting. For example, for the tomcat benchmark we encounter million events from which only 11 million involve shared variables. Another example is the xalan benchmark with over 62 million events and only 7 million on shared variables. To reduce the size of the trace and make benchmarking feasible, we ignore events on unshared variables. Without this filter, the memory consumption which would be far above 64 GB. To detect unshared variables during the recording of the program trace, we perform the following tracing method. The last thread and its access event are stored for each variable. If the same thread accesses the variable again, the tracer only stores the current event. As soon as a second thread accesses the variable (last thread , current thread), the stored last event and the current event are written to the trace. After encountering the first access by another thread all accesses to the variable are written to the trace, independent of the accessing thread. This filtering method can introduce false positives due to wrongly ordered write-read dependencies and missed data races because of the ignored events. The modified RoadRunner implementation can be found at hps://github.com/KaiSta/roadrunne Similar filters are used in [Flanagan and Freund 2010a], [Roemer et al. 2018] and [Mathur et al. 2018], where consecutive events by the same thread on a variable are ignored. Like in our case, false positives due to 'incomplete' traces may arise. E SHB Adaptation to predict WRD races We observe that write-read races due to write-read dependencies can be directly obtained via an adaptation of the SHB algorithm. Algorithm 5 Predicting WRD Races 1: procedure write(i, x, k) 2: raceCheck(Write(x), Š(i)) 3: raceCheck(Read(x), Š(i)) 4: LW (x) = Š(i) 5: L id W (x) = i 6: Write(x)[i 7→ Š(i)[i]] 7: inc(Š(i),i) 8: end procedure 1: procedure read(i, x, k) 2: raceCheck(Write(x), Š(i)) 3: raceWRDCheck(LW (x)[L id W (x)], Š(i)[L id W (x)]) 4: Š(i) = Š(i) ⊔ LW (x) 5: Read(x)[i 7→ Š(i)[i]] 6: inc(Š(i),i) 7: end procedure To distinguish between the different kinds of write-read races, we adapt the SHB algorithm as follows. We additionally keep track of the thread id of the last write via L id W (x). We write raceWRDCheck(i, j) as a short-hand for \"if ¬(i ≤ j) then write-read dependency race detected\". The updates only affect the processing of read and write events. See Algorithm 5. Thus, we can detect all write-read races due to write-read dependencies. Proposition E.1 (SHB Completeness forWrite-Read Dependency Races). Let T be a well-formed trace. Let (e, f ) ∈ RT where (e, f ) is a write-read data race satisfying the criteria (2) in Definition 3.6. Then, the SHB algorithm reports that the read event of the pair (e, f ) is in a (write) race. 15, , Martin Sulzmann and Kai Stadtmüller 1♯ [1, 0, 0] 2♯ [0, 1, 0] 3♯ [0, 0, 1] Rel(x) RW(x) conc(x) edges(x) 1. w(x) [1, 0, 0] {1♯1} 2. acq(y) [2, 0, 0] 3. rel(y) [2, 0, 0] [2, 0, 0] 4. acq(y) [2, 1, 0] 5. rel(y) [2, 1, 0] [2, 1, 0] 6. w(x) [2, 2, 0] {2♯2} {1♯1 ≺ 2♯2} 7. acq(y) [2, 1, 1] 8. rel(y) [2, 1, 1] [2, 1, 1] 9. w(x) [2, 1, 2] {2♯2, 3♯2} {(2♯2, 3♯2)} Figure 3. Edge Constraints are Incomplete F SHB∀- SHB Adaptation to predict all race pairs Adaptation of SHB algorithm to predict all data races pairs (for a trace-specific schedule). Some post-processing is necessary where we assume that for each processed event we have its vector clock. Algorithm 6 SHB algorithm adapted 1: procedure acqire(i, x) 2: Š(i) = Š(i) ⊔ Rel(x) 3: end procedure 1: procedure write(i, x, k) 2: evt = {(k, Š(i))} ∪ evt 3: raceCheck(Write(x), Š(i)) 4: raceCheck(Read(x), Š(i)) 5: LW (x) = Š(i) 6: Write(x)[i 7→ Š(i)[i]] 7: inc(Š(i),i) 8: end procedure 1: procedure release(i, x) 2: Rel(x) = Š(i) 3: inc(Š(i),i) 4: end procedure 1: procedure read(i, x, k) 2: raceCheck(Write(x), Š(i)) 3: Š(i) = Š(i) ⊔ LW (x) 4: evt = {(k, Š(i))} ∪ evt 5: Read(x)[i 7→ Š(i)[i]] 6: inc(Š(i),i) 7: end procedure The Algorithm 6 additionally records for each event its vector clock. For this purpose, we use the set evt. This component does not appear in the original formulation of SHB. However, this extra component is necessary to predict the set R T of all data race pairs under the schedulable happenbefore relation as defined by Definition 3.6. The set evt is initially empty. We use the trace position to uniquely identify each event and thus record its associated vector clock as pairs in evt. The set evt is updated for each write and read event. All other parts remain the same as in Algorithm 1. To predict all remaining races, we require some post-processing. For each potential conflicting pair of events, read-write and write-write, we need to check if the two events are concurrent to each other. The set evt records for each event its vector clock. So, we need to consider all possible combinations of potentially conflicting pairs and compare their vector clocks. The following result follows from Theorem 4.2 stated in[Mathur et al. 2018]. Theorem F.1 (Soundness of SHB Algorithm[Mathur et al. 2018]). Let T be a well-formed trace. For each e ∈ T where the SHB algorithm reports a race, there exists f ∈ T such that (e, f ) ∈ RT. Instead of building all pairs of combinations of events, we can use the (read/write) events reported by the SHB algorithm as a starting point. Definition F.2 (SHB Post-Processing). LetT be a well-formed trace. Let evt be the set obtained by processing T via the SHB algorithm. Let R be the set of events that are in a race as reported by raceCheck(, ). We define R(T) =    (e, f ) | f ∈ R ∧ e ∈ T∧ one write among e, f ∧ pos(e) < pos(f )∧ (pos(e),V1), (pos(f ),V2) ∈ evt∧ ¬V1 ⊑ V    For each event in a race as reported by SHB, we search for a potential race partner that appears before this event in the trace. We collect all such pairs in the set R(T). Thus, we obtain all (concurrent) data race pairs. This is guaranteed by Theorem 4.2. from [Mathur et al. 2018]: For each (concurrent) conflicting pair (e, f ) ∈ RT where pos(e) < pos(f ) we have that the SHB algorithm reports that f is in a race. Hence, we can derive the following result. 16Predicting All Data Race Pairs for a Specific Schedule (extended version) , , Corollary F.3 (SHB Post-Processing Concurrent Races). Let T be a well-formed trace. Let evt be the set obtained by processingT via the SHB algorithm. Let R be the set of events that are in a race as reported by raceCheck(, ). Let (e, f ) ∈ RTsuch that e, f are concurrent and pos(e) < pos(f ). Then, f ∈ R and there exists e ∈ T such that (e, f ) ∈ R(T). By construction R(T) ⊆ RT. Example F.4. Recall the trace from Example 4.1. The set of events in a race reported by raceCheck(, ) are {w(x)3,r(x)4,r(x)5}. Based on the above post-processing characterized by Corollary F.3, we find the following race pairs {(w(x)1,w(x)3), (r(x)2,w(x)3), (w(x)1,r(x)4), (w(x)1,r(x)5), (w(x)3,r(x)5)} Time complexity of the SHB post-processing phase to predict all (concurrent) data races is O(n ∗n ∗k). The algorithm reports O(n) conflicting events. Based on Corollary F.3 we can use these conflicting events as a starting point and scan through through the trace for race partners. This requires time O(n ∗ n). For each pair the comparison among their vector clocks takes time O(k). We assume that lookup of the vector clock for each event in evt takes constant time. Hence, O(n ∗ n ∗ k). 17\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper ID: 2404.13510v1\n",
      "\n",
      "Abstract: It is known that the set of all nonnegative integers may be equipped with a\n",
      "total order that is chaotic in the sense that there is no monotone three-term\n",
      "arithmetic progressions. Such chaotic order must be so complicated that the\n",
      "resulting ordered set cannot be order isomorphic to the set of all nonnegative\n",
      "integers or the set of all integers with the standard order. In this paper, we\n",
      "completely characterize order structures of chaotic orders on the set of all\n",
      "nonnegative integers, as well as on the set of all integers and on the set of\n",
      "all rational numbers.\n",
      "\n",
      "Clean Text: \n",
      "1. Introduction It has long been known ([3, 4, 5, 6]) that it is possible to arrange the integers 1, . . . , n (and consequently any finitely many rational numbers) into a sequence a1, . . . , an without a three-term subsequence forming an arithmetic progression, or more precisely without i, j, k with 1 ≤ i < j < k ≤ n and aj − ai = ak − aj . In contrast, Davis, Entringer, Graham, and Simmons [2] proved that it is impossible to arrange all of the positive integers (or equivalently all of the nonnegative integers) into a sequence a1, a2, . . . or a two-sided sequence . . . , a−1, a0, a1, . . . without a three-term subsequence forming an arithmetic progression. On the other hand, Ardal, Brown, and Jungi´c [1] proved that there exists a total order on Q such that there are no a, b, c ∈ Q with a ≺ b ≺ c and b − a = c − b, which implies that such total order exists on N (by which we mean the set of all nonnegative integers) and on Z; it should be noted that although they invoked K˝onig's infinity lemma to obtain the total order on Q (and hence the resulting total order is rather ), they also gave an explicit total order on Z (and hence on N). To summarize these results, we find it convenient to introduce the following terminology. For a set S of rational numbers and a totally ordered set (X, ), we say that a bijection f : S → X is chaotic if there are no a, b, c ∈ S with f(a) ≺ f(b) ≺ f(c) and b − a = c − b. Then the results of Davis, Entringer, Graham, and Simmons say that if S = N and X = N, Z with the standard order, then no bijection f : S → X is chaotic; the results of Ardal, Brown, and Jungi´c say that if S = N, Z, Q, then there exist a countably infinite totally ordered set (X, ) and a chaotic bijection f : S → X. This observation leads us to the following natural question: given S = N, Z, Q, which countably infinite totally ordered sets (X, ) admit a chaotic bijection f : S → X? Our main theorem completely answers this question. To state our main theorem, recall that a point p in a totally ordered set (X, ) is said to be isolated if 2020 Mathematics Subject Classification. Primary 06A05; Secondary 11B25. Key words and phrases. Arithmetic progression; Order structure. 12 MINORU HIROSE AND SHINGO SAITO it is isolated in the topological space X endowed with the order topology, namely (assuming that X has at least two elements) if either (i) {x ∈ X | x ≺ x0} = {p} for some x0 ∈ X, (ii) {x ∈ X | x ≻ x0} = {p} for some x0 ∈ X, or (iii) {x ∈ X | x0 ≺ x ≺ x1} = {p} for some x0, x1 ∈ X. Theorem 1.1 (Main Theorem). Let (X, ) be a countably infinite totally ordered set. (1) There exists a chaotic bijection f : N → X if and only if X has no isolated points. (2) There exists a chaotic bijection f : Z → X if and only if X has no isolated points. (3) There exists a chaotic bijection f : Q → X if and only if X has no isolated points and either X does not have a maximum or X does not have a minimum. 2. Proof of the 'only if' parts of our main theorem This section proves the 'only if' parts of our main theorem. Let S ⊂ Q, and let (X, ) be a countably infinite totally ordered set. The key to the proof is the observation that for S ∈ {N, Z, Q}, every chaotic map f : S → X has a stronger property concerning the 2-adic order. 2.1. Chaotic maps and binary maps. We begin by generalizing the definition of chaotic maps: we say that f : S → X is chaotic if f is injective and there are no a, b, c ∈ S such that f(a) ≺ f(b) ≺ f(c) and b − a = c − b. We then define a property that is stronger than being chaotic. Recall that the 2-adic order ord2 r of r ∈ Q× = Q \\ {0} is defined as the unique n ∈ Z such that −nr can be written as a quotient of odd integers; ord2 0 is defined as ∞. We say that f : S → X is binary if f is injective and there are no a, b, c ∈ S such that f(a) ≺ f(b) ≺ f(c) and ord2(b − a) = ord2(c − b). It is obvious that every binary map f : S → X is chaotic. Example 2.1. If f : {0, 1, 2, 3, 4, 5, 6, 7} → X satisfies f(0) ≺ f(4) ≺ f(2) ≺ f(6) ≺ f(1) ≺ f(5) ≺ f(3) ≺ f(7), then f is binary. If f : {0, 1, 2, 3} → X satisfies f(2) ≺ f(3) ≺ f(0) ≺ f(1), then f is chaotic but not binary. Proposition 2.2. If S ∈ {N, Z, Q} and there exists a binary bijection f : S → X, then X has no isolated points. Proof. Assume that {x ∈ X | f(a) ≺ x ≺ f(b)} = {f(c)} for some a, b, c ∈ S. Take c ′ ∈ S \\ {c} with ord2(c′ − c) > ord2(a − c) and ord2(c′ − c) > ord2(b − c) (we can for example take c ′ = c + 2n for a sufficiently large n ∈ N). Since f(c) is the only element of X between f(a) and f(b), it must be the case that either f(c ′ ) ≺ f(a) ≺ f(c) or f(c) ≺ f(b) ≺ f(c ′ ). Since ord2(a − c ′ ) = ord2(c − a) and ord2(b − c) = ord2(c ′ − b), the map f cannot be binary, which is a contradiction. In a similar manner, both assuming that {x ∈ X | x ≻ f(a)} = {f(c)} for some a, c ∈ S and assuming that {x ∈ X | x ≺ f(a)} = {f(c)} for some a, c ∈ S lead to a contradiction. CHARACTERIZATION OF ORDER STRUCTURES AVOIDING 3-APS Remark 2.3. Proposition 2.2 remains valid for any set S ⊂ Q with the property that for every a ∈ S, the set {ord2(b − a) | b ∈ S \\ {a}} is unbounded from above. 2.2. Chaotic maps are binary if S ∈ {N, Z, Q}. In this subsection, we prove that if S ∈ {N, Z, Q}, then every chaotic map f : S → X is in fact binary (Proposition 2.6). Note that this is not the case for general S, as the second example in Example 2.1 shows. We write N+ for the set of all positive integers. Lemma 2.4. Let f : S → X be chaotic and t ∈ N+ be odd. Suppose that a ∈ Q and d ∈ Q× are such that a + id ∈ S for all i ∈ N. Then f(a) ≺ f(a + d) if and only if f(a) ≺ f(a + td). Proof. The proof proceeds by induction on t. The lemma is trivial for t = 1. Suppose that the lemma is true for an odd positive integer t. In order to prove that the lemma is true for t+ 2, we only have to prove that f(a) ≺ f(a+d) implies f(a) ≺ f(a + (t + 2)d). Set b = a + 2(t + 2)d ∈ S. Since f is chaotic and f(a) ≺ f(a + d), we have f(a) ≺ f(a + d) ≻ f(a + 2d) ≺ · · · ≻ f(b) ≺ f(b + d). It follows from the inductive hypothesis applied to b and d that f(b) ≺ f(b + td) (note that b + id = a + (2t + 4 + i)d ∈ S for all i ∈ N). If f(b + td) ≺ f(b + (t + 2)d), then we have f(b) ≺ f(b + td) ≺ f(b + (t + 2)d), and so f(b + (t + 2)d) ≻ f(b) ≺ f(b − (t + 2)d) = f(a + (t + 2)d) ≻ f(a), as required. If f(b + td) ≻ f(b + (t + 2)d), then we have f(b + (t + 2)d) ≺ f(b + td) ≻ f(b + (t − 2)d) ≺ . . . ≺ f(b − (t + 2)d) = f(a + (t + 2)d) ≻ f(a + td). Since f(a) ≺ f(a + td), we may conclude that f(a) ≺ f(a + (t + 2)d). Lemma 2.5. Let f : S → X be chaotic, s ∈ N be even, and t ∈ N+ be odd. Suppose that a ∈ Q and d ∈ Q× are such that a+id ∈ S for all i ∈ N. Then f(a) ≺ f(a+d) if and only if f(a + sd) ≺ f(a + td). Proof. It suffices to prove that f(a) ≺ f(a+d) implies f(a+sd) ≺ f(a+td). Since f is chaotic, we have f(a) ≺ f(a + d) ≻ f(a + 2d) ≺ f(a + 3d) ≻ · · · . If s < t, then Lemma 2.4 and the fact that f(a + sd) ≺ f((a + sd) + d) imply that f(a + sd) ≺ f((a + sd) + (t − s)d) = f(a + td). If t < s, then Lemma 2.4 and the fact that f(a + td) ≻ f((a + td) + d) imply that f(a + td) ≻ f((a + td) + (s − t)d) = f(a + sd). Proposition 2.6. If S ∈ {N, Z, Q} and f : S → X is chaotic, then f is binary. Proof. Suppose that f is not binary. Then there exist a, b, c ∈ S such that f(a) ≺ f(b) ≺ f(c) and ord2(b − a) = ord2(c − b) = n, say. Take the smallest m ∈ N+ such that 2−nm(b − a) and 2−nm(c − b) are both (necessarily odd) integers. Put d = 2n/m.4 MINORU HIROSE AND SHINGO SAITO If b = min{a, b, c}, then applying Lemma 2.5 to b and d shows that f(b) ≻ f(a) = f(b + 2−nm(a − b)d) implies f(b) ≻ f(b + d), whereas f(b) ≺ f(c) = f(b + 2−nm(c − b)d) implies f(b) ≺ f(b + d); this is a contradiction. If a = min{a, b, c}, then applying Lemma 2.5 to a and d shows that f(a) ≺ f(b) = f(a+ 2−nm(b−a)d) implies f(a) ≺ f(a+d), whereas f(b) = f(a+ 2−nm(b−a)d) ≺ f(c) = f(a + 2−nm(c − a)d) implies f(a + d) ≺ f(a); this is a contradiction. If c = min{a, b, c}, then a similar argument leads us to a contradiction. Propositions 2.2 and 2.6 show that if S ∈ {N, Z, Q} and there exists a chaotic bijection f : S → X, then X has no isolated points. We may now complete the proof of the 'only if' parts of our main theorem by noticing the following simple proposition: Proposition 2.7. If f : Q → X is a chaotic bijection, then either X does not have a maximum or X does not have a minimum. Proof. If X has both a maximum and a minimum, say f(a) and f(b), then setting c = (a + b)/2, we have f(b) ≺ f(c) ≺ f(a) and c − b = a − c, a contradiction. 3. Proof of the 'if' parts of our main theorem This section proves the 'if' parts of our main theorem. For S ⊂ Q and r ∈ Q, we write S + r = {a + r | a ∈ S}. 3.1. Construction of binary maps from N and Z. Lemma 3.1. Let S ⊂ Q and r ∈ Q×. (1) If ord2(a − b) 6= ord2 r for all a, b ∈ S, then S ∩ (S + r) = ∅. (2) Suppose that ord2(a−b) < ord2 r for all distinct a, b ∈ S. Then for distinct a, b ∈ S ∪ (S + r), we have ord2(a − b) ≤ ord2 r with equality if and only if a − b = ±r. (3) Suppose that ord2(a − b) > ord2 r for all a, b ∈ S. Then for distinct a, b ∈ S ∪ (S + r), we have ord2(a − b) ≥ ord2 r with equality if and only if either a ∈ S and b ∈ S + r or a ∈ S + r and b ∈ S. Proof. (1) Obvious. (2) Let a, b ∈ S ∪ (S + r) be distinct. If either a, b ∈ S or a, b ∈ S + r, then we obviously have ord2(a − b) < ord2 r. Therefore by symmetry we may assume that a ∈ S and b ∈ S + r. If a = b − r, then we clearly have ord2(a − b) = ord2 r; otherwise a and b − r are distinct elements of S and so ord2(a − (b − r)) < ord2 r, which implies that ord2(a − b) < ord2 r. (3) Let a, b ∈ S ∪ (S + r) be distinct. If either a, b ∈ S or a, b ∈ S + r, then we obviously have ord2(a − b) > ord2 r. Therefore by symmetry we may assume that a ∈ S and b ∈ S + r. Then we have ord2(a − (b − r)) > ord2 r, which implies that ord2(a − b) = ord2 r. In writing the proofs that follow, it is convenient to make the set-theoretical identification of a map ϕ: A → B with the its graph {(a, b) ∈ A × B | ϕ(a) = b}. Thus for maps ϕ1 : A1 → B1 and ϕ2 : A2 → B2, the inclusion ϕ1 ⊂ ϕ2 means that A1 is a subset of A2 and that the restriction of ϕ2 to A1 is ϕ1; the union ϕ1 ∪ ϕ represents a map from A1 ∪ A2 to B1 ∪ B2, provided that ϕ1(a) = ϕ2(a) for all a ∈ A1 ∩ A2.CHARACTERIZATION OF ORDER STRUCTURES AVOIDING 3-APS Lemma 3.2. Let (X, ) be a totally ordered set without isolated points. Let S ⊂ Q be finite and r ∈ Q× be such that ord2(a − b) < ord2 r for all distinct a, b ∈ S. If f : S → X is binary, S˜ = S ∪ (S + r), and x ∈ X \\ Im f, then there exists a binary map ˜f : S˜ → X with f ⊂ ˜f and x ∈ Im ˜f. Proof. Take the enumeration a1, . . . , am of S so that f(a1) ≺ · · · ≺ f(am). We define an injection ˜f : S˜ → X with f ⊂ ˜f and x ∈ Im ˜f by inductively defining ˜f(ai +r) as an element of X such that f(ai−1) ≺ ˜f(ai +r), ˜f(ai−1 +r) ≺ ˜f(ai +r), ˜f(ai + r) ≺ f(ai+1), and ˜f(ai + r) 6= f(ai) for i = 1, . . . , m (ignore any condition in which 0 or m + 1 appears as a subscript), using the assumption that X has no isolated points and choosing x as ˜f(ai + r) at the earliest opportunity. It remains to prove that ˜f is binary. For ease of notation, we define an equivalence relation ∼ on S˜ by setting a ∼ b if and only if a−b ∈ {0, ±r}; Lemma 3.1 (2) implies that this is indeed an equivalence relation because ord2(±2r) = ord2 r + 1 > ord2 r. Note that for a, a′, b, b′ ∈ S˜ with a ∼ a ′ 6∼ b ∼ b′ , we have ˜f(a) ≺ ˜f(b) if and only if ˜f(a ′ ) ≺ ˜f(b ′ ). Suppose that ˜f is not binary. Then we may find a, b, c ∈ S˜ such that ˜f(a) ≺ ˜f(b) ≺ ˜f(c) and ord2(b − a) = ord2(c − b) = n, say. Lemma 3.1 (2) shows that n ≤ ord2 r and moreover that n < ord2 r because a ∼ b ∼ c would contradict the fact that a, b, c are distinct elements of S˜. Therefore if we choose a ′ , b′, c′ ∈ S so that a ∼ a ′ , b ∼ b ′ , c ∼ c ′ , then a ∼ a ′ 6∼ b ∼ b′ 6∼ c ∼ c′ and so ˜f(a ′ ) ≺ ˜f(b ′ ) ≺ ˜f(c ′ ) and ord2(b ′ − a′ ) = ord2(b − a) = ord2(c − b) = ord2(c ′ − b′ ); but this is a contradiction because the restriction of ˜f to S is equal to the binary map f. Hence we have proved that ˜f is binary. Proposition 3.3. If S ∈ {N, Z}, and (X, ) is a countably infinite totally ordered set without isolated points, then there exists a binary bijection f : S → X. Proof. Define a sequence r0, r1, · · · ∈ S by rn = ( n if S = N; (−2)n if S = Z, and set Sn = { P i∈A ri| A ⊂ {0, . . . , n − 1}} for n ∈ N. Note that for n ∈ N, since Sn =    [0, n − 1] ∩ N if S = N; [−2(2n − 1)/3,(2n − 1)/3] ∩ Z if S = Z and n is even; [−2(2n−1 − 1)/3,(2n+1 − 1)/3] ∩ Z if S = Z and n is odd, we have ord2(a − b) < n = ord2 rn for all distinct a, b ∈ Sn. Fixing a bijection g : N → X, we shall inductively construct binary maps fn : Sn → X for n ∈ N so that f0 ⊂ f1 ⊂ · · · . Define a binary map f0 from S0 = {0} to X by setting f0(0) = g(0). Let n ∈ N, and suppose that fn : Sn → X has been constructed. Take the smallest k ∈ N with g(k) ∈/ Im fn, and use Lemma 3.2 to construct a binary map fn+1 : Sn+1 → X with fn ⊂ fn+1 and g(k) ∈ Im fn+1. Define f = S∞ n=0 fn. Then f is a binary map from S∞n=0 Sn = S to X. Since the construction ensures that g(0), . . . , g(k) ∈ Im fk for all k ∈ N, it follows that f is surjective. 6 MINORU HIROSE AND SHINGO SAITO 3.2. Construction of binary maps from Q. We write Z(2) = {r ∈ Q | ord2 r ≥ 0}. Lemma 3.4. Let n ∈ N and q0, . . . , qn−1 ∈ Z(2) with ord2 qi = i for all i = 0, . . . , n−1. Then for every q ∈ Z(2) there exists a unique subset A of {0, . . . , n−1} such that ord2(q − P i∈A qi) ≥ n. Proof. We proceed by induction on n. The lemma is trivial for n = 0 because the only choice for A is ∅. Suppose that the lemma is true for a nonnegative integer n and that q0, . . . , qn ∈ Z(2) satisfy ord2 qi = i for all i = 0, . . . , n. Let q ∈ Z(2) be given. The inductive hypothesis shows that there exists a unique subset A′ of {0, . . . , n − 1} such that ord2(q − P i∈A′ qi) ≥ n. P We first show the existence of the required subset A of {0, . . . , n}. If ord2(q − i∈A′ qi) ≥ n + 1, then take A = A′ ; if ord2(q − P i∈A′ qi) = n, then setting A = A′ ∪ {n} gives ord2(q − P i∈A qi) ≥ n + 1 because ord2(α + β) ≥ n + 1 for all α, β ∈ Q with ord2 α = ord2 β = n. What remains to prove is the uniqueness of such A. Suppose that A ⊂ {0, . . . , n} satisfies ord2(q − P i∈A qi) ≥ n+ 1. Since q − P i∈A\\{n} qi equals either q − P i∈A qi or q − P i∈A qi + qn, we must have ord2(q − P i∈A\\{n} qi) ≥ n because ord2 qn = n. Therefore it follows from the inductive hypothesis that A \\ {n} = A′, which means that A is either A′ or A′ ∪ {n}. If ord2(q − P P i∈A′ qi) ≥ n + 1 and ord2(q − i∈A′∪{n} qi) ≥ n + 1 were both true, then we would also have ord2 qn ≥ n + 1, contradicting the assumption that ord2 qn = n. This completes the proof of the uniqueness of A. Lemma 3.5. There exists a sequence q0, q1, . . . ∈ Z(2) with the following properties: (1) ord2 qn = n for all n ∈ N; (2) for every q ∈ Z(2) there exists a finite subset A of N such that q = P n∈A qn. Proof. Fix a bijection h: N → Z(2). For each n ∈ N, when q0, . . . , qn−1 ∈ Z(2) have been constructed, take the smallest ln ∈ N such that ord2(h(ln) − P i∈A qi) = n for some A ⊂ {0, . . . , n − 1} (such ln always exists because the condition follows for example from ord2 h(ln) = n; Lemma 3.4 implies that A is unique), and set qn = h(ln) − P i∈A qi. Suppose that (2) is false, and take the smallest l ∈ N for which there is no finite subset A of N such that h(l) = P i∈A qi. Choose N ∈ N so large that for every k = 0, . . . , l − 1 there exists Ak ⊂ {0, . . . , N − 1} such that h(k) = P i∈Ak qi. By Lemma 3.4, there exists Al ⊂ {0, . . . , N − 1} such that ord2(h(l) − P i∈Al qi) ≥ N. Set N′ = ord2(h(l) − P i∈Al qi). Since ord2(h(k) − P i∈Ak qi) = ∞ > N′for k = 0, . . . , l − 1, we must have lN′ ≥ l. Since l has the property required for lN′ , this means that lN′ = l, contradicting the choice of l. Lemma 3.6. There exists a sequence r0, r1, . . . ∈ Q× such that if we set Sn = { P i∈A ri| A ⊂ {0, . . . , n − 1}} for n ∈ N, we have the following: (1) S∞ n=0 Sn = Q; (2) ord2(a − b) < ord2 rn whenever n ∈ N is even and a, b ∈ Sn are distinct; (3) ord2(a − b) > ord2 rn whenever n ∈ N is odd and a, b ∈ Sn.CHARACTERIZATION OF ORDER STRUCTURES AVOIDING 3-APS Proof. Take a sequence q0, q1, . . . ∈ Z(2) as in Lemma 3.5, and define r0, r1, . . . ∈ Q× by rn = ( qn/2 if n is even; −(n+1)/ if n is odd. To show (1), we observe that every r ∈ Q can be written (in fact uniquely) as q + P j∈B −j with q ∈ Z(2) and a finite set B ⊂ N+. To show (2), suppose that n = 2m for some m ∈ N+ and that a, b ∈ S2m are distinct (we may assume that n ≥ 2 because S0 consists of only one element). Since a − b is a nonzero rational number that can be written as a linear combination of q0, . . . , qm−1 and 2−1, . . . , −m with coefficients in {0, ±1}, we have ord2(a − b) ≤ max{ord2 q0, . . . , ord2 qm−1, ord2 − , . . . , ord2 −m} = m − 1 < m = ord2 rn. To show (3), suppose that n = 2m + 1 for some m ∈ N and that a, b ∈ S2m+1. Since a − b can be written as a linear combination of q0, . . . , qm and 2−1, . . . , −m with coefficients in {0, ±1}, we have ord2(a − b) ≥ min{ord2 q0, . . . , ord2 qm, ord2 − , . . . , ord2 −m} = −m > −m − 1 = ord2 rn. Lemma 3.7. Let (X, ) be a totally ordered set without a maximum. Let S ⊂ Q be finite and r ∈ Q× be such that ord2(a − b) > ord2 r for all a, b ∈ S. If f : S → X is binary and S˜ = S ∪ (S + r), then there exists a binary map ˜f : S˜ → X with f ⊂ ˜f. Proof. Take the enumeration a1, . . . , am of S so that f(a1) ≺ · · · ≺ f(am). We define an injection ˜f : S˜ → X with f ⊂ ˜f by inductively defining ˜f(ai + r) as an element of X larger than f(a1), . . . , f(am), ˜f(a1 + r), . . . ,˜f(ai−1 + r), using the assumption that X has no maximum. To prove that ˜f is binary, take any a, b, c ∈ S˜ with ˜f(a) ≺ ˜f(b) ≺ ˜f(c). We have either (i) a, b, c ∈ S, (ii) a, b ∈ S and c ∈ S + r, (iii) a ∈ S and b, c ∈ S + r, or (iv) a, b, c ∈ S + r. In cases (i) and (iv), we have ord2(b − a) 6= ord2(c − b) because f is binary. Lemma 3.1 implies that ord2(b − a) > ord2 r = ord2(c − b) in case (ii) and that ord2(b − a) = ord2 r < ord2(c − b) in case (iii). Proposition 3.8. Let (X, ) be a countably infinite totally ordered set. Suppose that X has no isolated points and that either X does not have a maximum or X does not have a minimum. Then there exists a binary bijection f : Q → X. Proof. By symmetry, we may assume that X does not have a maximum. Take a sequence r0, r1, . . . ∈ Q× as in Lemma 3.6, and set Sn = { P i∈A ri| A ⊂ {0, . . . , n− 1}} for n ∈ N. Fixing a bijection g : N → X, we shall inductively construct binary maps fn : Sn → X for n ∈ N so that f0 ⊂ f1 ⊂ · · · . Define a binary map f0 from S0 = {0} to X by setting f0(0) = g(0). Let n ∈ N, and suppose that fn : Sn → X has been constructed. If n is even, then take the smallest k ∈ N with g(k) ∈/ Im fn, and use Lemma 3.2 to construct a binary map fn+1 : Sn+1 → X with fn ⊂ fn+1 and g(k) ∈ Im fn+1. If n is odd, then use Lemma 3.7 to construct a binary map fn+1 : Sn+1 → X with fn ⊂ fn+1. Define f = S∞ n=0 fn. Then f is a binary map from S∞n=0 Sn = Q to X. Since the construction ensures that g(0), . . . , g(k) ∈ Im f2k+1 for all k ∈ N, it follows that f is surjective. 8 MINORU HIROSE AND SHINGO SAITO Propositions 3.3 and 3.8 complete the proof of the 'if' parts of our main theorem. Acknowledgements This work was supported by JSPS KAKENHI Grant Numbers JP18K03243, JP18K13392, JP22K03244, and JP23K03072. The authors would like to thank Hideki Murahara for valuable discussions. References [1] H. Ardal, T. Brown, and V. Jungi´c, Chaotic orderings of the rationals and reals, Amer. Math. Monthly 118 (2011), no. 10, 921–925. [2] J. A. Davis, R. C. Entringer, R. L. Graham, and G. J. Simmons, On permutations containing no long arithmetic progressions, Acta Arith. 34 (1977/78), no. 1, 81–90. [3] R. C. Entringer and D. E. Jackson, Problems and Solutions: Elementary Problems: E2440, Amer. Math. Monthly 80 (1973), no. 9, 1058. [4] R. C. Lyndon, Problems and Solutions: Solutions of Elementary Problems: E2440, Amer. Math. Monthly 82 (1975), no. 1, 74–75. [5] T. Odda, Problems and Solutions: Solutions of Elementary Problems: E2440, Amer. Math. Monthly 82 (1975), no. 1, 74. [6] H. E. Thomas, Jr., Problems and Solutions: Solutions of Elementary Problems: E2440, Amer. Math. Monthly 82 (1975), no. 1, 75–76. Institute for Advanced Research, Nagoya University, Furo-cho, Chikusa-ku, Nagoya, 464-8602, Japan Email address: minoru.hirose@math.nagoya-u.ac.jp Faculty of Arts and Science, Kyushu University, 744, Motooka, Nishi-ku, Fukuoka, 819-0395, Japan Email address: ssaito@artsci.kyushu-u.ac.jp\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper ID: 0610513v1\n",
      "\n",
      "Abstract: The orbit projection $\\pi : M \\to M/G$ of a proper $G$-manifold $M$ is a\n",
      "fibration if and only if all points in $M$ are regular. Under additional\n",
      "assumptions we show that $\\pi$ is a quasifibration if and only if all points\n",
      "are regular. We get a full answer in the equivariant category: $\\pi$ is a\n",
      "$G$-quasifibration if and only if all points are regular.\n",
      "\n",
      "Clean Text: \n",
      "1. Introduction A continuous map is called Hurewicz (Serre) fibration if it has the homotopy lifting property for all topological spaces (CW complexes). We show in section that the orbit projection π : M → M/G of a proper smooth G-manifold M is a Hurewicz (Serre) fibration if and only if all points in M are regular. The proof basically uses the existence of slices at any point and the fact that the projection G → G/H, for isotropy subgroups H, is a fibration. Hence, the result generalizes to proper locally smooth G-spaces M. Moreover, it has its analogon in the category of G-spaces and G-equivariant maps. In section 3 we investigate when the orbit projection π is a quasifibration, i.e., the canonical inclusion of each fiber in the corresponding homotopy fiber is a weak homotopy equivalence. We show that under certain conditions π is a quasifibration if and only if all points of M are regular. In the equivariant category we get a full answer: The orbit projection π is a G-quasifibration if and only if all points of M are regular. Its proof uses some deep theorems from equivariant homotopy theory. 2. Orbit projections as fibrations 2.1. Fibrations. ([3]) Let E and B be topological spaces. A continuous map p : E → B is called a Hurewicz fibration if it has the homotopy lifting property: For each topological space X, each continuous f : X × {0} → E and each homotopy φ : X ×I → B of p ◦ f, there exists a homotopy φ¯ of f covering φ. If p : E → B has the homotopy lifting property for all CW complexes X, it is called a Serre fibration. The fibration is regular if φ¯ can always be selected to be stationary with φ, i.e., for each x ∈ X such that φ(x, t) is constant as a function of t, the function φ¯(x, t) is constant as well. X × {0} f /E p X × I φ / φ¯ n n n n n n n B A locally trivial fiber bundle is a regular Serre fibration; if the base is paracompact then it is a regular Hurewicz fibration. Date: August 27, 2018. 2000 Mathematics Subject Classification. 55R05, 55R65, 57S15. Key words and phrases. orbit projection, proper G-manifold, fibration, quasifibration. The author was supported by 'Fonds zur F¨orderung der wissenschaftlichen Forschung, Projekt P 17108 N04'. 12 ARMIN RAINER For a Serre fibration p : E → B with fiber F = p − (b0) and p(e0) = b0 the following homotopy sequence is exact: · · · → πn(F, e0) → πn(E, e0) → πn(B, b0) → πn−1(F, e0) → · · · → π0(B, b0) (2.1) If p : E → B is a Hurewicz (Serre) fibration and B is path connected (and all fibers are CW complexes), then any two fibers belong to the same homotopy type. 2.2. Compact transformation groups. Let G be a compact Lie group and let M be a G-manifold, i.e., M is a paracompact Hausdorff smooth manifold and the action G × M → M,(g, x) 7→ g.x is smooth. Endow the orbit space M/G with the quotient topology. Then M/G is paracompact and Hausdorff, and the orbit projection π : M → M/G is continuous, open, closed, and proper (e.g. [1], [2]). In particular, it follows that if M is (path) connected, then M/G is (path) connected. The orbits G.x which are exactly the fibers of π are compact smooth submanifolds of M. A point x ∈ M is called stationary if G.x = {x}. Proposition. Let G be a compact Lie group and let M be an path connected Gmanifold containing a stationary point. The orbit projection π : M → M/G is a Hurewicz (Serre) fibration if and only if every point in M is stationary. Proof. Suppose that π : M → M/G is a Serre fibration. Since M/G is path connected and all fibers are CW complexes, all fibers of π belong to the same homotopy type. There is one fiber consisting of one point only, namely the stationary point in M. It follows that all orbits consist of one point only, since all orbits are closed manifolds. Hence each point in M is stationary. Corollary. Let ρ : G → GL(V ) be a representation of a compact Lie group G. The orbit projection π : V → V /G is a Hurewicz (Serre) fibration if and only if ρ is trivial. 2.3. Proper G-manifolds. ([2]) Let G be a Lie group and let M be a proper Gmanifold, i.e., the mapping G×M → M ×M,(g, x) 7→ (g.x, x) is proper. Examples are G-manifolds where G is compact or properly discontinuous actions on manifolds. Again M/G is paracompact and Hausdorff, and the orbit projection π is continuous, open, closed, and proper. In a proper G-manifold all isotropy subgroups Gx = {g ∈ G : g.x = x} are compact. We denote by Mreg the set of regular points x in M, i.e., points x allowing an invariant open neighborhood U such that for all y ∈ U there exists an equivariant map f : G.x → G.y, or equivalently, Gx ⊆ gGyg − for some g ∈ G. Orbits through regular points are said to be of principal orbit type. The orbit types in M are the conjugacy classes (H) of the isotropy subgroups H ⊆ G. The inclusion relation on the family of isotropy subgroups induces a partial ordering (H) ≤ (K) on the family of orbit types. If M/G is connected, then the minimum orbit type is precisely the principal orbit type. If M is a Riemannian G-manifold, the regular points in M are exactly those whose slice representation Gx → O(Tx(G.x) ⊥) is trivial, where Tx(G.x)⊥ denotes the orthogonal complement of Tx(G.x) in TxM. The set Mreg is open and dense in M, and Mreg → Mreg/G is a locally trivial fiber bundle. Theorem. Let M be a proper G-manifold. The orbit projection π : M → M/G is a Hurewicz (Serre) fibration if and only if M = Mreg. Proof. Suppose that π : M → M/G is a Serre fibration. There exists a G-invariant Riemannian metric making M a proper Riemannian G-manifold. By the differentiable slice theorem [9], for each x ∈ M there exists a slice Sx such that the Ginvariant neighborhood G.Sx of x is G-equivariantly diffeomorphic to the crossed product G ×Gx Sx. It follows that G.Sx/G ∼= Sx/Gx is an open neighborhood ofORBIT PROJECTIONS AS FIBRATIONS π(x) in the orbit space M/G. The slice Sx can be chosen to be the diffeomorphic image of an open ball around the origin in the vector subspace Tx(G.x) ⊥ of TxM. Evidently, the restriction π|G.Sx : G.Sx → G.Sx/G is a Serre fibration as well. G G/Gx X × {0} f R( RR RR RR RR RR RR RR ]p◦f j jj jj jj jj jj jj jj jj jj jj jj jj jj jj jj jj jj jj jj jj G.Sx π|G.Sx p :ttttttttt X × I φ R( RR RR RR RR RR RR φ¯ gg ggg ggg ggg ggg ggg ggg ggg ggg g ]p◦φ¯ p pp pp pp pp pp pp pp pp pp pp pp pp pp pp pp pp pp pp pp pp pp pp p (]p◦φ¯) − .φ¯ /Sx π|Sx + s ss s ss s ss ss G.Sx/G G.Sx/G ss ss ss ss ss ss ss ss ss ss We claim that also π|Sx: Sx → G.Sx/G ∼= Sx/Gx is a Serre fibration. Let f : X × {0} → Sx be continuous and let φ : X × I → G.Sx/G be a homotopy of π|Sx ◦ f. Since π|G.Sx: G.Sx → G.Sx/G is a Serre fibration, there exists a homotopy φ¯ : X × I → G.Sx of f covering φ. Consider the projection p : G.Sx ∼= G×Gx Sx → G/Gx of the fiber bundle associated to the principal bundle G → G/Gx and the compositions p ◦ f and p ◦ φ¯. Now p ◦ f is constant and equals eGx ∈ G/Gx and thus allows a lift into G, e.g., p]◦ f = e. Since G → G/Gx is a fibration, there exists a homotopy p]◦ φ¯ : X × I → G of p]◦ f covering p ◦ φ¯. It follows that (p]◦ φ¯) − .φ¯ : X ×I → Sx is a homotopy of f covering φ. Hence the claim is proved. We may view π|Sx: Sx → G.Sx/G ∼= Sx/Gx as the orbit projection of the Gxmanifold Sx. Since we may consider the Gx-manifold Sx as a linear representation of a compact Lie group, the Gx-action on Sx must be trivial, by corollary 2.2. Since x was arbitrary, the statement follows. Remark. If the orbit projection π : M → M/G is a Hurewicz (Serre) fibration, then it is regular. 2.4. G-fibrations. ([10]) A G-equivariant continuous map p : E → B between G-spaces E and B is called G-fibration if it is a fibration in the category of Gspaces and G-equivariant maps: For each G-space X, each G-equivariant continuous f : X × {0} → E and each G-equivariant homotopy φ : X × I → B of p ◦ f, there exists a G-equivariant homotopy φ¯ of f covering φ. The G-action on I is trivial. It is easy to verify that a G-fibration is a fibration in the usual sense. More precisely, one can show that p : E → B is a G-fibration if and only if p H : EH → BH is a fibration for each closed subgroup H ⊆ G. Note that EH = {e ∈ E : h.e = e for all h ∈ H} and p H denotes the restriction p|EH . Theorem. Let M be a proper G-manifold. The orbit projection π : M → M/G is a Hurewicz (Serre) G-fibration if and only if M = Mreg. Proof. Suppose that M = Mreg. Let Sx be a slice at x ∈ M. Then G.Sx ∼= G/Gx × Sx, G.Sx/G ∼= Sx, and π|G.Sx : G/Gx × Sx → Sx is given by ([g], s) 7→ s. Hence π|G.Sxis obviously a G-fibration; a G-equivariant homotopy of f covering φ is given by φ¯ = (prG/Gx ◦f, φ). Since M/G is paracompact and Hausdorff, one4 ARMIN RAINER can then show that π is a G-fibration analogously with Hurewicz's uniformization theorem ([3]). Since each G-fibration is a fibration, the other implication is an immediate consequence of theorem 2.3. 2.5. Proper locally smooth actions. ([1]) Let G be a Lie group and M a proper G-space, i.e., M is paracompact and Hausdorff and the G-action is continuous. Let G.x be an orbit in M and let V be a Euclidean vector space on which Gx operates orthogonally. Then a linear tube about G.x in M is a G-equivariant embedding onto an open neighborhood of G.x of the form G ×Gx V → M. A G-space M is called locally smooth if there exists a linear tube about each orbit. It that case M must be a topological manifold. It follows from the differentiable slice theorem [9] that proper G-manifolds in the sense of 2.3 are locally smooth. The definition of local smoothness can by extended to manifolds M with boundary. For this we require, for orbits G.x lying in the boundary of M, tubes of the form G ×Gx V + → M, where V+ = {y ∈ Rn : y1 ≥ 0} and Gx acts orthogonally on V + (in particular the y1-axis is stationary). Properness guarantees that all isotropy groups Gx are compact. Hence the orbits in each Gx-space V (resp. V +) are compact manifolds and therefore CW complexes. It follows that the arguments in 2.2, 2.3, and 2.4 are applicable and we obtain Theorem. Let M be a proper locally smooth G-space (with boundary). The orbit projection π : M → M/G is a Hurewicz (Serre) (G-)fibration if and only if M = Mreg. 3. Orbit projections as quasifibrations 3.1. Quasifibrations. ([4]) A continuous map p : E → B with B path connected is called quasifibration if the induced map p∗ : πn(E, p−1(b), e) → πn(B, b) is an isomorphism for all b ∈ B, e ∈ p − (b), and n ≥ 0, or equivalently, if the inclusion of each fiber p − (b) into the homotopy fiber Fb of p over b is a weak homotopy equivalence. The fiber p − (b) is included in Fb = {(e, γ) ∈ E × C (I, B) : γ(0) = p(e), γ(1) = b} as the pairs (e, γ) with e ∈ p − (b) and γ the constant path at b. If B is not path connected, then p : E → B is a quasifibration if the restriction of p over each path component of B is a quasifibration. For quasifibrations the homotopy sequence (2.1) is exact. All fibers of a quasifibration p : E → B with B path connected belong to the same weak homotopy type. Hurewicz and Serre fibrations are quasifibrations. 3.2. Lemma. Let M be a proper G-manifold with connected orbit space M/G. Let k be the least number of connected components of isotropy groups of dimension m := min{dim Gx : x ∈ M}. Then the following conditions are equivalent: (1) G.x is a principal orbit. (2) Gx is of dimension m and has k connected components. Proof. Let x ∈ M such that Gx has minimal dimension and the least number of connected components for this dimension in all of M. Let Sx be a slice at x. For any y ∈ G.Sx we have y ∈ g.Sx = Sg.x and thus Gy ⊆ Gg.x = gGxg − , for some g ∈ G. By the choice of x, we find Gy = gGxg −1 which shows that G.x is principal. The converse implication follows from the fact that there is precisely one principal orbit type, if M/G is connected. ORBIT PROJECTIONS AS FIBRATIONS 3.3. Theorem. Let M be a proper G-manifold. Let one of the following conditions be satisfied: (1) G is finite. (2) G is compact, connected, and simply connected. (3) G is compact and there exists a connected and simply connected orbit in each path component of M/G. (4) There exists a weakly contractible orbit in each path component of M/G. Then the orbit projection π : M → M/G is a quasifibration if and only if M = Mreg. Proof. Suppose that π : M → M/G is a quasifibration. We may suppose that M/G is path connected, by restricting π over each path component of M/G and treating them separately. Then all orbits belong to the same weak homotopy type. We claim that each of the four conditions in the theorem implies that all occurring isotropy groups have the same dimension and the same number of connected components. If G is finite, all orbits and thus all isotropy groups have the same cardinality. Assume that G is compact. Let G.x and G.y be distinct orbits. Since they are compact manifolds, we find dim G.x = dim G.y, and, consequently, dim Gx = dim Gy. If (2) is satisfied we may conclude from the homotopy sequences of the fibrations G → G/Gx ∼= G.x and G → G/Gy∼= G.y that π0(Gx) ∼= π1(G/Gx) ∼= π1(G/Gy) ∼= π0(Gy). Assume that (3) holds true. Then each orbit is connected and simply connected. Let G.x be principal and G.y arbitrary. Without loss Gx ⊆ Gy and we have a locally trivial fiber bundle G/Gx → G/Gy with fiber Gy/Gx. The associated homotopy sequence yields that Gy/Gx is trivial, whence the statement. Finally, if condition (4) is fulfilled, all orbits are weakly contractible, whence any two isotropy groups have the same weak homotopy type, again by the homotopy sequence of G → G/Gx ∼= G.x. Since all isotropy groups are compact manifolds, the claim follows. Since M/G is connected, there is precisely one principal orbit type, namely the type corresponding to the isotropy group with minimal dimension and minimal number of connected components. By the claim, all points are regular. 3.4. G-quasifibrations. A G-equivariant continuous map p : E → B between G-spaces E and B is called G-quasifibration if p H : EH → BH is a quasifibration for each closed subgroup H ⊆ G. In particular, a G-quasifibration is a quasifibration. Any G-fibration is a G-quasifibration. Corollary. Let M be a proper G-manifold. Suppose that one of the conditions (1) – (4) in the theorem 3.3 is satisfied. Then the orbit projection π : M → M/G is a G-quasifibration if and only if M = Mreg. Proof. The statement follows from theorem 2.4 and theorem 3.3. 3.5. Let M be a proper G-manifold. For the orbit projection π : M → M/G consider the path fibration p : Eπ → M/G, where Eπ = {(x, γ) ∈ M × C (I, M/G) : γ(0) = π(x)} and p(x, γ) = γ(1). The space C (I, M/G) carries the compact-open topology and Eπ inherits the subspace topology from M × C (I, M/G). Then p : Eπ → M/G is a Hurewicz fibration with fibers Fz = {(x, γ) ∈ M × C (I, M/G) : γ(0) = π(x), γ(1) = z}, z ∈ M/G. The G-action on M induces a natural G-action on each fiber π − (z) and each homotopy fiber Fz for which the canonical inclusion π − (z) ֒→ Fz is equivariant.6 ARMIN RAINER Assume that M/G is path connected. Let π − (u) = G.x and π − (z) = G.y be distinct orbits in M and choose a path α : I → M/G with α(0) = u and α(1) = z. We have the following diagram π − (u) /Fu /Fz π − (z) ? o _ , where Fu → Fz given by (x, γ) 7→ (x, αγ) is a homotopy equivalence. Note that each arrow in the diagram is G-equivariant. Theorem. Let M be a proper G-manifold and assume that M/G is path connected. The following conditions are equivalent: (1) The orbit projection π : M → M/G is a G-quasifibration. (2) The inclusion π − (z) ֒→ Fz is a homotopy equivalence allowing a Gequivariant homotopy inverse for all z ∈ M/G. (3) Let (H) be the principal orbit type. For any orbit type (K) there is a (weak) homotopy equivalence f : G/H → G/K, and f is G-equivariant. (4) M = Mreg. Proof. It is evident that (2) implies (3). Let us assume that condition (3) is satisfied. We prove (4). Without loss we may suppose that H ⊆ K and have the commuting diagram H / _ G / id G/H f K /G /G/K Consequently, using the fact that G → G/H and G → G/K are fibrations, we obtain the commuting diagram πn+1(G) / πn+1(G/H) / πn(H) / πn(G) / πn(G/H) πn+1(G) /πn+1(G/K) /πn(K) /πn(G) /πn(G/K) for each n ≥ 0 where the rows are exact and all vertical arrows apart from the middle one are isomorphisms. By the five lemma, the vertical middle arrow is an isomorphism as well. It follows that πn(H) ∼= πn(K) for all n ≥ 0, and, by Whitehead's theorem, we find that H and K are homotopically equivalent. Since H and K are compact Lie groups, we may conclude that they have the same dimension and the same number of connected components. By lemma 3.2, all points in M have to be regular. Theorem 2.4 yields that (4) implies (1). Finally, we prove that (1) implies (2). If π : M → M/G is a G-quasifibration, then the fixed point maps π H : MH → M/G are quasifibrations for all closed subgroups H ⊆ G. Let z ∈ M/G be arbitrary. The fiber π − (z) and the homotopy fiber Fz are G-spaces in a canonical way, and we have (π H )− (z) = π − (z) H and F H z = {(x, γ) ∈ MH × C (I, M/G) : γ(0) = π H(x), γ(1) = z}. Since π H is a quasifibration, the canonical inclusion π− (z) H ֒→ FH z is a weak homotopy equivalence. By 3.6.1, we may conclude that the F H z are homotopy equivalent to CW complexes and that Fz has the G-homotopy type of a G-CW complex. By Whitehead's theorem, the inclusions π − (z) H ֒→ FH z are homotopy equivalences. By 3.6.2, we obtain that the inclusion π − (z) ֒→ Fz is even a Ghomotopy equivalence. Hence (2). ORBIT PROJECTIONS AS FIBRATIONS Corollary. Let M be a proper locally smooth connected G-space (with boundary) and suppose that the principal orbits are of codimension 1. Then the orbit projection π : M → M/G is a quasifibration if and only if M = Mreg. Proof. It is proved in [1] IV.8. that under these condition either all orbits are principal or M is equivalent as G-space to the mapping cylinder of the equivariant map G/H → G/K for (H) principal and (H) < (K) or to the union of the two mapping cylinders of G/H → G/Ki for (H) principal and (H) < (Ki), i = 0, 1. In the latter cases the orbit space M/G is isomorphic either to [0, 1) or to [0, 1], and the natural projection of a mapping cylinder identifies with π. This projection is a quasifibration if and only if the mapping inducing the mapping cylinder is a weak homotopy equivalence. By the implication (3) ⇒ (4) in the forgoing theorem, the statement of the corollary follows. 3.6. Equivariant homotopy theory. We collect a few results from equivariant homotopy theory needed in the proof of theorem 3.5. For a definition of G-CW complexes see the cited references. 3.6.1. Result. ([12] 4.14; [7] 3.3.5; see also [8]) Suppose that X and Y are proper G-spaces. Let f : X → Y be a G-map, and let y ∈ Y have isotropy group H. Then, regarding f as an H-equivariant map based at y, the homotopy fiber Fy of f has the H-homotopy type of an H-CW complex whenever X and Y have the G-homotopy type of G-CW complexes. It is proved in [5] that a proper G-manifold M has a G-CW structure. The orbit space M/G is triangulable by [11]. 3.6.2. Result. ([6] 1.1, [10] II.2.7) A G-map f : X → Y of G-CW complexes is a G-homotopy equivalence if and only if for any subgroup H ⊆ G which occurs as isotropy subgroup of X or Y the induced map f H : XH → YH is a homotopy equivalence. References [1] G.E. Bredon, Introduction to compact transformation groups, Pure and applied mathematics 46, Academic press, New York, London, 1972. [2] J.J. Duistermaat, J.A.C. Kolk, Lie groups, Universitext, Springer-Verlag, Berlin, 2000. [3] J. Dugundji, Topology, Allyn and Bacon, Inc., Boston, 1966. [4] A. Hatcher, Algebraic topology, Cambridge University Press, Cambridge, 2002. [5] S. Illman, Existence and uniqueness of equivariant triangulations of smooth proper Gmanifolds with some applications to equivariant Whitehead torsion, J. Reine Angew. Math. 524 (2000), 129–183. [6] W. L¨uck, Survey on classifying spaces for families of subgroups, arXiv:math.GT/0312378. [7] J.P. May, J. Sigurdsson, Parameterized homotopy theory, arXiv:math.AT/0411656. [8] J. Milnor, On spaces having the homotopy type of a CW-complex, Trans. Amer. Math. Soc. 90 (1959), 272–280. [9] R.S. Palais, On the existence of slices for actions of non-compact Lie groups, Ann. of Math. (2) 73 (1961), 295–323. [10] T. tom Dieck, Transformation groups, de Gruyter Studies in Mathematics, 8, Walter de Gruyter & Co., Berlin, 1987. [11] A. Verona, Triangulation of stratified fibre bundles, Manuscripta Math. 30 (1979/80), no. 4, 425–445. [12] S. Waner, Equivariant homotopy theory and Milnor's theorem, Trans. Amer. Math. Soc. (1980), 351–368. Armin Rainer: Fakultat f ¨ ur Mathematik, Universit ¨ at Wien, Nordbergstrasse 15, ¨ A-1090 Wien, Austria E-mail address: armin.rainer@univie.ac.at\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper ID: 2111.11774v1\n",
      "\n",
      "Abstract: We prove that for all integers $k \\geq 1$, there exists a constant $C_k$\n",
      "depending only on $k$, such that for all $q > C_k$, and for $n = 1, 2$ every\n",
      "matrix in $M_n(\\mathbb{F}_q)$ is a sum of two $k$th powers and for all $n \\geq\n",
      "3$ every matrix in $M_n(\\mathbb{F}_q)$ is a sum of at most three $k$th powers.\n",
      "\n",
      "Clean Text: \n",
      "1. Introduction Let n be a positive integer, R a commutative ring with unity, and Mn(R) the ring of n×n matrices over R. The Matrix Waring Problem over R is, essentially, to represent an arbitrary matrix in Mn(R) as a sum of two kth powers for any positive integer k ≥ 1. This goal of this article is to answer this question in the case where R is a finite field Fq, with q sufficiently large; see Theorem 1.1 and Theorem 1.2. The classical Waring problem states that every natural number is a sum of 4 squares, of 9 cubes, of 19 biquadrates, etc. In other words, for all integers k ≥ 1, there exists a smallest positive integer g(k) such that every natural number is a sum of at most g(k) number of kth powers (of natural numbers); in particular, g(2) = 4, g(3) = 9, g(4) = 19. The existence of g(k) for arbitrary k was proved by Hilbert, and later on explicit formulae for g(k) have been found for all but finitey many values of k; for a survey of results about Waring's problem and its variants see [8]. In this context, a variant of the classical Waring problem may be posed, namely, for all k ≥ 2, one may ask whether there exists a smallest bound G(k) such that every sufficiently large natural number is a sum of at most G(k) number of kth powers. Unlike the case of g(k), the values of G(k) have been found only when k = and k = 4. Waring's problem makes sense over arbitrary rings, and in particular for matrix rings over finite fields. Let k and n be positive integers and let G(k, n) be the smallest positive integer such that for all sufficiently large q every matrix in Mn(Fq) can be written as a sum of G(k, n) number of kth powers (of matrices in Mn(Fq)). It is well-known, due to Small [7], that G(k, 1) = 2 for all k ≥ 1; see Proposition 3.2. Including this result of Small, we prove that, 12 KRISHNA KISHORE For all k ≥ 2, G(k, 1) = G(k, 2) = 2 and G(k, n) ≤ 3 for all n ≥ 3. In other words, we prove the following results. Theorem 1.1. For all integers k ≥ 1, there exists a constant Ck depending only on k, such that for all q > Ck, every matrix in M2(Fq) is a sum of two kth powers. Theorem 1.2. For all integers k ≥ 1, there exists a constant Ck depending only on k, such that for all q > Ck, and for all n ≥ 3, every matrix in Mn(Fq) is a sum of at most three kth powers. We note here that our results go beyond an eariler result due to Demiroglu published in this journal [3]. While Demiroglu obtained the result with infinitely many exceptions, we have the same result with only finitely many exceptions. Furthermore, the methods used to obtained these results in this article are distinct from the ones used by Demiroglu. These results are consequences of Weil's result on the number of solutions in Fq of polynomials defined over Fq; see Theorem 2.2. The paper is organized as follows. In §2 we obtain consequences of Weil's results on the number of solutions to equations over finite fields. In §3 we prove Theorem 1.1. In §4 we use results of §3 to prove Theorem 1.2. Notation The diagonal matrix with entries λ1, . . . , λn along the diagonal is denoted by diag(λ1, . . . , λn). The direct sum A ⊕ B of two square matrices A of size r and B of size s is the square matrix of size r + s with A and B lying along the diagonal; that is A ⊕ B is in the block diagonal form. Fq always denotes the finite field with q elements. 2. Equations over Finite Fields First, we need some results from algebraic geometry over finite fields. Recall, a polynomial over Fq is absolutely irreducible if it remains irreducible over the algebraic closure of Fq. Lemma 2.1. Consider the polynomial Y d = f(X) in Fq[X, Y ], where d ≥ 1. The following conditions are equivalent: (1) Y d − f(X) is absolutely irreducible.MATRIX WARING PROBLEM (2) Y d − cf(X) is absolutely irreducible for every nonzero c in Fq. (3) Let f(X) = a(X − α1) d · · ·(X − αs) ds be the factorization of f in the algebraic closure of Fq with αi 6= αjfor i 6= j and di are nonnegative. Then (d, d1, d2, · · · , ds) = 1. Proof. The reader may refer to [Page 11, [6]] for a proof. For an introduction to solutions to equations over finite fields the reader may refer to [4]. The following theorem is a special case of Weil's theorem on number of solutions of equations over a finite field [9]. Theorem 2.2. (Weil) Consider the polynomial Y d = f(X) over Fq, where d ≥ 1 . Let m be the degree of f(X). Suppose Y d − f(X) is absolutely irreducible and q > 100 · d · m2. Let N be the number of zeros of the polynomial Y d − f(X). Then |N − q| ≤ 4d 3/2m √ q. Proof. This is a consequence of Weil's result [9]. For a proof the reader may refer to [Page 10, [6]]. Proposition 2.3. Let c be any nonzero element in Fq, and consider the polynomial F := Xk + Y k − c in Fq[X, Y ]. For all sufficiently large q, there exists a solution (x, y) ∈ Fq × Fq such that (a) F(x, y) = 0. (b) x k 6= yk . (c) Moreover, for any λ ∈ Fp, the solution (x, y) satisfying (1) and (2) may be chosen so that x k y k 6= λ. Proof. Let p be the characteristic of Fq. The pth power map on Fq is an automorphism of Fq, so the equation Xl + Y l − c has a solution satisfying the conditions in the conclusion if and only if its pth power (X l + Yl − d)p = Xk + Yk − cp . has a solution satisfying the conditions in the conclusion. Hence we may assume without loss of generality that p ∤ k. The derivative of the polynomial f(X) := −(Xk − c) is nonzero, so f(X) is separable, and therefore by the implication (3) =⇒ (1) of Lemma 2.1, the polynomial F(X, Y ) := Y k + Xk − c is absolutely irreducible over Fq. Therefore, by Theorem 2.2, the number of solutions N to F(X, Y ) satisfies the inequality |N − q| ≤ 4k 5/2√ q. Now the set of solutions satisfying (a) and (b) is finite. Indeed, if (x, y) is a solution to F with x k = yk and if ζk is the kth root of unity in the algebraic closure of Fq then (x, ζkx) are all the possible solutions (x, y)4 KRISHNA KISHORE such that x k = yk . Furthermore, the set of solutions satsifying (a) and (c) is also finite. Indeed, let x and y be chosen as above satiyfing the system of equations Xk+Y k = c and XkYk = λ. Then Xk (c−Xk) = λ so that x is a root of the polynomial X2k −cXk +λ, which has at most 2k number of roots in Fq. Corresponding to each root x, there exists at most k number of y such that (x, y) is a solution to the system. Thus the number of solutions to the system is at most 2k . Therefore, there is a solution (x, y) satisfying the desired conditions (a), (b) and (c), if q is sufficiently large, for instance when q > 400 · k 5/2√q + k + 2k , so that for Ck = (k + 2k ) , the conclusion holds. 3. n = 1, 2 case We begin by observing the following elementary facts. Lemma 3.1. Let k, m1, m2, m and n be positive integers. Let A, B, C, D, P and Q be matrices over Fq for a fixed q. (1) The representation of A as a sum of kth powers is invariant under conjugation by GLn(Fq). In other words, if A is a sum of kth powers, so is any conjugate of A. (2) If A and B are matrices of same size n, and if A is a sum of m kth powers and B is a sum of m2 kth powers then the matrix sum A + B is a sum of (m1 + m2) kth powers. (3) If A is a sum of m1 kth powers and B is a sum of m2 kth powers, then A⊕B is a sum of m kth powers where m is the maximum of m1 and m2. (4) Let A and C be r ×r matrices, and B and D be s×s matrices. Then (A ⊕ B) · (C ⊕ D) = AC ⊕ BD, where · denotes matrix multiplication. In particular, for any k ≥ 1, (A⊕B) k = Ak⊕Bk . Furthermore, the inverse of A ⊕ B exists if and only if A and B are invertible, in which case (A ⊕ B) −1 = A−1 ⊕ B− . In particular, if P ∈ GLr(Fq) and Q ∈ GLs(Fq) then (P ⊕ Q) · (A ⊕ B) · (P −1 ⊕ Q− ) = P AP −1 ⊕ QAQ−1. Proof. For part (1), observe that if A = Bk 1 + . . . + Bkm for some Bi ∈ Mn(Fq) then for P ∈ GLn(Fq), P AP −1 = P(B k 1 + . . . + B k m)P −1 = P Bk 1P −1 + . . . + P Bk mP − = (P B1P − ) k + . . . + (P BmP− ) k . The remaining parts are straightforward. The action of GLn(Fq) on Mn(Fq) by conjugation partitions Mn(Fq) into conjugacy classes, with each conjugacy class represented by aMATRIX WARING PROBLEM matrix in rational canonical form [Theorem B-3.46, [5]]. By definition, a rational canonical form of a matrix in Mn(Fq) is a direct sum C(g1) ⊕ . . . ⊕ C(gr) of companion matrices C(gi), where gi are monic polynomials in Fq[x], such that g1 | g2 | . . . | gs. For g := x n − an−1xn− . . . − a1x − a0 in Fq[x] its companion matrix C(g) is the n × n matrix is (1) C(g) :=       0 1 0 . . . 0 0 1 . . . . . . . . . . . . . . . . . . 0 0 0 . . . a0 a1 0 · · · an−       By Lemma (3.1) (1) (3), and (4), it follows that to express a matrix as a sum of kth powers it suffices to express companion matrices of polynomials in Fq[x] as a sum of kth powers. First we consider the representibility of 1 × 1 matrices. Consider the following well-known result due to Small [7]. Proposition 3.2. (Small) Fix an integer k ≥ 1. For all sufficiently large finite fields Fq with q > k4, every element of Fq is a sum of two kth powers. In this section, we prove that every 2 × 2 matrix over Fq is a sum of two kth powers for any k ≥ 1 and for all sufficiently large q. The following lemma is elementary and well known, but for the sake of completeness we demonstrate it here. Lemma 3.3. Suppose the characteristic polynomial of a matrix A in M2(Fq) has a repeated eigenvalue λ ∈ Fq. Then A is similar either to the diagonal matrix diag(λ, λ) or to λ 0 λ . Proof. Suppose A is not similar diag(λ, λ). Let B := A − λI which is nonzero and nilpotent. We claim that it is similar to the nilpotent matrix 0 0 so that A is similar to the matrix in desired form. If v is an eigenvector corresponding to the eigenvalue λ of A, then Bv = 0, so that B has nontrivial kernel, viewing B as a Fq-linear transformation from F q → F q . Choose a nonzero v such that Bv = 0 and define a matrix P whose first column is v and the second column to be any vector w such that Bw = v, which exists because the kernel of B is equal to the image of B. Then P −1BP = 0 0 as desired. 6 KRISHNA KISHORE Lemma 3.4. Suppose a matrix A be similar to the diagonal matrix diag(λ, µ) over Fq. Then, for any k ≥ 1, and for all sufficiently large q, the matrix A is a sum of two kth powers. Proof. The expression of a matrix as a sum of kth powers is invariant under conjugation, so A may be assumed to be diagonal matrix diag(λ, µ). By Proposition 3.2, for all sufficiently large q, the elements λ, µ ∈ Fq are sums of two kth powers, so that λ = a k 1 + a k and µ = b k 1 + b k , with a1, a2, b1, b2 ∈ Fq. Then, A = diag(λ, µ) = diag(a k 1 + a k , bk 1 + b k ) = diag(a1, b1) k + diag(a2, b2)k . Before proving the main result, we need the following technical lemma. Proposition 3.5. For any element λ ∈ Fq, the matrix A := λ 0 λ is a sum of two kth powers. Proof. Let a, d be elements in Fq such that a + d 6= 0 and 2λ 6= a + d. By Proposition 2.3 there exist r, s ∈ Fq such that (a) r 6= s and r + s = a + d (with c takes as a + d in Proposition 2.3). (b) r and s are kth powers. (c) rs 6= ad (with 'λ' taken as ad in Proposition 2.3) Let c be an arbitrary element in Fq. Define b as b = ( 0 if c = (−c) − (rs − ad) if c 6= 0. Then b is nonzero if and only if c is nonzero by condition (c). The characteristic polynomial of the matrix B := a b c d is X2 − (a + d)X + (ad − bc), which is equal to X2 − (r + s)X + rs due to (a) and the definition of the element b above. Therefore, B is similar to the diagonal matrix diag(r, s) which is a kth power, due to (b). Now, due to Proposition 2.3 again, there exist distinct t, u ∈ Fq with a and d are as chosen above, • t 6= u and t + u = (λ − a) + (λ − d). • t and u are kth powers. • tu 6= (λ − a)(λ − d). Define b ′ := ( 0 if c = c − (tu − (λ − a)(λ − d)) if c 6= 0.MATRIX WARING PROBLEM Then the matrix C := λ − a b′ −c λ − d is conjugate to the diagonal matrix diag(t, u). Clearly B + C = λ b + b ′ 0 λ , and if c 6= 0 then b ′ 6= −b so that their sum x := b + b ′ 6= 0. The following relation x −1 0 x λ x 0 λ 1 0 x = λ 0 λ , implies that A is conjugate to the sum B + C and therefore it is a sum of two kth powers as desired. We now prove the first main result of this article. Proof. (of Theorem 1.1) Let A ∈ M2(Fq), and p(t) denote its characteristic polynomial. We consider three cases based on the nature of splitting p(t). First, if p(t) splits completely over Fq with distinct roots, then A is conjugate to a diagonal matrix with eigenvalues lying along the diagonal. By Lemma 3.4 A is a sum of two kth powers, for all sufficiently large q. Second, suppose p(t) splits completely over Fq with repeated root λ. Then A is similar to a diagonal matrix diag(λ, λ) or to the upper triangular matrix λ 0 λ . In the former case the assertion follows by Lemma 3.4 and in the latter case by Proposition 3.5. Finally, suppose p(t) is irreducible over Fq. Consider the evaluation map evA : Fq[t] → M2(Fq) defined by sending t to A. It is an Fq-algebra homomorphism with kernel as the ideal generated by p(t) and image as the Fq-algebra, say Fq[A], generated by the identity matrix I2 and A. Therefore, Fq[A] is isomorphic to Fq 2 , and by Proposition 3.2 every element in Fq 2 , hence A, is a sum of two kth powers for all sufficiently large q. 4. n ≥ 3 case Before we state our main results, we note one fact: the cardinality of the subgroup consisting of the kth powers of elements of Fq is (q − 1)/ gcd(k, q − 1) + 1, which is at least q/k so that if q is sufficiently large there exists sufficiently many elements in Fq that are not 1 and that are kth powers ; see [Proposition 7.1.2, [4]]. Proposition 4.1. Let q = p l with p prime, l ≥ 1. Let k ≥ 1 be a positive integer. Then −1 is a kth power (of an element in Fq) precisely in the following cases: (a) p = 2.8 KRISHNA KISHORE (b) k is odd. (c) k is even of the form 2st with s ≥ 1 and t odd and q ≡ 1 (mod 2s+1). In the remaining cases it is a sum of two kth powers. Proof. The cases (a) and (b) are clear. Now consider solutions to Xk + 1 = 0 in Fq. If q is even then x = 1 is a solution, so suppose that q is odd. Write k = 2ab, with b odd. Then the equation Xk + 1 = 0 has a solution in Fq if and only if the equation Y a + 1 = 0 has a solution in Fq. Indeed, if x k + 1 = 0 for some x ∈ Fq, then (xb ) a + 1 = 0 so that y = x b is a solution to Y a + 1 = 0. Conversely, if there is y in Fq such that y a + 1 = 0 so that y a = −1 , then y k = (y a ) b = (−1)b = −1 so that y is a solution to x k + 1 = 0 in Fq. Now, the equation Y a = − has a solution, say y, in Fq if and only if (y a ) 2 = 1 so that the order of y is divisible by q − 1. In other words, Xk + 1 = 0 has a solution in Fq if and only if q ≡ 1 (mod 2a+1). The last part is an immediate consequence of Propostion 3.2. Finally, the case n ≥ 3 can be reduced to that of n = 1, 2 based on the following lemma. Lemma 4.2. (Botha) Let B be an n × n diagonalizable matrix over a field Fq, and suppose a ∈ Fq is not an eigenvalue of B. Then A = B v 0 a , where v ∈ F n q , is also diagonalizable. Proof. The reader may refer to [Lemma 1.1(c), [2]]. We use a result and its proof both due to Botha [Lemma 2.1, [1]] and use the n = 1, 2 case to prove Theorem 1.2. For n ≥ 3 even and x ∈ Fq, let Gn = M n/ 0 0 −x and Hn = [0] ⊕   M (n−2)/ x 0   ⊕ [x], For n ≥ 3 odd and x ∈ Fq, let Gn =   M (n−1)/ 0 0 −x   ⊕ [0] and Hn = [0]M   M (n−1)/ x 0   Lemma 4.3. (Botha) If |Fq| > 2, then for any n ≥ 3, any matrix A in Mn(Fq) can be expressed as a sum of two diagonalisable matrices.MATRIX WARING PROBLEM Proof. The reader may refer to [Lemma 2.1, [1]]. We now prove the second main result of this article: Proof. (of Theorem 1.2): We use the proof of the lemma to deduce our result. The following four decompositions is due to Botha [1], which distinguish between n even and odd, and between an−1 zero and nonzero. Let A ∈ Mn(Fq). We show that A is a sum at most three kth powers. As noted at the beginning of §3 we may assume that A is a companion matrix (1) of §3 . Let v = (a0, . . . , an−2) T , where T denotes transpose of a matrix. Case n ≥ 3 odd and an−1 = 0: (2) A = Gn−1 v T − + Hn−1 en− 0 , where x 6= 0, 1. Let B denote the first summand, and C the second summand. If x 6= 0, 1 then the matrix 0 1 −x has distinct eigenvalues 0 and −x and the matrix x 1 has distinct eigenvalues 0 and x, so they are diagonalizable. By Lemma 3.1 the matrices B and C are diagonalizable. Furthermore let x be a kth power distinct from 0 and 1; such a x exists by the observation at the beginning of this section. Now, if k satisfies the conclusion of Proposition 4.1, then both B and C are kth powers so that A is a sum of two kth powers. In the remaining cases, B is a sum of two kth powers by Theorem 1.1 and C is a kth power so that A is a sum of three kth powers. Case n ≥ 3 odd and an−1 6= 0: (3) A = Gn−1 v T an− + Hn−1 en− 0 , with x 6= 0, −an−1. We choose x which is a kth power and not equal to either 0 or −an−1; such a x exists by the observation at the beginning of this section. Now, if k satisfies the conclusion of Lemma 4.1 then A is a sum of two kth powers. In the remaining cases, it follows as above that the first summand is a sum of two kth powers by Theorem 1. and the second summand is a kth power so that A is a kth power.10 KRISHNA KISHORE Case n ≥ 3 even, and an−1 = 0: (4) A = Gn−1 en 0 − + Hn−1 v T , where x 6= 0, 1. Now,let x 6= 0, 1 and is a kth power. Now, if k satisfies the conclusion of Lemma 4.1, it follows that A is a sum of two kth powers. In the remaining cases, it follows that the first summand is a sum of two kth powers by Theorem 1.1 and the second summand is a kth power, so that A is a sum of three kth powers. Case n ≥ 3 even and an−1 6= 0: (5) A = Gn−1 en 0 bn− + Hn−1 v T cn− . Let an−1 = bn−1 + cn−1 and furthermore suppose that bn−1 and cn− are kth powers. Such a representation exists by Proposition 2.3. Given such a bn−1 and a cn−1 there exists x 6= 0, cn−1 which is a kth power. Now, if k satisfies the conclusion of Lemma 4.1, then A is a sum of two kth powers, otherwise it is a sum of three kth powers. Note that we proved a stronger statement than Theorem 1.2, namely if k satisfies one of the conditions in Lemma 4.1 then every matrix in M2(Fq) is a sum of two kth powers, otherwise it is a sum of three kth powers. Acknowledgements It is a great pleasure to thank Michael Larsen for suggesting the question. References [1] J.D. Botha: Sums of diagonalizable matrices, Linear Algebra and its Applications, 315 (2000), 1–23. [2] J.D. Botha: Products of diagonalizable matrices, Linear Algebra and its Applications, 273 (1998), 65–82. [3] Yesim Demiroglu: Waring's problem in finite rings, Journal of Pure and Applied Algebra, Vol. 223, Issue 8, (2019), 3318– [4] K. Ireland, M.Rosen: A classical introduction to modern number theory, (84). Springer Science and Business Media, 2013. [5] J.J. Rotman: Advanced Modern Algebra: Third Edition, Part 1, Graduate Studies in Mathematics, American Mathematical Society, 165 (2015). [6] W. M. Schmidt: Equations over finite fields: an elementary approach, Lecture Notes in Mathematics, 536. New York: Springer-Verlag, 1976.MATRIX WARING PROBLEM [7] C. Small: Sums of powers in large finite fields, Proc. Amer. Math. Soc. (1977), 35–36. [8] R.Ch.Vaughan, T.D. Wooley: Waring's porblem: a survey, Number Theory Milleninum 3 (2002), 301–340. [9] Weil, Andr´e: Numbers of solutions of equations in finite fields, Bull. Amer. Math. Soc. 55, 5 (1949) 497–508. Email address: kishorekrishna@iittp.ac.in Krishna Kishore, Department of Mathematics, Indian Institute of Technology Tirupati Tirupati, AP India 517506\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper ID: 0511016v1\n",
      "\n",
      "Abstract: The ALL-1 gene is directly involved in 5-10% of ALLs and AMLs by fusion to\n",
      "other genes or through internal rearrangements. DNA microarrays were utilized\n",
      "to determine expression profiles of ALLs and AMLs with ALL-1 rearrangements.\n",
      "These profiles distinguish those tumors from other ALLs and AMLs. The\n",
      "expression patterns of ALL-1-associated tumors, in particular ALLs, involve\n",
      "oncogenes, tumor suppressors, anti apoptotic genes, drug resistance genes etc.,\n",
      "and correlate with the aggressive nature of the tumors. The genes whose\n",
      "expression differentiates between ALLs with and without ALL-1 rearrangement\n",
      "were further divided into several groups enabling separation of ALL-1-\n",
      "associated ALLs into two subclasses. Further, AMLs with partial duplication of\n",
      "ALL-1 vary in their expression pattern from AMLs in which ALL-1 had undergone\n",
      "fusion to other genes. The extensive analysis described here draws attention to\n",
      "genes which might have a direct role in pathogenesis.\n",
      "\n",
      "Clean Text: \n",
      "1. overexpressed oncogenes – a) HOX A9 and MEIS1, which form a sequence specific DNA binding complex (14), are frequently co-activated in spontaneous AML of BXH-2 mice (15). Forced co-expression of the two genes in murine bone marrow cells rapidly induces AML (16). b) HOX A10, which induces AML in mice (17). c) LMO2 (RMBT2), whose overexpression, resulting from chromosome translocations, is associated with T-cell ALL (18). d) MYC, which has a critical role in cell proliferation and is deregulated in human lymphomas and other tumors (19). e) LGALS1 (galectin1), which cooperates with RAS in cell transformation (20) and whose overexpression correlates with progression of glioblastoma (21). f) PDGFRB 8(platelet-derived growth factor receptor beta), which is a tyrosine kinase, and is deregulated through chromosome translocations and gene fusions in chronic myeloproliferative diseases (22). 2. overexpressed genes involved in drug resistance – a) CD44, associated with aggressive B-CLL (23) and conferring resistance to several widely-used anticancer drugs (24). b) DHFR (dihydrofolate reductase), conferring resistance to methotraxate. c). BLMH (bleomycine hydrolase). d) CAT (catalase), which protects from oxidative stress. 3. overexpressed genes involved in protection from apoptosis and in survival – a) CDC2 (cell division cycle 2; p34; CDK1), which preserves the viability of cancer cells in response to microtubule poisons and anticancer drugs like vincristine and taxol, by increasing expression of the apoptosis inhibitor survivin (25). b) PPP2R5C (phosphatase 2A ), implicated in regulation of growth, transcription and signal transduction. Required for survival and protects from apoptosis in Drosophila (26). c) MAP3K5 (MAP kinase kinase kinase 5), involved in activation of the p38 MAP kinase required for initiation of the G2/M checkpoint (27), and selectively activated in non-small cell lung cancer (28). 4. underexpressed pro-apoptotic genes – a) ITPR3 (inositol 1,4,5-triphosphate receptor type 3), which mediates the release of intracellular calcium and consequently actively promotes apoptosis (29), b) IGFBP3 (IGF binding protein 3), which has proapoptotic activity both dependent and independent of p (30). c) JUN, implicated as positive modulator of apoptosis induced in hematopoeitic progenitor cells of the myeloid linkage (31). Downregulation of JUN might account for the failure of glucocorticoid therapy (32). 5. underexpressed tumor suppressors and growth inhibitors – a) FHIT (fragile histidine triad), target of chromosome aberrations and inactivated in many cancers, including lung, oesophagus, stomach, breast, kidney and leukemias (33). b) DAPK1 (death-associated protein kinase 1), which counters oncogene9induced transformation by activating a p19ARF/p53 apoptotic checkpoint (34). c) MADH1 (mothers aginst decapentaplegic homologue 1; SMAD1), transcription modulator mutated in various forms of cancer (35). 6. overexpressed genes acting in cell cycle progression and cell proliferation – a) CCNA1 (cyclin A1), which functions in S phase and mitosis and its expression is elevated in a variety of tumors including AMLs (36). b) BMYB (myb-like 2), which is required for proliferation of hematopoietic cells (37) and directly activates the anti-apoptotic gene ApoJ/clusterin (38). c) CDKN3 (cyclin dependent kinase inhibitor 3), which interacts with cyclin dependent kinases and is overexpressed in breast and prostate cancer (39). Our battery of ALLs lacking t(4;11) consisted of tumors at various stages of differentiation including pre B-, pro B- and T-cell ALLs. Therefore, the differences in expression found should be due in part to the differences in differentiation stage between t(4;11) to the other ALLs. Hence we now tried to: 1) identify those genes whose expression pattern is directly correlated with the t(4;11) abnormality, either resulting from the abnormality or specifically associated with the cell type in which the chromosome translocation occurred. 2) separate the genes above from genes whose expression reflects (sensitive to) the differences between early vs late differentiation stage (pro B- vs pre B- and T-cell tumors). 3) identify genes associated with unique features of CD10- ALLs.To this end we defined three groups of ALL samples: (i) t(4;11) tumors (pro B-cells), (ii) CD - tumors (pro B-cells), and (iii) rest of the ALLs (pre B- and T-cells). Three distinct supervised analyses were performed, which separate: 1) t(4;11) ALLs from the rest of ALLs. 2) t(4;11) ALLs from CD10- ALLs. 3) CD10- ALLs from the rest of ALLs. The genes that participate in one or more separations were identified (see the Venn diagram of Fig. 2A). Three overlapping groups were found, containing 80, 46 and 21 genes (lists of genes in Tables 4-6 in the web site). Each of these groups contained genes that are overexpressed or underexpressed; the expression matrix of the three groups is shown in Fig. 2B. 80 genes separate both pro B-cell t(4;11) ALLs from pre B- and T-cell ALLs, as well as the latter from pro B-cell CD10- ALLs. Having been picked in 10both separations, this group of 80 genes distinguishes pro B-cell ALLs [both with and without the t(4;11) chromosome translocation] from pre B- and T-cell ALLs. The 46 genes of the second intersection separate simultaneously t(4;11) ALLs from CD10- ALLs and from pre B- and T-cell ALLs. Being singled out in both separations, this group of genes is neither associated with the differences between pro B- vs pre B- and Tcells and tumors, nor does it involve specific features of CD10- tumors. Rather, the expression of these genes is affected directly by the t(4;11) abnormality and probably by other unique features of the pro Bcells in which the t(4;11) aberration occurred. The majority of these 46 genes also appear in Table 1. The last group of 21 genes separates CD10- from t(4;11) ALLs as well as from pre B- and T-cell ALLs. Being selected in both separations, these 21 genes are likely to be associated with unique features of CD10tumors. Inspection of Fig. 2B points to three t(4;11) tumors, samples 2, 6, 14, which show a variant transcription profile. While the expression pattern of the 46 genes, specifically correlated with t(4;11) ALLs, is similar in these three tumors and in the rest of t(4;11) ALLs (see genes 81-126 of Fig. 2B), the transcription profile of the three tumors with regard to genes 1-80 (which distinguish pro B- from pre Band T-cell tumors) is closer to pre B- and T-cell ALLs, unlike the profile of the other eleven t(4;11) samples. The three tumors also show some quantitative variation from the other t(4;11) ALLs in transcription of the genes whose expression is associated with CD10- ALLs (genes 127-147) (Fig. 2B). These results suggest the existence of two sub-families of ALLs with the t(4;11) chromosome translocation, distinguished by their expression patterns. Finally, we applied the coupled two-way clustering method (11, 12) in an unsupervised analysis. A group of 25 genes was found consistently underexpressed in ALLs with t(4;11) compared to the other ALLs (Fig. 3; Table 7 in the web site). The cluster of samples with low expression of these genes includes 13/ of t(4;11) and 3/4 of CD10- ALLs. This is consistent with the close similarity in biological and clinical 11features between these two types of tumors. A second group of 132 genes separated the seven cell lines included in the analysis from the forty-five primary tumors. All these genes were underexpressed in the cell lines (Fig. 6 and Table 8 in the web site). Transcription profile of AMLs with ALL-1 rearrangements. AMLs with 11q23 translocations and ALL1 rearrangements were compared in their expression profiles to AMLs with normal karyotypes. At FDR of 0.15 (85% confidence) we identified 67 genes overexpressed or underexpressed in AMLs with 11q abnormalities (Fig. 4; Table 9 in web site). Three primary AMLs with ALL-1 partial duplication (5) were compared to the other AMLs with regard to expression of the 67 genes. Two of the three tumors resembled AMLs without 11q23 abnormalities, while the third appeared closer to the tumors with chromosome translocations (Fig. 4). The similarity between AMLs without 11q23 aberrations and AMLs with ALLpartial duplications was further evidenced in the failure to separate the two groups at an acceptable FDR. (In parallel, AMLs with 11q23 abnormalities were separated from AMLs with ALL-1 partial duplications at FDR of 0.3; some of this analysis is shown in Fig. 7 and Table 10 in the web site). These results, if confirmed with additional samples, suggest molecular variations between AMLs triggered by recombination of the ALL-1 gene to partner genes and AMLs triggered by ALL-1 partial duplications. The variations might be reflected in biological and clinical features. Examination of the list of genes most correlated with AMLs carrying 11q23 abnormalities (Table in the web site) discloses some involved in cancer or related processes. These include the overexpressed insulin receptor which enhances DNA synthesis and inhibits apoptosis (40), the overexpressed repair gene RAD 51 which is upregulated in breast and pancreatic cancers (41) and probably increases drug resistance, the overexpressed PPP2R5C phosphatase, the underexpressed JUNB which upregulates the tumor suppressor gene p16 and represses cyclin D1 (42) and whose knockout in mice induces myeloproliferative disease (43), the underexpressed tumor suppressor FHIT, the underexpressed double stranded RNA12activated protein kinase proapoptotic PRKR, which upregulates FAS and BAX (44), and the underexpressed DEFA1 (defensin) involved in immune response. Having identified genes differentially expressed in ALLs with t(4;11) compared to ALLs without t(4:11), and in AMLs with 11q23 abnormalities compared to AMLs without such abnormalties, we intersected the results of these two tests (we used FDR level of 0.15 for both) in order to find the genes in common. We identified 52 such genes that were overexpressed or downregulated in the relevant tumors (Fig. 5 and Table 11 in the web site). For all these genes the difference was high for one type of tumors (e.g. ALLs), but modest for the second type (e.g. AMLs). The genes that were overexpressed in the samples with ALL-1 rearrangements included the phosphatase PPP2R5C, and the MCM4 gene whose product is an essential component of the prereplicative complex (45). The underexpressed genes included FHIT and JUNB. Discussion Our results indicate distinct transcription profiles of ALL-1 associated tumors. This is likely to be reflected in the unusual clinical and biological characteristics of these tumors, such as short latency, poor prognosis, expression of myeloid genes in ALL, etc. Some of the genes pinpointed in our study of ALLs with t(4;11), which were mostly adults, were also indicated (Table 3) in our previous preliminary analysis (46) and in recent investigations which dealt with ALLs from infants and children (47, 48). Examining the genes overexpressed or underexpressed in tumors with ALL-1 rearrangements (in particular in ALLs) indicates constellation of expression patterns previously associated with, and/or highly favorable for malignant transformation and cancer. This includes activation of oncogenes (MYC, HOX A and MEIS1, LMO2, etc.), inactivation of tumor suppressor genes such as FHIT and DAPK1, suppression of apoptosis by downregulation of pro-apoptotic genes and upregulation of survival genes, suppression of host immune response (upregulation and downregulation of galectin 1 and defensin, respectively), upregulation 13of genes such as CD44, DHFR and bleomycin hydrolase conferring drug resistance, and overexpression of genes involved in cell prolferation (e.g. cyclin A1 and myb-like 2). Some of the overexpressed genes we identified, like VLDL, PDGFRB, HOX A9, MEIS1 and insulin receptor, are also found expressed in normal hematopoetic stem cells (49) but the majority of genes are not. We suggest that at least some of the genes alluded to by our study contribute directly to the aggressive nature of the disease and to its known resistance to therapy. In an attempt to identify genes whose expression correlates more strictly with the t(4;11) genotype, we separated away genes which distinguish pro B- from pre B- and T-cell tumors. The resulting list of genes (Table 5) includes several oncogenes and tumor suppressor genes and probably constitutes a better database from which to choose genes for further experiments. Another approach taken to identify genes more likely to be associated with the pathogenesis was based on the assumption (still unproven) that ALLfusion proteins trigger malignancy by a similar mechanism in both ALLs and AMLs. Thus, we looked for genes which behave in similar fashion (upregulated or downregulated) in ALLs and AMLs with ALLrearrangements (Fig. 5). At the top of the list we find PPP2R5C, FHIT and JUNB. Compartmentalization into two groups of the genes whose expression distinguishes t(4;11) from other ALLs resulted in the unexpected identification of two subclasses of t(4;11) tumors (Fig. 2B). The subclasses are discerned by the expression profile of the 80 genes separating pro B- from pre B- and T-cell tumors. Since t(4;11) tumors are generally considered pro B-cell ALL, it is surprising that with regard to genes separating pro B- from pre B- and T-cell ALLs, the smaller subclass of t(4;11) appears close to pre B- and T-cell tumors. Comparison of the clinical records of the corresponding two subclasses of patients (Table 2; samples ht17, 21 and 27 in this table show the variant profile) indicates that in the first group there are 2/3 long-term survivors, but in the second group the outcome is worse (2/9). How wide-spread is the distribution of t(4;11) patients into two groups and whether there is a significant correlation with survival 14remains to be determined. Finally, clinical studies have shown (8) that infants younger than 1 year, with ALL and t(4;11), fared significantly worse than older children. It will be of interest to compare these two groups of tumors with regard to the expression of the two groups of genes (46 and 80) identified here. The supervised analysis of AMLs with ALL-1 rearrangements vs control AMLs showed a less uniform pattern, as well as a lower number of separating genes. This suggests that the two groups of tumors are more heterogeneous. Surprisingly, two of the three AMLs with ALL-1 partial duplications showed expression profiles resembling AML controls. The generality of this observation should be decided by analyzing additional tumors. Acknowledgements O. R-A. thanks Amnon Amir for helpful thoughts and ideas. These studies were supported by NCI grant CA 50507 and by grants from the Israel Academy of Science, US-Israel BSF, Israel Cancer Research Fund, Minerva Foundation and the Germany-Israel Science Foundation (GIF). References 1. Johansson, B., Moorman, A. V., Haas, O. A., Watmore, A. E., Cheung, K. L., Swanton, S., SeckerWalker, L. M. (1998) Leukemia 12, 779-787. 2. Swansbury, G. J., Slater, R., Bain, B. J., Moorman, A. V., Secker-Walker, L. M. (1998) Leukemia 12, 792-800. 3. Gu, Y., Nakamura, T., Alder, H., Prasad, R., Canaani, O., Cimino, G., Croce, C. M., Canaani, E. (1992) Cell 71, 701-708. 4. Tkachuk, D. C., Kohler, S., Cleary, M. L. (1992) Cell 71, 691-700. 5. Schichman, S. A., Canaani, E., Croce, C. M. (1995) JAMA 273, 571-576. 6. DiMartino, J. F., Cleary, M. L. (1999) Br. J. Haematol. 106, 614-626. 7. Biondi, A., Cimino, G., Pieters, R., Pui, C. H. (2000) Blood 96, 24-33. 8. Pui, C. H., Gaynon, P. S., Boyett, J. M., Chessells, J. M., Baruchel, A., Kamps, W., Silverman, L. B., Biondi, A., Harms, D. O., Vilmer, E., Schrappe, M., Camitta, B. (2002) Lancet 359, 1909-1915. 159. Nakamura, T., Mori, T., Tada, S., Krajewski, W., Rozovskaia, T., Wassell, R., Dubois, G., Mazo, A., Croce, C. M., Canaani, E. (2002) Mol. Cell 10, 1119-1128. 10. Benjamini, Y. & Hochberg, Y. (1995) J. Royal Stat. Soc. Series B 57, 289-300. 11. Getz, G., Levine, E., Domany, E. (2000) Proc. Natl. Acad. Sci. USA 97, 12079-12084. 12. Blatt, M., Wiseman, S., Domany, E. (1996) Phys. Rev. Lett. 76, 3251-3254. 13. Levine, E., Domany, E. (2001) Neural Comput. 13, 2573-2593. 14. Shen, W. F., Rozenfeld, S., Kwong, A., Komuves, L. G., Lawrence, H. J., Largman, C. (1999) Mol. Cell Biol. 19, 3051-3061. 15. Nakamura, T., Largaespada, D. A., Shaughnessy, J. D. Jr., Jenkins, N. A., Copeland, N. G. (1996) Nat. Genet. 12, 149-153. 16. Kroon, E., Krosl, J., Thorsteinsdottir, U., Baban, S., Buchberg, A. M., Sauvageau, G. (1998) EMBO J. 17, 3714-3725. 17. Thorsteinsdottir, U., Sauvageau, G., Hough, M. R., Dragowska, W., Lansdorp, P. M., Lawrence, H. J., Largman, C., Humphries, R. K. (1997) Mol. Cell Biol. 17, 495-505. 18. Boehm, T., Foroni, L., Kaneko, Y., Perutz, M. F., Rabbitts, T. H. (1991) Proc. Natl. Acad. Sci. USA 88, 4367-71. 19. Nesbit, C. E., Tersak, J. M., Prochownik, E. V. (1999) Oncogene 18, 3004-3016. 20. Paz, A., Haklai, R., Elad-Sfadia, G., Ballan, E., Kloog, Y. (2001) Oncogene 20, 7486-7493. 21. Yamaoka, K., Mishima, K., Nagashima,Y., Asai, A., Sanai,Y., Kirino, T. (2000) J. Neurosci. Res. 59, 722-730. 22. Cross, N. C., Reiter, A. (2002) Leukemia 16, 1207-1212. 23. Eistere, W., Hilbe, W., Stauder, R., Bechter, O., Fend, F., Thaler, J. (1996) Br. J. Haematol. 93, 661669. 24. Fujita, Y., Kitagawa, M., Nakamura, S., Azuma, K., Ishi, G., Higashi, M., Kishi, H., Hiwasa, T., Koda, K., Nakajima, N., Harigaya, K. (2002) FEBS Lett. 528, 101-108. 25. O'Connor, D. S., Wall, N. R., Porter, A. C., Altieri, D. C. (2002) Cancer Cell 2, 43-54. 26. Li, X., Scuderi, A., Letsou, A., Virshup, D. M. (2002) Mol. Cell Biol. 22, 3674-3684. 27. Bulavin, D. V., Higashimoto, Y., Popoff, I. J., Gaarde, W. A., Basrur, V., Potapova, O., Appella, E., Fornace, A. J. (2001) Nature 411, 102-107. 28. Greenberg, A. K., Basu, S., Hu, J., Yie, T. A., Tchou-Wong, K. M., Rom, W. N., Lee, T. C. (2002) Am. J. Respir. Cell Mol. Biol. 26, 558-564. 1629. Blackshaw, S., Sawa, A., Sharp, A. H., Ross, C. A., Snyder, S. H., Khan, A. A. (2000) FASEB J. 14, 1375-1379. 30. Furstenberger, G., Senn, H. J. (2002) Lancet Oncol. 3, 298-302. 31. Liebermann, D. A., Gregory, B., Hoffman, B. (1998) Int. J. Oncol. 12, 685-700. 32. Pallardy, M., Biola, A. (1998) C. R. Seances Soc. Biol. Fil. 192, 1051-1063. 33. Pekarsky, Y., Zanesi, N., Palamarchuk, A., Huebner, K., Croce, C. M. (2002) Lancet Oncol. 3, 748-754. 34. Raveh, T., Droguett, G., Horwitz, M. S., DePinho, R. A., Kimchi, A. (2001) Nat. Cell Biol. 3, 1-7. 35. Hata, A., Shi, Y., Massague, J. (1998) Mol. Med. Today 4, 257-262. 36. Yam, C. H., Fung, T. K., Poon, R. Y. (2002) Cell Mol. Life Sci. 59, 1317-1326. 37. Arsura, M., Introna, M., Passerini, F., Mantovani, A., Golay, J. (1992) Blood 79, 2708-2716. 38. Cervellera, M., Raschella, G., Santilli, G., Tanno, B., Ventura, A., Mancini, C., Sevignani, C., Calabretta, B., Sala, A. (2000) J. Biol. Chem. 275, 21055-21060. 39. Lee, S. W., Reimer, C. L., Fang, L., Iruela-Arispe, M., Aaronson, S. A. (2000) Mol. Cell Biol. 20, 1723-1732. 40. Tseng, Y. H., Ueki, K., Kriauciunas, K. M., Kahn, C. R. (2002) J. Biol. Chem. 277, 31601-31611. 41. Maacke, H., Opitz, S., Jost, K., Hamdorf, W., Henning, W., Kruger, S., Feller, A. C., Lopens, A., Diedrich, K., Schwinger, E., Sturzbecher, H. W. (2000) Int. J. Cancer 88, 907-913. 42. Shaulian, E., Karin, M. (2001) Oncogene 20, 2390-2400. 43. Passegue, E., Jochum, W., Schorpp-Kistner, M., Mohle-Steinlein, U., Wagner, E. F. (2001) Cell 104, 21-32. 44. Gil, J., Esteban, M. (2000) Apoptosis 5, 107-14. 45. You, Z., Ishimi, Y., Masai, H., Hanaoka, F. (2002) J. Biol. Chem. 277, 42471-42479. 46. Rozovskaia, T., Feinstein, E., Mor, O., Foa, R., Blechman, J., Nakamura, T., Croce, C. M., Cimino, G., Canaani, E. (2001) Oncogene 20, 874-878. 47. Yeoh, E. J., Ross, M. E., Shurtleff, S. A., Williams, W. K., Patel, D., Mahfouz, R., Behm, F. G., Raimondi, S. C., Relling, M. V., Patel, A., Cheng, C., Campana, D., Wilkins, D., Zhou, X., Li, J., Liu, H., Pui, C. H., Evans, W. E., Naeve, C., Wong, L., Downing, J. R. (2002) Cancer Cell 1, 133-143. 48. Armstrong, S. A., Staunton, J. E., Silverman, L. B., Pieters, R., den Boer, M. L., Minden, M. D., Sallan, S. E., Lander, E. S., Golub, T. R., Korsmeyer, S. J. (2002) Nat. Genet. 30, 4149. Ivanova, N. B., Dimos, J. T., Schaniel, C., Hackney, J. A., Moore, K. A., Lemischka, I. R. (2002) Science 298, 601-604. 17Fig. 1 Supervised analysis of genes distinguishing ALLs with ALL-1 rearrangement [t(4;11)] from other ALLs (A), and relative levels of expression of selected genes (B). Expression levels greater and smaller than the mean 0 are shown in red and green, respectively. 18Fig. 2 Intersections of genes separating three types of ALLs (see text). Three groups of genes, encompassing 80, 46 and 21 genes, were found to participate each in two separations (A). The expression matrix of these three groups is shown in (B). Levels of expression higher or lower than the mean 0 are shown in red/yellow and blue, respectively. Arrows point to samples with variant expression profile (see text). Fig. 3 Clustering the ALL samples, on the basis of their expression levels over a cluster of 25 genes, G (that was obtained by the CTWC method). The resulting dendrogram is on the left; each leave corresponds to an ALL sample, with t(4;11) ALLs colored red and CD10- ALLs by rose. The expression matrix is shown on the right, with rows corresponding to samples and columns to genes. 13/14 of t(4;11) samples and 3/ of CD10- ALLs are in the central cluster of samples with low expression levels. 19Fig. 4 Genes distinguishing AMLs with 11q23 chromosome translocations and ALL-1 rearrangements (samples 1-12) from other AMLs (samples 16-25). Samples 13-15 of AMLs with ALL-1 partial duplication were not included in the supervised analysis, but were added later for purpose of comparison. 20TABLE 1. GENES MOST CORRELATED (OVEREXPRESSED OR UNDEREXPRESSED) IN ALLs WITH THE t(4;11) ABERRATION, COMPARED TO OTHER ALLs OVEREXPRESSED Also scored as confidence No t(4;11)- specific* Acc. No Symbol and function p-value fold change interval 1 √ D VLDLR, very low density lipoprotein receptor; signal transduction, modulation of Dab1/Tau phosphorylation 0.000004 17.51 (10.67-28.74) 2 √ U MEIS1, myeloid ecotropic viral integration site 1 homolog (mouse); homeobox protein, murine leukemia 0.000004 14.50 (7.64-27.51) 3 √ AC004080 HOXA10, homeo box A10; sequence specific transcription factor 0.000022 10.80 (6.17-18.90) 4 √ AI LGALS1, lectin, galactoside-binding, soluble 1 (galectin1); cell apoptosis and differentiation 0.000024 23.00 (8.82-59.98) 5 √ M54992 CD72 antigen; B cell proliferation and differentiation 0.000037 4.35 (2.80-6.74) 6 √ U HOXA9, homeo box A9; sequence specific transcription factor, murine myeloid leukemia 0.000041 20.12 (7.22-56.09) 7 AF098641 CD44, CD44 isoform (Indian blood group system) 0.000056 4.43 (2.65-7.41) 8 √ L CD44, CD44 antigen (Indian blood group system); cell surface receptor, lymphocyte activation/homing 0.000056 5.43 (3.07-9.60) 9 √ AA RECK, reversion-inducing-cystein-rich protein with kazal motifs; membrane glycoprotein, tumor suppression 0.000063 3.58 (2.03-6.31) 10 √ M14087 HL14, beta-galactoside-binding lectin 0.000068 6.94 (3.50-13.76) 11 √ Z PPP2R5C, protein phosphatase 2, regulatory subunit B (B56), gamma isoform 0.000069 7.55 (3.60-15.83) 12 √ M CD44, CD44 antigen (Indian blood group system); cell surface receptor, lymphocyte activation/homing 0.000069 4.10 (2.57-6.54) 13 D83767 D8S2298E (reproduction 8); fertilization 0.000086 3.16 (2.01-4.97) 14 AF GPM6B, glycoprotein M6B; integral membrane protein, expressed in neurons and glia 0.000095 13.06 (5.98-28.53) 15 X CSPG4, chondroitin sulfate proteoglycan 4 (melanomaassociated) 0.000097 7.97 (3.56-17.85) 16 √ D QPRT, quinolinate phosphoribosyltransferase; biosynthesis of NAD and NADP 0.000104 7.31 (3.86-13.86) 17 √ V MYC, v-myc myelocytomatosis viral oncogene homolog (avian); transcription factor, cell proliferation 0.000126 5.93 (2.68-13.12) 18 X LMO2, LIM domain only 2 (rhombotin-like 1); transcription factor, red blood cell development 0.000126 3.85 (2.05-7.22) 19 Z PPP2R5C, protein phosphatase 2, regulatory subunit B (B56), gamma isoform 0.000153 6.11 (2.79-13.38) 20 √ M FUT4, fucosyltransferase 4 (alpha (1,3) fucosyltransferase, myeloid-specific); glycosylation 0.000187 3.52 (2.17-5.71) UNDEREXPRESSED 131 √ U FHIT, fragile histidine triad; nucleotide metabolism, tumor suppressor 0.000010 -8. (-5.16)-(- 12.97) 132 √ U TNFRSF14, tumor necrosis factor receptor superfamily, member 14; lymphocyte activation 0.000012 -24. (-12.05)-(- 50.72) 133 √ U ITPR3, inositol 1,4,5-triphosphate receptor type 3; signal transduction, small molecule transport 0.000013 -10. (-6.49)-(- 17.63) 134 √ M16594 GSTA2, glutathione S-transferase A2 0.000017 -3.48 (-2.27)-(-5.34) 135 √ U FLT3LG, fms-related tyrosine kinase 3 ligand; stimulates proliferation of early hematopoietic cells 0.000024 -2.24 (-1.56)-(-3.20) 136 √ AB007895 KIAA0435 0.000037 -4.38 (-2.47)-(-7.77) 137 J05257 DPEP1, dipeptidase 1 (renal); renal metabolism of glutathione 0.000046 -3.24 (-2.07)-(-5.07) 138 √ X ITGA6, integrin alpha 6; laminin receptor, critical structure role in the hemidesmosome 0.000056 -15. (-6.59)-(- 36.79) 139 √ J ALOX5, arachidonate 5- lipoxygenase; biosythesis of leukotrienes 0.000056 -4.57 (-2.63)-(-7.94) 140 U ITPR3, inositol 1,4,5-triphosphate receptor, type 3; signal transduction, small molecule transport 0.000062 -5.21 (-3.30)-(-8.23) 21141 √ L34059 CDH4, cadherin 4, type 1, R-cadherin (retinal); cell adhesion 0.000069 -6. (-3.48)-(- 13.64) 142 AF041434 PTP4A3, protein tyrosine phosphatase type IVA, member 3 0.000085 -4.11 (-2.36)-(-7.18) 143 √ X DAPK1, death-associated protein kinase 1; mediating interferongamma-induced cell death 0.000093 -7.90 (-3.94)-(- 15.85) 144 √ U TCF8, transcription factor 8; repression of transcription (interleukin-2) 0.000100 -3.29 (-1.85)-(-5.84) 145 √ M92357 TNFAIP2, tumor necrosis factor, alpha-induced protein 2 0.000104 -3.82 (-2.20)-(-6.66) 146 √ U FHIT, fragile histidine triad; nucleotide metabolism, tumor suppressor 0.000104 -3.76 (-2.04)-(-6.91) 147 √ AB002301 KIAA0303 0.000110 -15. (-6.31)-(- 36.68) 148 √ S59184 RYK, RYK receptor-like tyrosine kinase 0.000135 -4.64 (-2.58)-(-8.33) 149 Y11312 PIK3C2B, phosphoinositide-3-kinase, class 2, beta polypeptide 0.000187 -2.52 (-1.66)-(-3.81) 150 M ANPEP, alanyl (membrane) aminopeptidase (aminopeptidase N, M, CD13, p150); receptor for coronavirus 0.000216 -4.24 (-2.23)-(-8.06) 151 √ U MADH1, mothers against decapentaplegic homolog (Drosophila); receptor-regulated transcription 0.000253 -10. (-4.20)-(- 26.35) * Also included within the group of 46 genes, associated with specific features of t(4;11) ALLs, in Fig. 22\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run \"PDF text cleaning.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a003ef-08c5-47a2-82a5-2b29c44f7668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set up basic configuration for logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # You can change this to DEBUG for more details\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Create a logger object\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8f4c11-fc8b-4c27-a2f0-97339b17dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tfidf_summarize(text, top_n = 25):\n",
    "    \n",
    "    try:\n",
    "        # Validate input\n",
    "        if not isinstance(text, str):\n",
    "            raise ValueError(\"Input text must be a string.\")\n",
    "        \n",
    "        sentences = sent_tokenize(text)\n",
    "        \n",
    "        # Handle edge cases\n",
    "        if not sentences:  # Empty input\n",
    "            return \"Error: No valid sentences found in text.\"\n",
    "        if top_n <= 0:\n",
    "            raise ValueError(\"Error: top_n must be greater than zero.\")\n",
    "        if len(sentences) <= top_n:\n",
    "            return text  # If fewer sentences than top_n, return original text\n",
    "        \n",
    "        # Apply TF-IDF\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "        # Compute sentence scores\n",
    "        sentence_scores = np.array(tfidf_matrix.sum(axis = 1)).ravel()\n",
    "        top_indices = sentence_scores.argsort()[-top_n:][::-1]\n",
    "        top_sentences = [sentences[i] for i in sorted(top_indices)]\n",
    "        \n",
    "        return ' '.join(top_sentences)\n",
    "    \n",
    "    except ValueError as ve:\n",
    "        return f\"ValueError: {ve}\"\n",
    "    except Exception as e:\n",
    "        return f\"Unexpected error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172d6ddd-0454-47e7-aa8a-4d91857c4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tfidf_summarize(texts, top_n=25):\n",
    "\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not isinstance(texts, list):\n",
    "            raise ValueError(\"Input must be a list of texts.\")\n",
    "        \n",
    "        # Process each text in the batch\n",
    "        results = []\n",
    "        for i, text in enumerate(texts):\n",
    "            try:\n",
    "                summary = tfidf_summarize(text, top_n)\n",
    "                results.append(summary)\n",
    "            except Exception as e:\n",
    "                # Catch errors for individual texts without stopping the batch\n",
    "                results.append(f\"Error in document {i}: {str(e)}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except ValueError as ve:\n",
    "        return [f\"ValueError: {ve}\"]\n",
    "    except Exception as e:\n",
    "        return [f\"Unexpected error in batch processing: {str(e)}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "699793d0-1c38-4c3b-8295-106c423c290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "def led_summarize(text, max_input_length=4096, max_output_length=1024):\n",
    "\n",
    "    try:\n",
    "        # Load model and tokenizer\n",
    "        model_name = \"allenai/led-base-16384\"  \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        \n",
    "        # Check for GPU availability\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Tokenize with attention mask that allows the model to attend to all tokens\n",
    "        inputs = tokenizer(text, \n",
    "                          max_length=max_input_length, \n",
    "                          truncation=True, \n",
    "                          return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate summary\n",
    "        global_attention_mask = torch.zeros_like(inputs[\"input_ids\"])\n",
    "        # Set global attention on the first token\n",
    "        global_attention_mask[:, 0] = 1\n",
    "        inputs[\"global_attention_mask\"] = global_attention_mask\n",
    "        \n",
    "        summary_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            global_attention_mask=global_attention_mask,\n",
    "            max_length=max_output_length,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "        \n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"LED Summarization Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def batch_led_summarize(texts, max_input_length=4096, max_output_length=1024, batch_size=4):\n",
    "\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not isinstance(texts, list):\n",
    "            raise ValueError(\"Input must be a list of texts.\")\n",
    "        \n",
    "        # Load model and tokenizer once for all texts\n",
    "        model_name = \"allenai/led-base-16384\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        \n",
    "        # Check for GPU availability\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model = model.to(device)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Process texts in batches to improve efficiency\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_results = []\n",
    "            \n",
    "            # Process each text in the current batch\n",
    "            for text in batch_texts:\n",
    "                try:\n",
    "                    # Tokenize\n",
    "                    inputs = tokenizer(text, \n",
    "                                      max_length=max_input_length, \n",
    "                                      truncation=True, \n",
    "                                      return_tensors=\"pt\")\n",
    "                    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                    \n",
    "                    # Generate summary\n",
    "                    global_attention_mask = torch.zeros_like(inputs[\"input_ids\"])\n",
    "                    global_attention_mask[:, 0] = 1\n",
    "                    inputs[\"global_attention_mask\"] = global_attention_mask\n",
    "                    \n",
    "                    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "                        summary_ids = model.generate(\n",
    "                            inputs[\"input_ids\"],\n",
    "                            attention_mask=inputs[\"attention_mask\"],\n",
    "                            global_attention_mask=global_attention_mask,\n",
    "                            max_length=max_output_length,\n",
    "                            num_beams=4,\n",
    "                            length_penalty=2.0,\n",
    "                            early_stopping=True,\n",
    "                        )\n",
    "                    \n",
    "                    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "                    batch_results.append(summary)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    batch_results.append(f\"LED Summarization Error: {str(e)}\")\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except ValueError as ve:\n",
    "        return [f\"ValueError: {ve}\"]\n",
    "    except Exception as e:\n",
    "        return [f\"Unexpected error in batch processing: {str(e)}\"]\n",
    "\n",
    "\n",
    "# Alternative implementation with true parallel batch processing\n",
    "def batch_led_summarize_parallel(\n",
    "    texts,\n",
    "    model_name=\"allenai/led-base-16384\",\n",
    "    max_input_length=4096,\n",
    "    max_output_length= 1024,\n",
    "    batch_size=4,\n",
    "    num_beams=4\n",
    "):\n",
    "\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    import torch\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    if not isinstance(texts, list):\n",
    "        raise ValueError(\"Input must be a list of texts.\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"LED Summarizing\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_input_length\n",
    "        )\n",
    "\n",
    "        # Move input tensors to the correct device\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            summary_ids = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_length=max_output_length,\n",
    "                num_beams=num_beams,\n",
    "                early_stopping=True\n",
    "            )\n",
    "\n",
    "        batch_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "        summaries.extend(batch_summaries)\n",
    "\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4125c185-7fda-4de8-905a-e176aab8bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_summarize(texts, tfidf_top_n=25, led_max_input_length=4096, led_max_output_length=1024, led_batch_size=4):\n",
    "    metrics = {\n",
    "        'tfidf_time': 0,\n",
    "        'led_time': 0,\n",
    "        'total_time': 0,\n",
    "        'original_chars': sum(len(t) for t in texts),\n",
    "        'tfidf_chars': 0,\n",
    "        'final_chars': 0\n",
    "    }\n",
    "    \n",
    "    start_total = time.time()\n",
    "    \n",
    "    # Step 1: TF-IDF summarization\n",
    "    logger.info(f\"Starting TF-IDF summarization for {len(texts)} documents...\")\n",
    "    start_tfidf = time.time()\n",
    "    tfidf_summaries = batch_tfidf_summarize(texts, top_n=tfidf_top_n)\n",
    "    metrics['tfidf_time'] = time.time() - start_tfidf\n",
    "    metrics['tfidf_chars'] = sum(len(s) for s in tfidf_summaries)\n",
    "    \n",
    "    logger.info(f\"TF-IDF summarization completed in {metrics['tfidf_time']:.2f} seconds\")\n",
    "    logger.info(f\"Original text: {metrics['original_chars']} chars, TF-IDF summaries: {metrics['tfidf_chars']} chars\")\n",
    "    \n",
    "    # Step 2: LED summarization on TF-IDF results\n",
    "    logger.info(f\"Starting LED summarization on TF-IDF results...\")\n",
    "    start_led = time.time()\n",
    "    led_summaries = batch_led_summarize_parallel(\n",
    "        tfidf_summaries, \n",
    "        max_input_length=led_max_input_length,\n",
    "        max_output_length=led_max_output_length,\n",
    "        batch_size=led_batch_size\n",
    "    )\n",
    "    metrics['led_time'] = time.time() - start_led\n",
    "    metrics['final_chars'] = sum(len(s) for s in led_summaries)\n",
    "    \n",
    "    logger.info(f\"LED summarization completed in {metrics['led_time']:.2f} seconds\")\n",
    "    logger.info(f\"Final summaries: {metrics['final_chars']} chars\")\n",
    "    \n",
    "    metrics['total_time'] = time.time() - start_total\n",
    "    logger.info(f\"Total pipeline time: {metrics['total_time']:.2f} seconds\")\n",
    "    \n",
    "    # Calculate compression ratios\n",
    "    metrics['tfidf_compression'] = metrics['tfidf_chars'] / metrics['original_chars'] if metrics['original_chars'] > 0 else 0\n",
    "    metrics['final_compression'] = metrics['final_chars'] / metrics['original_chars'] if metrics['original_chars'] > 0 else 0\n",
    "    \n",
    "    # Modified return statement to include tfidf_summaries\n",
    "    return led_summaries, tfidf_summaries, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480c13e2-c6a2-4307-84c1-d6c3be922119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 02:20:47,561 - INFO - Starting TF-IDF summarization for 100 documents...\n",
      "2025-05-08 02:20:48,587 - INFO - TF-IDF summarization completed in 1.03 seconds\n",
      "2025-05-08 02:20:48,587 - INFO - Original text: 3668724 chars, TF-IDF summaries: 678928 chars\n",
      "2025-05-08 02:20:48,600 - INFO - Starting LED summarization on TF-IDF results...\n",
      "LED Summarizing:   0%|          | 0/25 [00:00<?, ?it/s]Input ids are automatically padded from 3015 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "LED Summarizing:   8%|▊         | 2/25 [04:03<49:18, 128.63s/it]Input ids are automatically padded from 2960 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "LED Summarizing:   8%|▊         | 2/25 [05:33<1:03:55, 166.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sample_texts \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m----> 2\u001b[0m led_summaries, tfidf_summaries, metrics \u001b[38;5;241m=\u001b[39m pipeline_summarize(\n\u001b[0;32m      3\u001b[0m     sample_texts, \n\u001b[0;32m      4\u001b[0m     tfidf_top_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m,  \u001b[38;5;66;03m# Extract top 25 sentences with TF-IDF\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     led_max_output_length\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m  \u001b[38;5;66;03m# Generate summaries of up to 512 tokens\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Add summaries to dataframe for ROUGE evaluation\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf_summaries\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tfidf_summaries\n",
      "Cell \u001b[1;32mIn[7], line 26\u001b[0m, in \u001b[0;36mpipeline_summarize\u001b[1;34m(texts, tfidf_top_n, led_max_input_length, led_max_output_length, led_batch_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting LED summarization on TF-IDF results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m start_led \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 26\u001b[0m led_summaries \u001b[38;5;241m=\u001b[39m batch_led_summarize_parallel(\n\u001b[0;32m     27\u001b[0m     tfidf_summaries, \n\u001b[0;32m     28\u001b[0m     max_input_length\u001b[38;5;241m=\u001b[39mled_max_input_length,\n\u001b[0;32m     29\u001b[0m     max_output_length\u001b[38;5;241m=\u001b[39mled_max_output_length,\n\u001b[0;32m     30\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mled_batch_size\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mled_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_led\n\u001b[0;32m     33\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_chars\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m led_summaries)\n",
      "Cell \u001b[1;32mIn[6], line 149\u001b[0m, in \u001b[0;36mbatch_led_summarize_parallel\u001b[1;34m(texts, model_name, max_input_length, max_output_length, batch_size, num_beams)\u001b[0m\n\u001b[0;32m    146\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {key: val\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 149\u001b[0m     summary_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    150\u001b[0m         inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    151\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    152\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_output_length,\n\u001b[0;32m    153\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mnum_beams,\n\u001b[0;32m    154\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    157\u001b[0m batch_summaries \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(summary_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    158\u001b[0m summaries\u001b[38;5;241m.\u001b[39mextend(batch_summaries)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2484\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[0;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2482\u001b[0m     )\n\u001b[0;32m   2483\u001b[0m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2484\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[0;32m   2485\u001b[0m         input_ids,\n\u001b[0;32m   2486\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2487\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2488\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2489\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2490\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2491\u001b[0m     )\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2494\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2495\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2496\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2497\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2503\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2504\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3895\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3892\u001b[0m beam_indices \u001b[38;5;241m=\u001b[39m running_beam_indices\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;66;03m# 4. run the generation loop\u001b[39;00m\n\u001b[1;32m-> 3895\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_unfinished_sequences(this_peer_finished, synced_gpus, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[0;32m   3896\u001b[0m     \u001b[38;5;66;03m# a. Forward current tokens, obtain the logits\u001b[39;00m\n\u001b[0;32m   3897\u001b[0m     flat_running_sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_beam_dim(running_sequences[:, :, :cur_len])\n\u001b[0;32m   3898\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(flat_running_sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2602\u001b[0m, in \u001b[0;36mGenerationMixin._has_unfinished_sequences\u001b[1;34m(self, this_peer_finished, synced_gpus, device)\u001b[0m\n\u001b[0;32m   2599\u001b[0m         result\u001b[38;5;241m.\u001b[39mpast_key_values \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mpast_key_values\u001b[38;5;241m.\u001b[39mto_legacy_cache()\n\u001b[0;32m   2600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 2602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_has_unfinished_sequences\u001b[39m(\u001b[38;5;28mself\u001b[39m, this_peer_finished: \u001b[38;5;28mbool\u001b[39m, synced_gpus: \u001b[38;5;28mbool\u001b[39m, device: torch\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   2603\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;124;03m    Returns whether there are still unfinished sequences in the device. The existence of unfinished sequences is\u001b[39;00m\n\u001b[0;32m   2605\u001b[0m \u001b[38;5;124;03m    fed through `this_peer_finished`. ZeRO stage 3-friendly.\u001b[39;00m\n\u001b[0;32m   2606\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m synced_gpus:\n\u001b[0;32m   2608\u001b[0m         \u001b[38;5;66;03m# Under synced_gpus the `forward` call must continue until all gpus complete their sequence.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m         \u001b[38;5;66;03m# The following logic allows an early break if all peers finished generating their sequence\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_texts = df['clean'].tolist()\n",
    "led_summaries, tfidf_summaries, metrics = pipeline_summarize(\n",
    "    sample_texts, \n",
    "    tfidf_top_n = 25,  # Extract top 25 sentences with TF-IDF\n",
    "    led_max_output_length= 1024  # Generate summaries of up to 512 tokens\n",
    ")\n",
    "\n",
    "# Add summaries to dataframe for ROUGE evaluation\n",
    "df['tfidf_summaries'] = tfidf_summaries\n",
    "df['led_summaries'] = led_summaries\n",
    "\n",
    "# Print results\n",
    "print(\"\\n=== FINAL SUMMARIES ===\")\n",
    "for i, summary in enumerate(led_summaries):\n",
    "    print(f\"\\nDocument {i+1} summary:\")\n",
    "    print(summary)\n",
    "    \n",
    "print(\"\\n=== PERFORMANCE METRICS ===\")\n",
    "print(f\"Original text: {metrics['original_chars']} characters\")\n",
    "print(f\"After TF-IDF: {metrics['tfidf_chars']} characters ({metrics['tfidf_compression']*100:.1f}% of original)\")\n",
    "print(f\"Final summaries: {metrics['final_chars']} characters ({metrics['final_compression']*100:.1f}% of original)\")\n",
    "print(f\"TF-IDF time: {metrics['tfidf_time']:.2f} seconds\")\n",
    "print(f\"LED time: {metrics['led_time']:.2f} seconds\")\n",
    "print(f\"Total time: {metrics['total_time']:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9cadd8-626d-4c92-a523-c9f192793450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge_scores(reference_text, generated_summary):\n",
    "\n",
    "    try:\n",
    "        # Initialize ROUGE scorer with the metrics we want to use\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        \n",
    "        # Calculate scores\n",
    "        scores = scorer.score(reference_text, generated_summary)\n",
    "        \n",
    "        # Extract F1 scores (balance of precision and recall)\n",
    "        rouge1_f1 = scores['rouge1'].fmeasure\n",
    "        rouge2_f1 = scores['rouge2'].fmeasure\n",
    "        rougeL_f1 = scores['rougeL'].fmeasure\n",
    "        \n",
    "        return {\n",
    "            'rouge1_f1': rouge1_f1,\n",
    "            'rouge2_f1': rouge2_f1,\n",
    "            'rougeL_f1': rougeL_f1,\n",
    "            'average_f1': np.mean([rouge1_f1, rouge2_f1, rougeL_f1])\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating ROUGE scores: {str(e)}\")\n",
    "        return {\n",
    "            'rouge1_f1': 0.0,\n",
    "            'rouge2_f1': 0.0,\n",
    "            'rougeL_f1': 0.0,\n",
    "            'average_f1': 0.0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7899057-5cfc-44af-9330-d2d3817bb902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROUGE scores if needed\n",
    "print(\"\\n=== CALCULATING ROUGE SCORES ===\")\n",
    "print(\"Calculating ROUGE scores for TF-IDF summaries...\")\n",
    "df['tfidf_rouge'] = df.apply(\n",
    "    lambda row: calculate_rouge_scores(row['clean'], row['tfidf_summaries']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Calculating ROUGE scores for LED summaries...\")\n",
    "df['led_rouge'] = df.apply(\n",
    "    lambda row: calculate_rouge_scores(row['clean'], row['led_summaries']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3587e-d3f2-4236-9133-69da20888b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n=== ROUGE SCORES BY DOCUMENT ===\")\n",
    "for idx, row in df.head(10).iterrows():\n",
    "    print(f\"\\n--- DOCUMENT {idx} ROUGE SCORES ---\")\n",
    "    \n",
    "    print(\"TF-IDF Summary:\")\n",
    "    print(f\"  ROUGE-1: {row['tfidf_rouge']['rouge1_f1']:.4f}\")\n",
    "    print(f\"  ROUGE-2: {row['tfidf_rouge']['rouge2_f1']:.4f}\")\n",
    "    print(f\"  ROUGE-L: {row['tfidf_rouge']['rougeL_f1']:.4f}\")\n",
    "    print(f\"  Average: {row['tfidf_rouge']['average_f1']:.4f}\")\n",
    "    \n",
    "    print(\"\\nLED Summary:\")\n",
    "    print(f\"  ROUGE-1: {row['led_rouge']['rouge1_f1']:.4f}\")\n",
    "    print(f\"  ROUGE-2: {row['led_rouge']['rouge2_f1']:.4f}\")\n",
    "    print(f\"  ROUGE-L: {row['led_rouge']['rougeL_f1']:.4f}\")\n",
    "    print(f\"  Average: {row['led_rouge']['average_f1']:.4f}\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14e767-b235-417e-8642-f86f409b95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n=== AVERAGE ROUGE SCORES ACROSS ALL DOCUMENTS ===\")\n",
    "\n",
    "# For TF-IDF\n",
    "avg_tfidf_rouge1 = df['tfidf_rouge'].apply(lambda x: x['rouge1_f1']).mean()\n",
    "avg_tfidf_rouge2 = df['tfidf_rouge'].apply(lambda x: x['rouge2_f1']).mean()\n",
    "avg_tfidf_rougeL = df['tfidf_rouge'].apply(lambda x: x['rougeL_f1']).mean()\n",
    "avg_tfidf_avg = df['tfidf_rouge'].apply(lambda x: x['average_f1']).mean()\n",
    "\n",
    "# For LED\n",
    "avg_led_rouge1 = df['led_rouge'].apply(lambda x: x['rouge1_f1']).mean()\n",
    "avg_led_rouge2 = df['led_rouge'].apply(lambda x: x['rouge2_f1']).mean()\n",
    "avg_led_rougeL = df['led_rouge'].apply(lambda x: x['rougeL_f1']).mean()\n",
    "avg_led_avg = df['led_rouge'].apply(lambda x: x['average_f1']).mean()\n",
    "\n",
    "print(\"TF-IDF Summarization:\")\n",
    "print(f\"  Avg ROUGE-1: {avg_tfidf_rouge1:.4f}\")\n",
    "print(f\"  Avg ROUGE-2: {avg_tfidf_rouge2:.4f}\")\n",
    "print(f\"  Avg ROUGE-L: {avg_tfidf_rougeL:.4f}\")\n",
    "print(f\"  Avg Overall: {avg_tfidf_avg:.4f}\")\n",
    "\n",
    "print(\"\\nLED Summarization:\")\n",
    "print(f\"  Avg ROUGE-1: {avg_led_rouge1:.4f}\")\n",
    "print(f\"  Avg ROUGE-2: {avg_led_rouge2:.4f}\")\n",
    "print(f\"  Avg ROUGE-L: {avg_led_rougeL:.4f}\")\n",
    "print(f\"  Avg Overall: {avg_led_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7996568f-ea24-4a47-b394-4c8245e3ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "metrics = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'Average']\n",
    "tfidf_scores = [avg_tfidf_rouge1, avg_tfidf_rouge2, avg_tfidf_rougeL, avg_tfidf_avg]\n",
    "led_scores = [avg_led_rouge1, avg_led_rouge2, avg_led_rougeL, avg_led_avg]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 6))\n",
    "tfidf_bars = ax.bar(x - width/2, tfidf_scores, width, label = 'TF-IDF', color = 'skyblue')\n",
    "led_bars = ax.bar(x + width/2, led_scores, width, label = 'LED', color = 'lightcoral')\n",
    "\n",
    "ax.set_title('Average ROUGE Scores Comparison', fontsize=16)\n",
    "ax.set_ylabel('F1 Score', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics, fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "def add_value_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy = (bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext = (0, 3),  # 3 points vertical offset\n",
    "                    textcoords = \"offset points\",\n",
    "                    ha = 'center', va='bottom')\n",
    "\n",
    "add_value_labels(tfidf_bars)\n",
    "add_value_labels(led_bars)\n",
    "\n",
    "plt.ylim(0, max(max(tfidf_scores), max(led_scores)) * 1.15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "def calculate_bleu(reference, summary):\n",
    "    reference_tokens = reference.split()\n",
    "    summary_tokens = summary.split()\n",
    "    return sentence_bleu([reference_tokens], summary_tokens, smoothing_function=smoothie)\n",
    "\n",
    "print(\"Calculating BLEU scores for TF-IDF summaries...\")\n",
    "df['tfidf_bleu'] = df.apply(lambda row: calculate_bleu(row['clean'], row['tfidf_summaries']), axis=1) \n",
    "print(\"Calculating BLEU scores for LED summaries...\")\n",
    "df['led_bleu'] = df.apply(lambda row: calculate_bleu(row['clean'], row['led_summaries']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff39f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bert_score\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "print(\"Calculating BERTScores for TF-IDF summaries...\")\n",
    "P, R, F1 = bert_score(df['tfidf_summaries'].tolist(), df['clean'].tolist(), lang=\"en\", verbose=True)\n",
    "df['tfidf_bertscore'] = F1\n",
    "\n",
    "print(\"Calculating BERTScores for LED summaries...\")\n",
    "P, R, F1 = bert_score(df['led_summaries'].tolist(), df['clean'].tolist(), lang=\"en\", verbose=True)\n",
    "df['led_bertscore'] = F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f1c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n=== AVERAGE BLEU & BERTScores ===\")\n",
    "\n",
    "print(\"TF-IDF:\")\n",
    "print(f\"  Avg BLEU: {df['tfidf_bleu'].mean():.4f}\")\n",
    "print(f\"  Avg BERTScore (F1): {df['tfidf_bertscore'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nLED:\")\n",
    "print(f\"  Avg BLEU: {df['led_bleu'].mean():.4f}\")\n",
    "print(f\"  Avg BERTScore (F1): {df['led_bertscore'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c2c71-4b99-424d-8570-e280792ec7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extracting BLEU & BERTScore averages dynamically\n",
    "models = [\"TF-IDF\", \"LED\"]\n",
    "metrics = [\"BLEU\", \"BERTScore (F1)\"]\n",
    "\n",
    "scores = np.array([\n",
    "    [df['tfidf_bleu'].mean(), df['tfidf_bertscore'].mean()],  # TF-IDF Scores\n",
    "    [df['led_bleu'].mean(), df['led_bertscore'].mean()]       # LED Scores\n",
    "])\n",
    "\n",
    "# Plot settings\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot bars\n",
    "tfidf_bars = ax.bar(x - width/2, scores[0], width, label=\"TF-IDF\", color=\"skyblue\")\n",
    "led_bars = ax.bar(x + width/2, scores[1], width, label=\"LED\", color=\"lightcoral\")\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics, fontsize=12)\n",
    "ax.set_ylabel(\"Score\", fontsize=14)\n",
    "ax.set_title(\"Comparison of BLEU & BERTScore (F1) Between Models\", fontsize=16)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "# Add value labels\n",
    "def add_value_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.4f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 5),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha=\"center\", va=\"bottom\")\n",
    "\n",
    "add_value_labels(tfidf_bars)\n",
    "add_value_labels(led_bars)\n",
    "\n",
    "plt.ylim(0, max(scores.flatten()) * 1.15)  # Adjust limit for better visibility\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf86ed-5945-4dec-8dec-d1a6d1abc1ab",
   "metadata": {},
   "source": [
    "-Measures n-gram precision, showing how much the generated text matches exact phrases from the reference summary.\n",
    "-TF-IDF (higher BLEU score) → More exact word match with the reference.\n",
    "-LED (lower BLEU score) → More abstract paraphrasing, leading to fewer identical word sequences.\n",
    "\n",
    "-Measures semantic similarity between generated and reference summaries.\n",
    "-TF-IDF (higher BERTScore) → Preserves more word-level similarity.\n",
    "-LED (lower BERTScore) → Rewrites sentences more abstractly, leading to slightly lower word alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd8fe9-18d1-4609-b3cf-13f419bcab29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
